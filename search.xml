<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[muduo EventLoopThread相关]]></title>
    <url>%2F2017%2F06%2F24%2Fmuduo-EventLoopThread%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[EventLoopThread分析比较好的服务器模型是采用继续one loop in one thread的方式。并且最好设置EventLoop的数目最好不要超过cpu的核数，这样减少线程之间的对于cpu的争用。 EventLoop的用途是新建一个线程，在此线程上初始化EventLoop对象，启动事件循环，并且返回新建的事件循环。其具体实现可以类比为使用count设为1的CountDownLatch来完成。为了新建在新的线程上的事件循环采用下述方式： 123456789101112131415EventLoop* EventLoopThread::startLoop()&#123; assert(!thread_.started()); thread_.start(); &#123; MutexLockGuard lock(mutex_); while (loop_ == NULL) &#123; cond_.wait(); &#125; &#125; return loop_;&#125; thread在启动时会调用如下函数，新建并且启动EventLoop。创建EventLoop完成之后，会使用notify通知调用startLoop的线程，新的EventLoop已经就绪。 12345678910111213141516171819void EventLoopThread::threadFunc()&#123; EventLoop loop; if (callback_) &#123; callback_(&amp;loop); &#125; &#123; MutexLockGuard lock(mutex_); loop_ = &amp;loop; cond_.notify(); &#125; loop.loop(); //assert(exiting_); loop_ = NULL;&#125; EventLoopThreadPool用途：创建一个EventLoop pool, 创建给定数目的线程，每个线程之上新建一个EventLoop对象并且启动事件循环。 其关键方法是getNextLoop, 他会采用round robin方式，每次返回下一个可用的事件循环。若pool不为空，只返回pool之中的事件循环，否则返回baseLoop_。这一做法在于后面TcpServer之中，只使用baseLoop_来处理连接建立，使用pool之中的线程用来处理和客户端的io事件。 123456789101112131415161718EventLoop* EventLoopThreadPool::getNextLoop()&#123; baseLoop_-&gt;assertInLoopThread(); assert(started_); EventLoop* loop = baseLoop_; if (!loops_.empty()) &#123; // round-robin loop = loops_[next_]; ++next_; if (implicit_cast&lt;size_t&gt;(next_) &gt;= loops_.size()) &#123; next_ = 0; &#125; &#125; return loop;&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo EventLoop解析]]></title>
    <url>%2F2017%2F06%2F24%2Fmuduo-EventLoop%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[线程安全回调在很多情况下，需要将函数操作转移到io线程之中进行，muduo EventLoop支持queueInLoop 和 runInLoop 调用，视调用线程情况，将回调函数暂时存放在vector之中，在时间循环的末尾统一进行调用处理。 为了保证输入的回调函数能够尽快完成，不然这些回调函数可能需要等到poller超时返回之后才能得以运行。muduo在事件循环中使用了eventFd，对于可能阻塞在Poller的情况，会向eventFd写入1，触发Poller调用返回，从而使回调函数得以执行。 当然，可能在其他线程之中调用queueInLoop函数，为了线程安全，存入新的回调函数的时候需要进行加锁处理。 定时回调实现核心思想在muduo之中，对于定时回调的实现主要代码在TimerQueue.cc 以及TimerQueue.h之中。其核心思路是使用timerFd。timerFd用于通知事件循环最近一次的超时事件发生了，然后在对timerFd包装的channel的read回调函数之中，会对所有当前超时所对应的回调函数，一一调用。对于需要反复设置的定时器，也做好处理，保证timerFd能在合适的时间触发可读事件。 新增回调函数为了方便的拿到最近一个超时的时刻，并且应对多个回调函数对应一个超时条件的情况，在muduo之中使用set存放他所管理的时间回调函数，如下所示： 123typedef std::pair&lt;Timestamp, Timer*&gt; Entry;typedef std::set&lt;Entry&gt; TimerList;TimerList timers_; 如果要新增回调函数，首先将其插入到timers_之中，如果发现在加入新的定时回调之后，最早超时的时刻有变，那么重新设置timerFd，保证新增的回调函数能在准确的时间被调用。 cancel定时回调如果当前事件循环正在调用定时回调函数，那么在此期间不可cancel定时回调，否则会引发未定义行为。我们只需要做好记录，确保要cancel的回调函数不会被重新设置。相反，若事件循环当前没有调用超时回调函数，那么直接将对应的定时回调从对应的数据结构之中删除即可。 这里的问题在于，如果在正在调用定时回调函数的时候来cancel，可能会造成cancel失败，这里的cancel并不是强保证。但是cancel之后，总能保证在后续reset处理之后不会再调用cancel的定时回调函数。 boost::any有时候需要在不同线程的EventLoop之中记录一些EventLoop相关的信息，和muduo::TcpConnection一样，这里使用了boost::any. 12345678910void setContext(const boost::any&amp; context)&#123; context_ = context; &#125;const boost::any&amp; getContext() const&#123; return context_; &#125;boost::any* getMutableContext()&#123; return &amp;context_; &#125;boost::any context_; 一些转调用12345void updateChannel(Channel* channel);void removeChannel(Channel* channel);void hasChannel(Channel* channel);// 转调用Poller之中的定义其调用流程是Channel -&gt; EventLoop -&gt; Poller loop分析事件循环的退出很简单，一旦quit_为false，那么循环便无法继续。 123456789101112131415161718192021222324252627282930313233void EventLoop::loop()&#123; assert(!looping_); assertInLoopThread(); looping_ = true; quit_ = false; // FIXME: what if someone calls quit() before loop() ? LOG_TRACE &lt;&lt; "EventLoop " &lt;&lt; this &lt;&lt; " start looping"; while (!quit_) &#123; activeChannels_.clear(); pollReturnTime_ = poller_-&gt;poll(kPollTimeMs, &amp;activeChannels_); ++iteration_; if (Logger::logLevel() &lt;= Logger::TRACE) &#123; printActiveChannels(); &#125; // TODO sort channel by priority eventHandling_ = true; for (ChannelList::iterator it = activeChannels_.begin(); it != activeChannels_.end(); ++it) &#123; currentActiveChannel_ = *it; currentActiveChannel_-&gt;handleEvent(pollReturnTime_); &#125; currentActiveChannel_ = NULL; eventHandling_ = false; doPendingFunctors(); &#125; LOG_TRACE &lt;&lt; "EventLoop " &lt;&lt; this &lt;&lt; " stop looping"; looping_ = false;&#125; 事件循环之中主要做两件事，调用poller获取当前的activeChannel, 然后调用这些channel的回调函数。接着处理之前从外面调入的为了保证线程安全需要在io线程之中调用的回调函数。此过程循环进行，直到显示调用quit退出事件循环。]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo InetAddress]]></title>
    <url>%2F2017%2F06%2F24%2Fmuduo-InetAddress%2F</url>
    <content type="text"><![CDATA[功能解析这是一个简单的对sockfd的wrapper类，主要借助C++的RAII机制实现sockfd的自动管理。当Socket对象被析构的时候会自动关闭sockfd。 重点函数可以适当关注一下以下方法，特别是对于tcp信息的获取，设置TCP_NODELAY，SO_REUSEADDR，SO_REUSEPORT，SO_KEEPALIVE 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101bool Socket::getTcpInfo(struct tcp_info* tcpi) const&#123; socklen_t len = sizeof(*tcpi); bzero(tcpi, len); return ::getsockopt(sockfd_, SOL_TCP, TCP_INFO, tcpi, &amp;len) == 0;&#125;bool Socket::getTcpInfoString(char* buf, int len) const&#123; struct tcp_info tcpi; bool ok = getTcpInfo(&amp;tcpi); if (ok) &#123; snprintf(buf, len, "unrecovered=%u " "rto=%u ato=%u snd_mss=%u rcv_mss=%u " "lost=%u retrans=%u rtt=%u rttvar=%u " "sshthresh=%u cwnd=%u total_retrans=%u", tcpi.tcpi_retransmits, // Number of unrecovered [RTO] timeouts tcpi.tcpi_rto, // Retransmit timeout in usec tcpi.tcpi_ato, // Predicted tick of soft clock in usec tcpi.tcpi_snd_mss, tcpi.tcpi_rcv_mss, tcpi.tcpi_lost, // Lost packets tcpi.tcpi_retrans, // Retransmitted packets out tcpi.tcpi_rtt, // Smoothed round trip time in usec tcpi.tcpi_rttvar, // Medium deviation tcpi.tcpi_snd_ssthresh, tcpi.tcpi_snd_cwnd, tcpi.tcpi_total_retrans); // Total retransmits for entire connection &#125; return ok;&#125;void Socket::bindAddress(const InetAddress&amp; addr)&#123; sockets::bindOrDie(sockfd_, addr.getSockAddr());&#125;void Socket::listen()&#123; sockets::listenOrDie(sockfd_);&#125;int Socket::accept(InetAddress* peeraddr)&#123; struct sockaddr_in6 addr; bzero(&amp;addr, sizeof addr); int connfd = sockets::accept(sockfd_, &amp;addr); if (connfd &gt;= 0) &#123; peeraddr-&gt;setSockAddrInet6(addr); &#125; return connfd;&#125;void Socket::shutdownWrite()&#123; sockets::shutdownWrite(sockfd_);&#125;void Socket::setTcpNoDelay(bool on)&#123; int optval = on ? 1 : 0; ::setsockopt(sockfd_, IPPROTO_TCP, TCP_NODELAY, &amp;optval, static_cast&lt;socklen_t&gt;(sizeof optval)); // FIXME CHECK&#125;void Socket::setReuseAddr(bool on)&#123; int optval = on ? 1 : 0; ::setsockopt(sockfd_, SOL_SOCKET, SO_REUSEADDR, &amp;optval, static_cast&lt;socklen_t&gt;(sizeof optval)); // FIXME CHECK&#125;void Socket::setReusePort(bool on)&#123;#ifdef SO_REUSEPORT int optval = on ? 1 : 0; int ret = ::setsockopt(sockfd_, SOL_SOCKET, SO_REUSEPORT, &amp;optval, static_cast&lt;socklen_t&gt;(sizeof optval)); if (ret &lt; 0 &amp;&amp; on) &#123; LOG_SYSERR &lt;&lt; "SO_REUSEPORT failed."; &#125;#else if (on) &#123; LOG_ERROR &lt;&lt; "SO_REUSEPORT is not supported."; &#125;#endif&#125;void Socket::setKeepAlive(bool on)&#123; int optval = on ? 1 : 0; ::setsockopt(sockfd_, SOL_SOCKET, SO_KEEPALIVE, &amp;optval, static_cast&lt;socklen_t&gt;(sizeof optval)); // FIXME CHECK&#125; SO_REUSEADDR和SO_REUSEPORTSO_REUSEPORT功能 允许多个套接字 bind()/listen() 同一个TCP/UDP端口每一个线程拥有自己的服务器套接字 在服务器套接字上没有了锁的竞争，因为每个进程一个服务器套接字 内核层面实现负载均衡 安全层面，监听同一个端口的套接字只能位于同一个用户下面 SO_REUSEADDR提供如下四个功能： SO_REUSEADDR允许启动一个监听服务器并捆绑其众所周知端口，即使以前建立的将此端口用做他们的本地端口的连接仍存在。这通常是重启监听服务器时出现，若不设置此选项，则bind时将出错。 SO_REUSEADDR允许在同一端口上启动同一服务器的多个实例，只要每个实例捆绑一个不同的本地IP地址即可。对于TCP，我们根本不可能启动捆绑相同IP地址和相同端口号的多个服务器。 SO_REUSEADDR允许单个进程捆绑同一端口到多个套接口上，只要每个捆绑指定不同的本地IP地址即可。这一般不用于TCP服务器。 SO_REUSEADDR允许完全重复的捆绑：当一个IP地址和端口绑定到某个套接口上时，还允许此IP地址和端口捆绑到另一个套接口上。一般来说，这个特性仅在支持多播的系统上才有，而且只对UDP套接口而言（TCP不支持多播）。 SO_REUSEPORT选项有如下语义： 此选项允许完全重复捆绑，但仅在想捆绑相同IP地址和端口的套接口都指定了此套接口选项才行。 如果被捆绑的IP地址是一个多播地址，则SO_REUSEADDR和SO_REUSEPORT等效。 man12345678SO_REUSEADDR Indicates that the rules used in validating addresses supplied in a bind(2) call should allow reuse of local addresses. For AF_INET sockets this means that a socket may bind, except when there is an active listening socket bound to the address. When the listening socket is bound to INADDR_ANY with a specific port then it is not possible to bind to this port for any local address. Argument is an integer boolean flag. 12SO_REUSEPORT One of the features merged in the 3.9 development cycle was TCP and UDP support for the SO_REUSEPORT socket option; that support was implemented in a series of patches by Tom Herbert. The new socket option allows multiple sockets on the same host to bind to the same port, and is intended to improve the performance of multithreaded network server applications running on top of multicore systems.]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo socket解析]]></title>
    <url>%2F2017%2F06%2F24%2Fmuduo-socket%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[功能解析这是一个简单的对sockfd的wrapper类，主要借助C++的RAII机制实现sockfd的自动管理。当Socket对象被析构的时候会自动关闭sockfd。 重点函数可以适当关注一下以下方法，特别是对于tcp信息的获取，设置TCP_NODELAY，SO_REUSEADDR，SO_REUSEPORT，SO_KEEPALIVE 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101bool Socket::getTcpInfo(struct tcp_info* tcpi) const&#123; socklen_t len = sizeof(*tcpi); bzero(tcpi, len); return ::getsockopt(sockfd_, SOL_TCP, TCP_INFO, tcpi, &amp;len) == 0;&#125;bool Socket::getTcpInfoString(char* buf, int len) const&#123; struct tcp_info tcpi; bool ok = getTcpInfo(&amp;tcpi); if (ok) &#123; snprintf(buf, len, "unrecovered=%u " "rto=%u ato=%u snd_mss=%u rcv_mss=%u " "lost=%u retrans=%u rtt=%u rttvar=%u " "sshthresh=%u cwnd=%u total_retrans=%u", tcpi.tcpi_retransmits, // Number of unrecovered [RTO] timeouts tcpi.tcpi_rto, // Retransmit timeout in usec tcpi.tcpi_ato, // Predicted tick of soft clock in usec tcpi.tcpi_snd_mss, tcpi.tcpi_rcv_mss, tcpi.tcpi_lost, // Lost packets tcpi.tcpi_retrans, // Retransmitted packets out tcpi.tcpi_rtt, // Smoothed round trip time in usec tcpi.tcpi_rttvar, // Medium deviation tcpi.tcpi_snd_ssthresh, tcpi.tcpi_snd_cwnd, tcpi.tcpi_total_retrans); // Total retransmits for entire connection &#125; return ok;&#125;void Socket::bindAddress(const InetAddress&amp; addr)&#123; sockets::bindOrDie(sockfd_, addr.getSockAddr());&#125;void Socket::listen()&#123; sockets::listenOrDie(sockfd_);&#125;int Socket::accept(InetAddress* peeraddr)&#123; struct sockaddr_in6 addr; bzero(&amp;addr, sizeof addr); int connfd = sockets::accept(sockfd_, &amp;addr); if (connfd &gt;= 0) &#123; peeraddr-&gt;setSockAddrInet6(addr); &#125; return connfd;&#125;void Socket::shutdownWrite()&#123; sockets::shutdownWrite(sockfd_);&#125;void Socket::setTcpNoDelay(bool on)&#123; int optval = on ? 1 : 0; ::setsockopt(sockfd_, IPPROTO_TCP, TCP_NODELAY, &amp;optval, static_cast&lt;socklen_t&gt;(sizeof optval)); // FIXME CHECK&#125;void Socket::setReuseAddr(bool on)&#123; int optval = on ? 1 : 0; ::setsockopt(sockfd_, SOL_SOCKET, SO_REUSEADDR, &amp;optval, static_cast&lt;socklen_t&gt;(sizeof optval)); // FIXME CHECK&#125;void Socket::setReusePort(bool on)&#123;#ifdef SO_REUSEPORT int optval = on ? 1 : 0; int ret = ::setsockopt(sockfd_, SOL_SOCKET, SO_REUSEPORT, &amp;optval, static_cast&lt;socklen_t&gt;(sizeof optval)); if (ret &lt; 0 &amp;&amp; on) &#123; LOG_SYSERR &lt;&lt; "SO_REUSEPORT failed."; &#125;#else if (on) &#123; LOG_ERROR &lt;&lt; "SO_REUSEPORT is not supported."; &#125;#endif&#125;void Socket::setKeepAlive(bool on)&#123; int optval = on ? 1 : 0; ::setsockopt(sockfd_, SOL_SOCKET, SO_KEEPALIVE, &amp;optval, static_cast&lt;socklen_t&gt;(sizeof optval)); // FIXME CHECK&#125; SO_REUSEADDR和SO_REUSEPORTSO_REUSEPORT功能 允许多个套接字 bind()/listen() 同一个TCP/UDP端口每一个线程拥有自己的服务器套接字 在服务器套接字上没有了锁的竞争，因为每个进程一个服务器套接字 内核层面实现负载均衡 安全层面，监听同一个端口的套接字只能位于同一个用户下面 SO_REUSEADDR提供如下四个功能： SO_REUSEADDR允许启动一个监听服务器并捆绑其众所周知端口，即使以前建立的将此端口用做他们的本地端口的连接仍存在。这通常是重启监听服务器时出现，若不设置此选项，则bind时将出错。 SO_REUSEADDR允许在同一端口上启动同一服务器的多个实例，只要每个实例捆绑一个不同的本地IP地址即可。对于TCP，我们根本不可能启动捆绑相同IP地址和相同端口号的多个服务器。 SO_REUSEADDR允许单个进程捆绑同一端口到多个套接口上，只要每个捆绑指定不同的本地IP地址即可。这一般不用于TCP服务器。 SO_REUSEADDR允许完全重复的捆绑：当一个IP地址和端口绑定到某个套接口上时，还允许此IP地址和端口捆绑到另一个套接口上。一般来说，这个特性仅在支持多播的系统上才有，而且只对UDP套接口而言（TCP不支持多播）。 SO_REUSEPORT选项有如下语义： 此选项允许完全重复捆绑，但仅在想捆绑相同IP地址和端口的套接口都指定了此套接口选项才行。 如果被捆绑的IP地址是一个多播地址，则SO_REUSEADDR和SO_REUSEPORT等效。 man12345678SO_REUSEADDR Indicates that the rules used in validating addresses supplied in a bind(2) call should allow reuse of local addresses. For AF_INET sockets this means that a socket may bind, except when there is an active listening socket bound to the address. When the listening socket is bound to INADDR_ANY with a specific port then it is not possible to bind to this port for any local address. Argument is an integer boolean flag. 12SO_REUSEPORT One of the features merged in the 3.9 development cycle was TCP and UDP support for the SO_REUSEPORT socket option; that support was implemented in a series of patches by Tom Herbert. The new socket option allows multiple sockets on the same host to bind to the same port, and is intended to improve the performance of multithreaded network server applications running on top of multicore systems.]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo TcpServer解析]]></title>
    <url>%2F2017%2F06%2F24%2Fmuduo-TcpServer%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[TcpServer简介在tcp网络编程之中，服务器比客户端更容易实现。对应TcpServer的实现，总共不过200多行代码。 核心数据成员： 12typedef std::map&lt;string, TcpConnectionPtr&gt; ConnectionMap;ConnectionMap connections_; TcpServer的使用流程如下所示： 创建TcpServer对象 设置各种回调函数，包括MessageCallback以及ConnectionCallback 设置io的线程数目 开启监听 创建连接当Acceptor成功接受了一个连接之后，会调用newConnection函数。 12345678910111213141516171819202122232425262728void TcpServer::newConnection(int sockfd, const InetAddress&amp; peerAddr)&#123; loop_-&gt;assertInLoopThread(); EventLoop* ioLoop = threadPool_-&gt;getNextLoop(); char buf[64]; snprintf(buf, sizeof buf, "-%s#%d", ipPort_.c_str(), nextConnId_); ++nextConnId_; string connName = name_ + buf; LOG_INFO &lt;&lt; "TcpServer::newConnection [" &lt;&lt; name_ &lt;&lt; "] - new connection [" &lt;&lt; connName &lt;&lt; "] from " &lt;&lt; peerAddr.toIpPort(); InetAddress localAddr(sockets::getLocalAddr(sockfd)); // FIXME poll with zero timeout to double confirm the new connection // FIXME use make_shared if necessary TcpConnectionPtr conn(new TcpConnection(ioLoop, connName, sockfd, localAddr, peerAddr)); connections_[connName] = conn; conn-&gt;setConnectionCallback(connectionCallback_); conn-&gt;setMessageCallback(messageCallback_); conn-&gt;setWriteCompleteCallback(writeCompleteCallback_); conn-&gt;setCloseCallback( std::bind(&amp;TcpServer::removeConnection, this, _1)); // FIXME: unsafe ioLoop-&gt;runInLoop(std::bind(&amp;TcpConnection::connectEstablished, conn));&#125; 从上述代码可见，TcpServer为新的连接对应的sockfd创建了TcpConnection对象，并且设置了各种回调。重点操作是对于负载均衡的处理，TcpServer从EventLoop池中取出一个loop用于处理新的连接对应的io时间，实现了多线程负载均衡服务。在muduo的TcpServer之中，使用专一的loop用来处理接受连接，使用EventLoop池中的loop用来处理与客户端之间的io事件。 移除连接在muduo的TcpServer之中，移除连接需要从对应的io线程之中移除连接，而非接受连接的那个线程。所以，对于removeConnection以及TcpServer的析构函数需要进行特殊处理，将remove操作锁定在连接对应的io线程之中运行。 123456789101112void TcpServer::removeConnectionInLoop(const TcpConnectionPtr&amp; conn)&#123; loop_-&gt;assertInLoopThread(); LOG_INFO &lt;&lt; "TcpServer::removeConnectionInLoop [" &lt;&lt; name_ &lt;&lt; "] - connection " &lt;&lt; conn-&gt;name(); size_t n = connections_.erase(conn-&gt;name()); (void)n; assert(n == 1); EventLoop* ioLoop = conn-&gt;getLoop(); ioLoop-&gt;queueInLoop( std::bind(&amp;TcpConnection::connectDestroyed, conn));&#125; 123456789101112131415TcpServer::~TcpServer()&#123; loop_-&gt;assertInLoopThread(); LOG_TRACE &lt;&lt; "TcpServer::~TcpServer [" &lt;&lt; name_ &lt;&lt; "] destructing"; for (ConnectionMap::iterator it(connections_.begin()); it != connections_.end(); ++it) &#123; TcpConnectionPtr conn = it-&gt;second; it-&gt;second.reset(); conn-&gt;getLoop()-&gt;runInLoop( std::bind(&amp;TcpConnection::connectDestroyed, conn)); conn.reset(); &#125;&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo TcpConnection解析]]></title>
    <url>%2F2017%2F06%2F24%2Fmuduo-TcpConnection%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[TcpConnectionTcpConnection实现了对连接的抽象，连接建立，连接断开，发送数据，接收数据的操作也都封装在其中，其中的难点是对连接关闭的处理。 连接建立123456789101112131415161718192021222324252627TcpConnection::TcpConnection(EventLoop* loop, const string&amp; nameArg, int sockfd, const InetAddress&amp; localAddr, const InetAddress&amp; peerAddr) : loop_(CHECK_NOTNULL(loop)), name_(nameArg), state_(kConnecting), reading_(true), socket_(new Socket(sockfd)), channel_(new Channel(loop, sockfd)), localAddr_(localAddr), peerAddr_(peerAddr), highWaterMark_(64*1024*1024)&#123; channel_-&gt;setReadCallback( std::bind(&amp;TcpConnection::handleRead, this, _1)); channel_-&gt;setWriteCallback( std::bind(&amp;TcpConnection::handleWrite, this)); channel_-&gt;setCloseCallback( std::bind(&amp;TcpConnection::handleClose, this)); channel_-&gt;setErrorCallback( std::bind(&amp;TcpConnection::handleError, this)); LOG_DEBUG &lt;&lt; "TcpConnection::ctor[" &lt;&lt; name_ &lt;&lt; "] at " &lt;&lt; this &lt;&lt; " fd=" &lt;&lt; sockfd; socket_-&gt;setKeepAlive(true);&#125; 从代码中可知，TcpConnection也是基于Channel实现的。在构造函数中记录了loop句柄，使用Socket对象管理sockfd。对于io事件，读事件绑定的回调函数是handleRead函数，写事件绑定的回调函数是handleWrite, close事件绑定的回调函数是handleClose, error事件绑定的回调函数是handleError。同时，在构造函数的末尾开启了socket的keepalive选项。在构造函数之中设置了连接的当前状态是kConnecting，表示正在连接。 连接完成之后，可以通过调用函数connectEstablished来设定当前状态为已经连接并且调用连接所对应的回调函数。 12345678910void TcpConnection::connectEstablished()&#123; loop_-&gt;assertInLoopThread(); assert(state_ == kConnecting); setState(kConnected); channel_-&gt;tie(shared_from_this()); channel_-&gt;enableReading(); // call connection callback function to notify TcpConnectionPtr user connectionCallback_(shared_from_this());&#125; 为了保证Channel在执行TcpConnection中相关io事件的回调函数的过程中，不会因为TcpConnection对象在相关回调调用过程中被析构而造成为channel设定的回调函数失效，这里使用了Channel内置的tie方法记录TcpConnection的weak_ptr，调用回调期间将weak_ptr提升为shared_ptr来保证上述情况不会发生。因为有这种用法，TcpConnection对象必须使用shared_ptr进行管理。 读取数据1234567891011121314151617181920void TcpConnection::handleRead(Timestamp receiveTime)&#123; loop_-&gt;assertInLoopThread(); int savedErrno = 0; ssize_t n = inputBuffer_.readFd(channel_-&gt;fd(), &amp;savedErrno); if (n &gt; 0) &#123; messageCallback_(shared_from_this(), &amp;inputBuffer_, receiveTime); &#125; else if (n == 0) &#123; handleClose(); &#125; else &#123; errno = savedErrno; LOG_SYSERR &lt;&lt; "TcpConnection::handleRead"; handleError(); &#125;&#125; 当有可读事件发生时，调用handleRead函数。若read返回0，代表对方关闭了连接，调用handleClose函数，若read返回值大于0，使用当前时间，inputBuffer以及本对象的shared_ptr调用message回调。 1234567891011121314void TcpConnection::handleClose()&#123; loop_-&gt;assertInLoopThread(); LOG_TRACE &lt;&lt; "fd = " &lt;&lt; channel_-&gt;fd() &lt;&lt; " state = " &lt;&lt; stateToString(); assert(state_ == kConnected || state_ == kDisconnecting); // we don't close fd, leave it to dtor, so we can find leaks easily. setState(kDisconnected); channel_-&gt;disableAll(); TcpConnectionPtr guardThis(shared_from_this()); connectionCallback_(guardThis); // must be the last line closeCallback_(guardThis);&#125; handleClose之中将当前状态设置为DisConnected, channel不再关注任何io事件，调用connection以及close回调通知TcpConnection对象的所有者，连接已经关闭了。 需要留意的是，在调用close回调的时候，可能TcpConnection的所有者就直接将TcpConnection 丢弃，因而这里做了guard处理。 写入数据我们一定要保证所有的io操作都需要在io线程之中完成，这样才能实现线程安全。数据的发送主要分为两种情况，一种是当前没有数据要发送，那么首先在io线程中尝试发送，将剩余没有发送的数据存入outputBuffer，关注可写事件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354void TcpConnection::sendInLoop(const void* data, size_t len)&#123; loop_-&gt;assertInLoopThread(); ssize_t nwrote = 0; size_t remaining = len; bool faultError = false; if (state_ == kDisconnected) &#123; LOG_WARN &lt;&lt; "disconnected, give up writing"; return; &#125; // if no thing in output queue, try writing directly if (!channel_-&gt;isWriting() &amp;&amp; outputBuffer_.readableBytes() == 0) &#123; nwrote = sockets::write(channel_-&gt;fd(), data, len); if (nwrote &gt;= 0) &#123; remaining = len - nwrote; if (remaining == 0 &amp;&amp; writeCompleteCallback_) &#123; loop_-&gt;queueInLoop(std::bind(writeCompleteCallback_, shared_from_this())); &#125; &#125; else // nwrote &lt; 0 &#123; nwrote = 0; if (errno != EWOULDBLOCK) &#123; LOG_SYSERR &lt;&lt; "TcpConnection::sendInLoop"; if (errno == EPIPE || errno == ECONNRESET) // FIXME: any others? &#123; faultError = true; &#125; &#125; &#125; &#125; assert(remaining &lt;= len); if (!faultError &amp;&amp; remaining &gt; 0) &#123; size_t oldLen = outputBuffer_.readableBytes(); if (oldLen + remaining &gt;= highWaterMark_ &amp;&amp; oldLen &lt; highWaterMark_ &amp;&amp; highWaterMarkCallback_) &#123; loop_-&gt;queueInLoop(std::bind(highWaterMarkCallback_, shared_from_this(), oldLen + remaining)); &#125; outputBuffer_.append(static_cast&lt;const char*&gt;(data)+nwrote, remaining); if (!channel_-&gt;isWriting()) &#123; channel_-&gt;enableWriting(); &#125; &#125; &#125; 请注意，这里有对高水位回调函数的调用，高水位回调函数在outputBuffer的size大于HighWaterMark_的时候会被调用。 123456789101112131415161718192021222324252627282930313233343536373839void TcpConnection::handleWrite()&#123; loop_-&gt;assertInLoopThread(); if (channel_-&gt;isWriting()) &#123; ssize_t n = sockets::write(channel_-&gt;fd(), outputBuffer_.peek(), outputBuffer_.readableBytes()); if (n &gt; 0) &#123; outputBuffer_.retrieve(n); if (outputBuffer_.readableBytes() == 0) &#123; channel_-&gt;disableWriting(); if (writeCompleteCallback_) &#123; loop_-&gt;queueInLoop(std::bind(writeCompleteCallback_, shared_from_this())); &#125; if (state_ == kDisconnecting) &#123; shutdownInLoop(); &#125; &#125; &#125; else &#123; LOG_SYSERR &lt;&lt; "TcpConnection::handleWrite"; // if (state_ == kDisconnecting) // &#123; // shutdownInLoop(); // &#125; &#125; &#125; else &#123; LOG_TRACE &lt;&lt; "Connection fd = " &lt;&lt; channel_-&gt;fd() &lt;&lt; " is down, no more writing"; &#125;&#125; 在handleWrite中继续发送剩余的数据，当发送完毕之后，会调用WriteComplete回调函数，通知TcpConnection所有者所有数据都已发送完毕。发送完所有数据会不再关注可写事件，否则会造成busy loop。 连接关闭关闭连接不可直接close对应的sockfd，否则积压在链路中未被对方应用程序接收的数据可能丢失。对此muduo的处理是首先shutdown write。关闭写之后，对方read就会返回0，此时对方就会关闭连接，这样本地sockfd就会read返回0，此时调用handleClose完成最终的连接关闭操作。这种主动的连接关闭策略是一种比较文雅的关闭方式，能够保证链路中的数据能够被对方完整的接收到。 123456789void TcpConnection::shutdownInLoop()&#123; loop_-&gt;assertInLoopThread(); if (!channel_-&gt;isWriting()) &#123; // we are not writing socket_-&gt;shutdownWrite(); &#125;&#125; 对应文雅的连接关闭方式，也有比较粗暴的连接关闭手段，那就是直接forceClose。forceClose的操作和对方关闭连接导致本地连接read返回0的操作其实是一致的。 123456789void TcpConnection::forceCloseInLoop()&#123; loop_-&gt;assertInLoopThread(); if (state_ == kConnected || state_ == kDisconnecting) &#123; // as if we received 0 byte in handleRead(); handleClose(); &#125;&#125; TcpConnection对象的主要使用者是TcpServer和TcpClient，当TcpServer对象被析构的时候，其所拥有的所有连接对象也应该被析构。但是没有那么简单，我们需要保证TcpConnection对象在析构的时候，其对应的Channel也从Poller之中移除了。 123456789101112void TcpConnection::connectDestroyed()&#123; loop_-&gt;assertInLoopThread(); if (state_ == kConnected) &#123; setState(kDisconnected); channel_-&gt;disableAll(); connectionCallback_(shared_from_this()); &#125; channel_-&gt;remove();&#125; 因而TcpServer在析构的时候，会对他所拥有的所有TcpConnection逐一调用connectDestroyed，保证所有的channel都被正确移除了。 当然，在TcpServer移除连接的时候，也会做上述处理。]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo TcpClient解析]]></title>
    <url>%2F2017%2F06%2F24%2Fmuduo-TcpClient%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介TcpClient是muduo网络库中提供的用于创建tcp连接的类。 TcpClient的主要操作主要是借助Connector来实现的。 连接建立创建新连接操作： 1234567891011121314151617181920212223242526272829void TcpClient::newConnection(int sockfd)&#123; loop_-&gt;assertInLoopThread(); InetAddress peerAddr(sockets::getPeerAddr(sockfd)); char buf[32]; snprintf(buf, sizeof buf, ":%s#%d", peerAddr.toIpPort().c_str(), nextConnId_); ++nextConnId_; string connName = name_ + buf; InetAddress localAddr(sockets::getLocalAddr(sockfd)); // FIXME poll with zero timeout to double confirm the new connection // FIXME use make_shared if necessary TcpConnectionPtr conn(new TcpConnection(loop_, connName, sockfd, localAddr, peerAddr)); conn-&gt;setConnectionCallback(connectionCallback_); conn-&gt;setMessageCallback(messageCallback_); conn-&gt;setWriteCompleteCallback(writeCompleteCallback_); conn-&gt;setCloseCallback( std::bind(&amp;TcpClient::removeConnection, this, _1)); // FIXME: unsafe &#123; MutexLockGuard lock(mutex_); connection_ = conn; &#125; conn-&gt;connectEstablished();&#125; 连接建立成功之后，会创建TcpConnectionPtr，并且做好记录。在close回调之中，TcpClient首先移除了连接，然后调用了connectDestroyed方法来将连接对应的channel从poller之中移除。若设定为需要重试，那么removeConnection还会重启Connector，重新进行连接。 12345678910111213141516171819void TcpClient::removeConnection(const TcpConnectionPtr&amp; conn)&#123; loop_-&gt;assertInLoopThread(); assert(loop_ == conn-&gt;getLoop()); &#123; MutexLockGuard lock(mutex_); assert(connection_ == conn); connection_.reset(); &#125; loop_-&gt;queueInLoop(std::bind(&amp;TcpConnection::connectDestroyed, conn)); if (retry_ &amp;&amp; connect_) &#123; LOG_INFO &lt;&lt; "TcpClient::connect[" &lt;&lt; name_ &lt;&lt; "] - Reconnecting to " &lt;&lt; connector_-&gt;serverAddress().toIpPort(); connector_-&gt;restart(); &#125;&#125; 若要关闭连接，则首先判断TcpClient的TcpConnectionPtr是否有效，有效就关闭连接，并且设置connect_为false，TcpClient不再进行重试。因为可能会涉及到跨线程调用，所以在修改TcpConnectionPtr的时候会使用锁进行保护，确保线程安全。 TcpClient的析构函数首先列出一下TcpClient对象的析构函数的代码： 123456789101112131415161718192021222324252627282930TcpClient::~TcpClient()&#123; LOG_INFO &lt;&lt; "TcpClient::~TcpClient[" &lt;&lt; name_ &lt;&lt; "] - connector " &lt;&lt; get_pointer(connector_); TcpConnectionPtr conn; bool unique = false; &#123; MutexLockGuard lock(mutex_); unique = connection_.unique(); conn = connection_; &#125; if (conn) &#123; assert(loop_ == conn-&gt;getLoop()); // FIXME: not 100% safe, if we are in different thread CloseCallback cb = std::bind(&amp;detail::removeConnection, loop_, _1); loop_-&gt;runInLoop( std::bind(&amp;TcpConnection::setCloseCallback, conn, cb)); if (unique) &#123; conn-&gt;forceClose(); &#125; &#125; else &#123; connector_-&gt;stop(); // FIXME: HACK loop_-&gt;runAfter(1, std::bind(&amp;detail::removeConnector, connector_)); &#125;&#125; 可见TcpClient对象的析构函数实现比较复杂，问题的核心在于TcpConnection中的close回调调用的是TcpClient的removeConnection方法，当TcpClient对象析构之后，这一回调也就失效了。所以在析构函数中要将TcpConnection的closeCallback调整为TcpConnection中的connectDestroyed。若用户程序没有保留TcpConnectionPtr，那么就可以简单粗暴的关闭连接。否则，不能关闭连接，以保证用户程序能够继续使用。]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb杂项]]></title>
    <url>%2F2017%2F06%2F24%2Fleveldb%E6%9D%82%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[slice在leveldb内部使用中，使用了内置的类型Slice用来表示字符串。Slice可以和const char*, string之间相互转换，是一种比较轻量级的字符串表示方式。Slice类似muduo之中的StringPiece数据类型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596//// Created by zy on 17-5-22.//#pragma once#include &lt;assert.h&gt;#include &lt;stddef.h&gt;#include &lt;string.h&gt;#include &lt;string&gt;namespace leveldb &#123;class Slice &#123; public: // Create an empty slice. Slice() : data_(""), size_(0) &#123; &#125; // Create a slice that refers to d[0,n-1]. Slice(const char* d, size_t n) : data_(d), size_(n) &#123; &#125; // Create a slice that refers to the contents of "s" Slice(const std::string&amp; s) : data_(s.data()), size_(s.size()) &#123; &#125; // Create a slice that refers to s[0,strlen(s)-1] Slice(const char* s) : data_(s), size_(strlen(s)) &#123; &#125; // Return a pointer to the beginning of the referenced data const char* data() const &#123; return data_; &#125; // Return the length (in bytes) of the referenced data size_t size() const &#123; return size_; &#125; // Return true iff the length of the referenced data is zero bool empty() const &#123; return size_ == 0; &#125; // Return the ith byte in the referenced data. // REQUIRES: n &lt; size() char operator[](size_t n) const &#123; assert(n &lt; size()); return data_[n]; &#125; // Change this slice to refer to an empty array void clear() &#123; data_ = ""; size_ = 0; &#125; // Drop the first "n" bytes from this slice. void remove_prefix(size_t n) &#123; assert(n &lt;= size()); data_ += n; size_ -= n; &#125; // Return a string that contains the copy of the referenced data. std::string ToString() const &#123; return std::string(data_, size_); &#125; // Three-way comparison. Returns value: // &lt; 0 iff "*this" &lt; "b", // == 0 iff "*this" == "b", // &gt; 0 iff "*this" &gt; "b" int compare(const Slice&amp; b) const; // Return true iff "x" is a prefix of "*this" bool starts_with(const Slice&amp; x) const &#123; return ((size_ &gt;= x.size_) &amp;&amp; (memcmp(data_, x.data_, x.size_) == 0)); &#125; private: const char* data_; size_t size_; // Intentionally copyable&#125;;inline bool operator==(const Slice&amp; x, const Slice&amp; y) &#123; return ((x.size() == y.size()) &amp;&amp; (memcmp(x.data(), y.data(), x.size()) == 0));&#125;inline bool operator!=(const Slice&amp; x, const Slice&amp; y) &#123; return !(x == y);&#125;inline int Slice::compare(const Slice&amp; b) const &#123; const size_t min_len = (size_ &lt; b.size_) ? size_ : b.size_; int r = memcmp(data_, b.data_, min_len); if (r == 0) &#123; if (size_ &lt; b.size_) r = -1; else if (size_ &gt; b.size_) r = +1; &#125; return r;&#125;&#125; // namespace leveldb Status在leveldb中，使用自定义类型Status来表示当前状态。Status内部数据成员如下所示： 123456// OK status has a NULL state_. Otherwise, state_ is a new[] array // of the following form: // state_[0..3] == length of message // state_[4] == code // state_[5..] == message const char* state_; 可见这是一种非常精简的数据表示方式，使用const char* state_存储一些复合的数据，包括状态码，字符串长度，字符串。这种表示方式简单明了，可以借鉴。特别是如果当前状态为kOk，那么state_设定为NULL，这样充分节省了空间(因为状态除非出错，一般都为kOk)。 Status具体实现非常简单，以下仅贴出代码说明: status.h 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#pragma once#include &lt;string&gt;#include "leveldb/slice.h"namespace leveldb &#123;class Status &#123; public: // Create a success status. Status() : state_(NULL) &#123; &#125; ~Status() &#123; delete[] state_; &#125; // Copy the specified status. Status(const Status&amp; s); void operator=(const Status&amp; s); // Return a success status. static Status OK() &#123; return Status(); &#125; // Return error status of an appropriate type. static Status NotFound(const Slice&amp; msg, const Slice&amp; msg2 = Slice()) &#123; return Status(kNotFound, msg, msg2); &#125; static Status Corruption(const Slice&amp; msg, const Slice&amp; msg2 = Slice()) &#123; return Status(kCorruption, msg, msg2); &#125; static Status NotSupported(const Slice&amp; msg, const Slice&amp; msg2 = Slice()) &#123; return Status(kNotSupported, msg, msg2); &#125; static Status InvalidArgument(const Slice&amp; msg, const Slice&amp; msg2 = Slice()) &#123; return Status(kInvalidArgument, msg, msg2); &#125; static Status IOError(const Slice&amp; msg, const Slice&amp; msg2 = Slice()) &#123; return Status(kIOError, msg, msg2); &#125; // Returns true iff the status indicates success. bool ok() const &#123; return (state_ == NULL); &#125; // Returns true iff the status indicates a NotFound error. bool IsNotFound() const &#123; return code() == kNotFound; &#125; // Returns true iff the status indicates a Corruption error. bool IsCorruption() const &#123; return code() == kCorruption; &#125; // Returns true iff the status indicates an IOError. bool IsIOError() const &#123; return code() == kIOError; &#125; // Returns true iff the status indicates a NotSupportedError. bool IsNotSupportedError() const &#123; return code() == kNotSupported; &#125; // Returns true iff the status indicates an InvalidArgument. bool IsInvalidArgument() const &#123; return code() == kInvalidArgument; &#125; // Return a string representation of this status suitable for printing. // Returns the string "OK" for success. std::string ToString() const; private: // OK status has a NULL state_. Otherwise, state_ is a new[] array // of the following form: // state_[0..3] == length of message // state_[4] == code // state_[5..] == message const char* state_; enum Code &#123; kOk = 0, kNotFound = 1, kCorruption = 2, kNotSupported = 3, kInvalidArgument = 4, kIOError = 5 &#125;; Code code() const &#123; return (state_ == NULL) ? kOk : static_cast&lt;Code&gt;(state_[4]); &#125; Status(Code code, const Slice&amp; msg, const Slice&amp; msg2); static const char* CopyState(const char* s);&#125;;inline Status::Status(const Status&amp; s) &#123; state_ = (s.state_ == NULL) ? NULL : CopyState(s.state_);&#125;inline void Status::operator=(const Status&amp; s) &#123; // The following condition catches both aliasing (when this == &amp;s), // and the common case where both s and *this are ok. if (state_ != s.state_) &#123; delete[] state_; state_ = (s.state_ == NULL) ? NULL : CopyState(s.state_); &#125;&#125;&#125; // namespace leveldb status.cc 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include "port/port.h"#include "leveldb/status.h"namespace leveldb&#123;// 4byte 1byte message......// length code message contentsconst char *Status::CopyState(const char *state)&#123; uint32_t size; memcmp(&amp;size, state, sizeof(size)); char *result = new char[size + 5]; memcpy(result, state, size + 5); return result;&#125;Status::Status(Code code, const Slice &amp;msg, const Slice &amp;msg2)&#123; assert(code != kOk); const uint32_t len1 = msg.size(); const uint32_t len2 = msg2.size(); const uint32_t size = len1 + (len2 ? (2 + len2) : 0); char *result = new char[size + 5]; memcpy(result, &amp;size, sizeof(size)); result[4] = static_cast&lt;char&gt;(code); memcpy(result + 5, msg.data(), len1); if (len2) &#123; result[5 + len1] = ':'; result[6 + len1] = ' '; memcpy(result + 7 + len1, msg2.data(), len2); &#125; state_ = result;&#125;std::string Status::ToString() const&#123; if (state_ == NULL) &#123; return "OK"; &#125; else &#123; char tmp[30]; const char *type; switch (code()) &#123; case kOk:type = "OK"; break; case kNotFound:type = "NotFound: "; break; case kCorruption:type = "Corruption: "; break; case kNotSupported:type = "Not implemented: "; break; case kInvalidArgument:type = "Invalid argument: "; break; case kIOError:type = "IO error: "; break; default: snprintf(tmp, sizeof(tmp), "Unknown code(%d): ", static_cast&lt;int&gt;(code())); type = tmp; break; &#125; std::string result(type); uint32_t length; memcpy(&amp;length, state_, sizeof(length)); result.append(state_ + 5, length); return result; &#125;&#125;&#125; // namespace leveldb hash在leveldb内部实现之中，hash采用的是murmur hash算法，这种hash实现能够最大化减小hash碰撞，值得学习。 123456789101112131415161718192021222324252627282930uint32_t Hash(const char* data, size_t n, uint32_t seed) &#123; // Similar to murmur hash const uint32_t m = 0xc6a4a793; const uint32_t r = 24; const char* limit = data + n; uint32_t h = seed ^ (n * m); // Pick up four bytes at a time while (data + 4 &lt;= limit) &#123; uint32_t w = DecodeFixed32(data); data += 4; h += w; h *= m; h ^= (h &gt;&gt; 16); &#125; // Pick up remaining bytes switch (limit - data) &#123; case 3: h += static_cast&lt;unsigned char&gt;(data[2]) &lt;&lt; 16; case 2: h += static_cast&lt;unsigned char&gt;(data[1]) &lt;&lt; 8; case 1: h += static_cast&lt;unsigned char&gt;(data[0]); h *= m; h ^= (h &gt;&gt; r); break; &#125; return h;&#125; 至此，leveldb util相关的代码分析完毕，下面转入对table定义的分析。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb env解读]]></title>
    <url>%2F2017%2F06%2F24%2Fleveldb-env%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[创建Env对象在leveldb之中，创建默认的env对象使用的是pthread_once操作保证初始化操作只执行一次。此操作可以用来实现singleton。 12345static void InitDefaultEnv() &#123; default_env = new PosixEnv; &#125;Env* Env::Default() &#123; pthread_once(&amp;once, InitDefaultEnv); return default_env;&#125; 简单的任务调度在PosixEnv中，实现了一个简单的任务调度，实质上是一个基于多生产者，单消费者的任务调度，生产者与消费者之间通过阻塞队列完成任务的传递分发。 123456789101112131415161718192021222324void PosixEnv::Schedule(void (*function)(void*), void* arg) &#123; PthreadCall("lock", pthread_mutex_lock(&amp;mu_)); // Start background thread if necessary if (!started_bgthread_) &#123; started_bgthread_ = true; PthreadCall( "create thread", pthread_create(&amp;bgthread_, NULL, &amp;PosixEnv::BGThreadWrapper, this)); &#125; // If the queue is currently empty, the background thread may currently be // waiting. if (queue_.empty()) &#123; PthreadCall("signal", pthread_cond_signal(&amp;bgsignal_)); &#125; // Add to priority queue queue_.push_back(BGItem()); queue_.back().function = function; queue_.back().arg = arg; PthreadCall("unlock", pthread_mutex_unlock(&amp;mu_));&#125; 在schedule之中，如果没有创建后台线程，会创建一个后台线程用于处理任务。后台线程会执行BGThread函数，在此函数之内循环从阻塞队列中取出任务，执行任务对应的函数。 12345678910111213141516void PosixEnv::BGThread() &#123; while (true) &#123; // Wait until there is an item that is ready to run PthreadCall("lock", pthread_mutex_lock(&amp;mu_)); while (queue_.empty()) &#123; PthreadCall("wait", pthread_cond_wait(&amp;bgsignal_, &amp;mu_)); &#125; void (*function)(void*) = queue_.front().function; void* arg = queue_.front().arg; queue_.pop_front(); PthreadCall("unlock", pthread_mutex_unlock(&amp;mu_)); (*function)(arg); &#125;&#125; 一些系统调用查看文件是否存在123virtual bool FileExists(const std::string&amp; fname) &#123; return access(fname.c_str(), F_OK) == 0;&#125; 获取文件大小1234567891011virtual Status GetFileSize(const std::string&amp; fname, uint64_t* size) &#123; Status s; struct stat sbuf; if (stat(fname.c_str(), &amp;sbuf) != 0) &#123; *size = 0; s = IOError(fname, errno); &#125; else &#123; *size = sbuf.st_size; &#125; return s; &#125; 重命名文件1234567virtual Status RenameFile(const std::string&amp; src, const std::string&amp; target) &#123; Status result; if (rename(src.c_str(), target.c_str()) != 0) &#123; result = IOError(src, errno); &#125; return result; &#125; 获取路径中的内容1234567891011121314virtual Status GetChildren(const std::string&amp; dir, std::vector&lt;std::string&gt;* result) &#123; result-&gt;clear(); DIR* d = opendir(dir.c_str()); if (d == NULL) &#123; return IOError(dir, errno); &#125; struct dirent* entry; while ((entry = readdir(d)) != NULL) &#123; result-&gt;push_back(entry-&gt;d_name); &#125; closedir(d); return Status::OK();&#125; 锁定文件12345678910static int LockOrUnlock(int fd, bool lock) &#123; errno = 0; struct flock f; memset(&amp;f, 0, sizeof(f)); f.l_type = (lock ? F_WRLCK : F_UNLCK); f.l_whence = SEEK_SET; f.l_start = 0; f.l_len = 0; // Lock/unlock entire file return fcntl(fd, F_SETLK, &amp;f);&#125; sync 文件123456789101112virtual Status Sync() &#123; // Ensure new files referred to by the manifest are in the filesystem. Status s = SyncDirIfManifest(); if (!s.ok()) &#123; return s; &#125; if (fflush_unlocked(file_) != 0 || fdatasync(fileno(file_)) != 0) &#123; s = Status::IOError(filename_, strerror(errno)); &#125; return s; &#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb coding解读]]></title>
    <url>%2F2017%2F06%2F24%2Fleveldb-coding%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[leveldb coding解读这一节的重点主要围绕varint，varint是一个变长的int数表示方法，他利用每个byte的第一位来记录后面是否还有byte来组成这个int数。若byte的第一位为1，表示后面还有byte来组成这个数，否则说明此byte是组成int数的最后一个byte。如果用于存储比较小的数，使用varint比使用int更节省空间，在protobuf之中也使用了varint。 下面是EncodeVarint32的操作步骤：123456789101112131415161718192021222324252627282930313233char* EncodeVarint32(char* dst, uint32_t v) &#123; // Operate on characters as unsigneds unsigned char* ptr = reinterpret_cast&lt;unsigned char*&gt;(dst); static const int B = 128; if (v &lt; (1&lt;&lt;7)) &#123; *(ptr++) = v; &#125; else if (v &lt; (1&lt;&lt;14)) &#123; *(ptr++) = v | B; *(ptr++) = v&gt;&gt;7; &#125; else if (v &lt; (1&lt;&lt;21)) &#123; *(ptr++) = v | B; *(ptr++) = (v&gt;&gt;7) | B; *(ptr++) = v&gt;&gt;14; &#125; else if (v &lt; (1&lt;&lt;28)) &#123; *(ptr++) = v | B; *(ptr++) = (v&gt;&gt;7) | B; *(ptr++) = (v&gt;&gt;14) | B; *(ptr++) = v&gt;&gt;21; &#125; else &#123; *(ptr++) = v | B; *(ptr++) = (v&gt;&gt;7) | B; *(ptr++) = (v&gt;&gt;14) | B; *(ptr++) = (v&gt;&gt;21) | B; *(ptr++) = v&gt;&gt;28; &#125; return reinterpret_cast&lt;char*&gt;(ptr);&#125;void PutVarint32(std::string* dst, uint32_t v) &#123; char buf[5]; char* ptr = EncodeVarint32(buf, v); dst-&gt;append(buf, ptr - buf);&#125; 下面是DecodeVarint32的操作： 12345678910111213141516const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* value) &#123; uint64_t result = 0; for (uint32_t shift = 0; shift &lt;= 63 &amp;&amp; p &lt; limit; shift += 7) &#123; uint64_t byte = *(reinterpret_cast&lt;const unsigned char*&gt;(p)); p++; if (byte &amp; 128) &#123; // More bytes are present result |= ((byte &amp; 127) &lt;&lt; shift); &#125; else &#123; result |= (byte &lt;&lt; shift); *value = result; return reinterpret_cast&lt;const char*&gt;(p); &#125; &#125; return NULL;&#125; varint64的相关操作与此类似，省略。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb cache解读]]></title>
    <url>%2F2017%2F06%2F24%2Fleveldb-cache%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[leveldb cache 解读简介在leveldb之中，实现了一个基于hash table和双向循环链表的cache。每个cache的结构如下所示: 123456789101112131415161718192021222324252627282930struct LRUHandle&#123; // pointer to value void *value; // destructor function void (*deleter)(const Slice &amp;, void *value); LRUHandle *next_hash; // point to next hash elem LRUHandle *next; // linked list pointer LRUHandle *prev; // linked list pointer size_t charge; size_t key_length; bool in_cache; // whether entry is in the cache uint32_t refs; // references, including cache reference, if present. uint32_t hash; // Hash of key(); used for fast sharding and comparisons char key_data[1]; // beginning of key. Slice key() const &#123; // for cheapter lookups, we allow a temporary Handle object // to store a pointer to a key in "value". if (next == this) &#123; return *(reinterpret_cast&lt;Slice *&gt;(value)); &#125; else &#123; return Slice(key_data, key_length); &#125; &#125;&#125;; HashTable作者实现了一个hashTable，和stl一样，此hash table是基于开链hash实现，并且负载系数限制在1以内，如果负载因子超过此限制，就会扩充hash table的容量，并进行rehash处理。 hash table的查找操作如下所示: 其实就是找到对应hash的链表，依次遍历链表直到找到key完全一致的元素。如果找不到，会返回NULL。 12345678910111213// return a pointer to slot that points to a cache entry that // matches key/hash. If there is no such cache entry, return // a pointer to the trailing slot in the corresponding linked list. LRUHandle **FindPointer(const Slice &amp;key, uint32_t hash) &#123; LRUHandle **ptr = &amp;list_[hash &amp; (length_ - 1)]; // 开链 while ((*ptr != NULL) &amp;&amp; ((*ptr)-&gt;hash != hash || key != (*ptr)-&gt;key())) &#123; ptr = &amp;(*ptr)-&gt;next_hash; &#125; return ptr; &#125; insert操作是找到对应hash值的链表，将其插入链表的头部。当然，需要检查负载系数，负载系数超过1需要进行resize。 123456789101112131415161718LRUHandle *Insert(LRUHandle *h)&#123; LRUHandle **ptr = FindPointer(h-&gt;key(), h-&gt;hash); LRUHandle *old = *ptr; h-&gt;next_hash = (old == NULL ? NULL : old-&gt;next_hash); *ptr = h; if (old == NULL) &#123; ++elems_; if (elems_ &gt; length_) &#123; // Since each entry is fairly large, we aim for a small // average linked list length (&lt;= 1). Resize(); &#125; &#125; return old;&#125; Remove操作是将找到的元素从hash链表中删除，并且更新元素的数目。 123456789101112// remove from hash tableLRUHandle *Remove(const Slice &amp;key, uint32_t hash)&#123; LRUHandle **ptr = FindPointer(key, hash); LRUHandle *result = *ptr; if (result != NULL) &#123; *ptr = result-&gt;next_hash; --elems_; &#125; return result;&#125; Resize操作和vector一样，容量扩充的倍数为2。创建新的容量的hash table之后，要将原有的元素根据hash table的原则链接到正确的位置之上。 1234567891011121314151617181920212223242526272829303132void Resize()&#123; uint32_t new_length = 4; while (new_length &lt; elems_) &#123; new_length *= 2; &#125; LRUHandle **new_list = new LRUHandle *[new_length]; memset(new_list, 0, sizeof(new_list[0]) * new_length); uint32_t count = 0; // rehash hash table for (uint32_t i = 0; i &lt; length_; i++) &#123; LRUHandle *h = list_[i]; while (h != NULL) &#123; LRUHandle *next = h-&gt;next_hash; uint32_t hash = h-&gt;hash; LRUHandle **ptr = &amp;new_list[hash &amp; (new_length - 1)]; // link new hash item to the header h-&gt;next_hash = *ptr; *ptr = h; // now to handle next hash item h = next; count++; &#125; &#125; assert(elems_ == count); delete[] list_; list_ = new_list; length_ = new_length;&#125; LRUCache在LRUCache之中，使用hashTable存放key与对应cache块之间的对应关系。并且在此类中还有两个双向循环链表，其中in_use_链表存放用户正在使用的cache，这一部分数据不可以被销毁。lru_链表存放用户没有使用的cache，从lru_-&gt;prev 到lru_-&gt;next表示使用的先后关系，越在前面，表示越近被使用。lru_和in_use_是一个dummy node，简化了链表的实现，便于快速定位链表的头部和尾部。 Ref操作表示对cache的引用操作，会将其引用计数加1，如果当前cache块在lru_链表之中，会将其转移到in_use_链表之中，防止被LRU操作清除。 12345678910void LRUCache::Ref(LRUHandle *e)&#123; if (e-&gt;refs == 1 &amp;&amp; e-&gt;in_cache) // if on lru_ list, move to in_use_ list &#123; LRU_Remove(e); // now in use list LRU_Append(&amp;in_use_, e); &#125; e-&gt;refs++;&#125; 而UnRef操作会减小cache的引用计数，若cache的引用计数降为1，表示cache从链表中删除了，会调用deleter函数之后，将其从内存释放。若用户将此块完全释放，会将其转移到lru_链表之中。 12345678910111213141516void LRUCache::UnRef(LRUHandle *e)&#123; assert(e-&gt;refs &gt; 0); e-&gt;refs--; if (e-&gt;refs == 0) // Deallocate. &#123; assert(!e-&gt;in_cache); (*e-&gt;deleter)(e-&gt;key(), e-&gt;value); free(e); &#125; else if (e-&gt;in_cache &amp;&amp; e-&gt;refs == 1) // no longer in use; move to lru_ list &#123; LRU_Remove(e); LRU_Append(&amp;lru_, e); &#125;&#125; LRUCache的插入操作会将其插入lru_链表的开头位置。若插入之后cache的容量超限，会将最近没有使用的块按照时间顺序依次清除，最先清除使用时间间隔最长的块。 12345678910111213141516171819202122232425262728293031323334353637383940Cache::Handle *LRUCache::Insert(const Slice &amp;key, uint32_t hash, void *value, size_t charge, void (*deleter)(const Slice &amp;, void *))&#123; MutexLock l(&amp;mutex_); LRUHandle *e = reinterpret_cast&lt;LRUHandle *&gt;(malloc(sizeof(LRUHandle) - 1 + key.size())); e-&gt;value = value; e-&gt;deleter = deleter; e-&gt;charge = charge; e-&gt;key_length = key.size(); e-&gt;hash = hash; e-&gt;in_cache = false; e-&gt;refs = 1; memcpy(e-&gt;key_data, key.data(), key.size()); if (capacity_ &gt; 0) &#123; e-&gt;refs++; // for the cache's reference e-&gt;in_cache = true; // append into use list LRU_Append(&amp;in_use_, e); usage_ += charge; FinishErase(table_.Insert(e)); &#125; // else don't cache // erase from cache list while (usage_ &gt; capacity_ &amp;&amp; lru_.next != &amp;lru_) &#123; LRUHandle *old = lru_.next; assert(old-&gt;refs == 1); bool erased = FinishErase(table_.Remove(old-&gt;key(), old-&gt;hash)); if (!erased) // to avoid unused variable when compiled NDEBUG &#123; assert(erased); &#125; &#125; return reinterpret_cast&lt;Cache::Handle *&gt;(e);&#125; Erase操作则是删除对应key和hash值的cache，从链表之中剥离，并进行UnRef操作。 123456789101112131415161718192021void LRUCache::Erase(const Slice &amp;key, uint32_t hash)&#123; MutexLock l(&amp;mutex_); // erase from hash table FinishErase(table_.Remove(key, hash));&#125;// if e != NULL, finish removing *e from the cache; it has already been removed// from the hash table. return whether e != NULL. Requires mutex_ held.bool LRUCache::FinishErase(LRUHandle *e)&#123; if (e != NULL) &#123; assert(e-&gt;in_cache); LRU_Remove(e); e-&gt;in_cache = false; usage_ -= e-&gt;charge; UnRef(e); &#125; return e != NULL;&#125; Prune操作是删除lru_链表之中的所有cache。 1234567891011121314void LRUCache::Prune()&#123; MutexLock l(&amp;mutex_); while (lru_.next != &amp;lru_) &#123; LRUHandle *e = lru_.next; assert(e-&gt;refs == 1); bool erased = FinishErase(table_.Remove(e-&gt;key(), e-&gt;hash)); if (!erased) &#123; assert(erased); &#125; &#125;&#125; ShardedLRUCache最终，leveldb采用的是ShardedLRUCache, 它由16个LRUCache组成，根据hash值的头4位将任务划分给对应的LRUCache进行。 1234Cache* NewLRUCache(size_t capacity)&#123; return new ShardedLRUCache(capacity);&#125; 其具体实现很简单，下面简单贴出代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889static const int kNumShardBits = 4;static const int kNumShards = 1 &lt;&lt; kNumShardBits;class ShardedLRUCache : public Cache&#123; private: LRUCache shard_[kNumShards]; port::Mutex id_mutex_; uint64_t last_id_; // get hash value static inline uint32_t HashSlice(const Slice &amp;s) &#123; return Hash(s.data(), s.size(), 0); &#125; // in which bucket ? hash &gt;&gt; 28 static uint32_t Shard(uint32_t hash) &#123; return hash &gt;&gt; (32 - kNumShardBits); &#125; public: explicit ShardedLRUCache(size_t capacity) : last_id_(0) &#123; const size_t per_shard = (capacity + (kNumShards - 1)) / kNumShards; for (int s = 0; s &lt; kNumShards; s++) &#123; shard_[s].SetCapacity(per_shard); &#125; &#125; virtual ~ShardedLRUCache() &#123;&#125; virtual Handle *Insert(const Slice &amp;key, void *value, size_t charge, void(*deleter)(const Slice &amp;key, void *value)) &#123; const uint32_t hash = HashSlice(key); return shard_[Shard(hash)].Insert(key, hash, value, charge, deleter); &#125; virtual Handle *Lookup(const Slice &amp;key) &#123; const uint32_t hash = HashSlice(key); return shard_[Shard(hash)].Lookup(key, hash); &#125; virtual void Release(Handle *handle) &#123; LRUHandle *h = reinterpret_cast&lt;LRUHandle *&gt;(handle); shard_[Shard(h-&gt;hash)].Release(handle); &#125; virtual void Erase(const Slice&amp; key) &#123; const uint32_t hash = HashSlice(key); shard_[Shard(hash)].Erase(key, hash); &#125; virtual void *Value(Handle *handle) &#123; return reinterpret_cast&lt;LRUHandle *&gt;(handle)-&gt;value; &#125; virtual uint64_t NewId() &#123; MutexLock l(&amp;id_mutex_); return ++(last_id_); &#125; virtual void Prune() &#123; for (int s = 0; s &lt; kNumShards; s++) &#123; shard_[s].Prune(); &#125; &#125; virtual size_t TotalCharge() const &#123; size_t total = 0; for (int s = 0; s &lt; kNumShards; s++) &#123; total += shard_[s].TotalCharge(); &#125; return total; &#125;&#125;;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb compaction分析]]></title>
    <url>%2F2017%2F06%2F24%2Fleveldb-compaction%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介在leveldb中，为了保证读操作能够访问更少的sstable文件，倾向于将sstable从低的level推向高的level。level为0的sstable之间可能key的范围有重叠，而其他level上的文件的key的范围没有重叠。level从低到高，其空间限制也由小到大，更高的level允许容纳更多的sstable文件。当某个level上的sstable文件空间超出限定值，或者在访问过程中遇到的某个key与两个以上level的文件范围发生重叠，且达到一定阈值，都会进行compaction操作。当然，compaction操作也允许手动启动，db在启动的时候也会主动触发compaction操作。 触发Compaction调用MaybeScheduleCompaction会触发compaction操作，但是是否真正会进行compaction则要进行一些判断。 当正在进行compaction操作时，不能同时执行compaction操作。 在正在关闭数据库时，不能执行compaction操作。 当没有immutable memtable且当前版本不需要进行compaction时，不会触发compaction操作。 123456789101112131415161718192021void DBImpl::MaybeScheduleCompaction() &#123; mutex_.AssertHeld(); // 避免两次调用schedule compaction操作 if (bg_compaction_scheduled_) &#123; // Already scheduled &#125; else if (shutting_down_.Acquire_Load()) &#123; /// 若满足此条件，表示db当前正在被删除 // DB is being deleted; no more background compactions &#125; else if (!bg_error_.ok()) &#123; // Already got an error; no more changes &#125; else if (imm_ == NULL &amp;&amp; // 不需要进行compaction操作 manual_compaction_ == NULL &amp;&amp; !versions_-&gt;NeedsCompaction()) &#123; // No work to be done &#125; else &#123; /// 需要进行compaction操作 /// 记录当前正在进行compaction操作 bg_compaction_scheduled_ = true; /// 在后台线程中执行BGWork函数 env_-&gt;Schedule(&amp;DBImpl::BGWork, this); &#125;&#125; 在进入BackGroundCall函数时，会再次判断当前数据库有没有关闭。没有关闭数据库，且没有出现后台错误，则会在后台执行compaction操作。结束Compaction操作之后，因为下一个level的文件大小可能超出限制，再次触发compaction操作，同时通知等待的线程Compaction操作已经完成。 1234567891011121314151617181920212223242526void DBImpl::BackgroundCall() &#123; MutexLock l(&amp;mutex_); /// 断言正在进行compaction assert(bg_compaction_scheduled_); /// 正在关闭，返回 if (shutting_down_.Acquire_Load()) &#123; // No more background work when shutting down. &#125; else if (!bg_error_.ok()) &#123; // No more background work after a background error. &#125; else &#123; /// 执行后台的Compaction操作 BackgroundCompaction(); &#125; /// 结束Compaction bg_compaction_scheduled_ = false; // Previous compaction may have produced too many files in a level, // so reschedule another compaction if needed. /// 再次尝试compaction /// 前一次compaction操作可能在同一个level上产生了过多的文件，超出了相应的size限制， /// 所以再次执行MaybeScheduleCompaction()以触发compaction MaybeScheduleCompaction(); /// 通知等待的线程(在析构的时候，析构操作所在的线程会等待compaction操作完成) bg_cv_.SignalAll();&#125; Compaction流程如果当前存在immutable memtable，将其dump称为level 0 sstable，返回。 如果存在外部触发的compaction操作，通过manual_compaction指定的level和范围选出Compaction。若指定的key的范围很大，而每次compaction操作输入的文件大小有限制，manual_compaction可能不会一次完成，所以有done来记录是否全部完成。tmp_storage保存上一次compact到的end-key，即下一次的start key。 否则，根据数据库的当前状态，选出Compaction。如果不是手动的compaction操作，并且此次compaction操作只需要将level-n上的输入文件简单地移动到level-n+1上，更新Version信息并写入到manifest文件。否则，继续执行compaction操作。 在compaction操作完成之后，会进行清理工作，复原输入文件的引用计数，同时删除当前版本控制所不需要的文件。如果是手动compaction操作，且compaction操作没有一次完成，会更新下一次compaction操作开始的key。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/// 在此处执行compaction相关操作void DBImpl::BackgroundCompaction() &#123; mutex_.AssertHeld(); /// immutable memtable exists, dump to level-0 table if (imm_ != NULL) &#123; CompactMemTable(); return; &#125; Compaction* c; /// 是手动的compaction操作吗？ bool is_manual = (manual_compaction_ != NULL); InternalKey manual_end; if (is_manual) &#123; ManualCompaction* m = manual_compaction_; /// 根据manual_compaction_指定的level/start_key/end_key选出compaction c = versions_-&gt;CompactRange(m-&gt;level, m-&gt;begin, m-&gt;end); m-&gt;done = (c == NULL); if (c != NULL) &#123; /// 输入的第一个level文件的最大值 manual_end = c-&gt;input(0, c-&gt;num_input_files(0) - 1)-&gt;largest; &#125; Log(options_.info_log, "Manual compaction at level-%d from %s .. %s; will stop at %s\n", m-&gt;level, (m-&gt;begin ? m-&gt;begin-&gt;DebugString().c_str() : "(begin)"), (m-&gt;end ? m-&gt;end-&gt;DebugString().c_str() : "(end)"), (m-&gt;done ? "(end)" : manual_end.DebugString().c_str())); &#125; else &#123; /// 根据db当前的状态，选取并进行compaction操作 c = versions_-&gt;PickCompaction(); &#125; Status status; /// 没有compaction任务 if (c == NULL) &#123; // Nothing to do /// 不是manual compact并且只需要简单地将level上的文件移动到level+1层 &#125; else if (!is_manual &amp;&amp; c-&gt;IsTrivialMove()) &#123; // Move file to next level assert(c-&gt;num_input_files(0) == 1); FileMetaData* f = c-&gt;input(0, 0); /// 标记此文件删除 c-&gt;edit()-&gt;DeleteFile(c-&gt;level(), f-&gt;number); /// 将此文件添加到level + 1 c-&gt;edit()-&gt;AddFile(c-&gt;level() + 1, f-&gt;number, f-&gt;file_size, f-&gt;smallest, f-&gt;largest); /// 更新manifest文件 status = versions_-&gt;LogAndApply(c-&gt;edit(), &amp;mutex_); if (!status.ok()) &#123; RecordBackgroundError(status); &#125; VersionSet::LevelSummaryStorage tmp; Log(options_.info_log, "Moved #%lld to level-%d %lld bytes %s: %s\n", static_cast&lt;unsigned long long&gt;(f-&gt;number), c-&gt;level() + 1, static_cast&lt;unsigned long long&gt;(f-&gt;file_size), status.ToString().c_str(), versions_-&gt;LevelSummary(&amp;tmp)); &#125; else &#123; CompactionState* compact = new CompactionState(c); ///!!! 进行compaction 操作 status = DoCompactionWork(compact); if (!status.ok()) &#123; /// 在后台记录错误，并完成通知 RecordBackgroundError(status); &#125; /// 进行清理操作 CleanupCompaction(compact); /// release input version c-&gt;ReleaseInputs(); /// 删除无用的文件 DeleteObsoleteFiles(); &#125; delete c; if (status.ok()) &#123; // Done &#125; else if (shutting_down_.Acquire_Load()) &#123; // Ignore compaction errors found during shutting down &#125; else &#123; Log(options_.info_log, "Compaction error: %s", status.ToString().c_str()); &#125; if (is_manual) &#123; ManualCompaction* m = manual_compaction_; if (!status.ok()) &#123; m-&gt;done = true; &#125; if (!m-&gt;done) &#123; // We only compacted part of the requested range. Update *m // to the range that is left to be compacted. m-&gt;tmp_storage = manual_end; /// 记录下一次compaction的开始位置 m-&gt;begin = &amp;m-&gt;tmp_storage; &#125; manual_compaction_ = NULL; &#125;&#125; DoCompactionWork实际的compaction过程就是对多个已经排序的sstable做一次merge排序，丢弃已经删除的key，或者重复且当前版本控制所不需要的key。 将选出的Compaction中输入的sstable的Iterator组合成为一个单一的Iterator。使用迭代器遍历访问数据库中的每一个值。在循环之中，检查并且优先compact存在的immutable memtable。如果当前key与grandparent层重叠的文件超过阈值，结束输出此sstable文件。 1234567891011121314151617181920212223if (has_imm_.NoBarrier_Load() != NULL) &#123; const uint64_t imm_start = env_-&gt;NowMicros(); mutex_.Lock(); /// 检查并优先compact存在的immutable memtable if (imm_ != NULL) &#123; /// 执行对memtable的compaction的操作 CompactMemTable(); bg_cv_.SignalAll(); // Wakeup MakeRoomForWrite() if necessary &#125; mutex_.Unlock(); imm_micros += (env_-&gt;NowMicros() - imm_start);&#125;/// 如果当前与grandparent层产生overlap的size超过阈值，立即结束当前写入的sstableSlice key = input-&gt;key();if (compact-&gt;compaction-&gt;ShouldStopBefore(key) &amp;&amp; compact-&gt;builder != NULL) &#123; /// 停止输出compaction文件 status = FinishCompactionOutputFile(compact, input); if (!status.ok()) &#123; break; &#125;&#125; 当前遍历到的key不是第一次出现，且前一个相同key的sequence number小于等于smallest_snapshot，说明当前版本控制不再需要这个重复的key，将其删除。当key的类型是删除，且其sequence小于等于smallest_snapshot，并且更高level的文件之中没有这个key，也将其删除。 1234567891011121314151617181920/// 若sequence number 小于 snapshot list中最小的那个sequence number/// 第一次出现的key，其last_sequence_for_key被赋值为kMaxSequenceNumber，不会触发删除if (last_sequence_for_key &lt;= compact-&gt;smallest_snapshot) &#123; // Hidden by an newer entry for same user key drop = true; // (A)&#125; /// key的类型为删除，且其sequence &lt;= compact-&gt;smallest_snapshot， /// 且在更高level没有这个key，那么也可以将其删除else if (ikey.type == kTypeDeletion &amp;&amp; ikey.sequence &lt;= compact-&gt;smallest_snapshot &amp;&amp; compact-&gt;compaction-&gt;IsBaseLevelForKey(ikey.user_key)) &#123; // For this user key: // (1) there is no data in higher levels // (2) data in lower levels will have larger sequence numbers // (3) data in layers that are being compacted here and have // smaller sequence numbers will be dropped in the next // few iterations of this loop (by rule (A) above). // Therefore this deletion marker is obsolete and can be dropped. drop = true;&#125; 如果需要建立新的sstable，会生成新的sstable，将不丢弃的key写入。如果当前sstable的大小达到阈值，也会结束输出。 1234567891011121314151617181920212223242526// Open output file if necessaryif (compact-&gt;builder == NULL) &#123; /// 生成新的sstable status = OpenCompactionOutputFile(compact); if (!status.ok()) &#123; break; &#125;&#125;/// 记录最小值if (compact-&gt;builder-&gt;NumEntries() == 0) &#123; compact-&gt;current_output()-&gt;smallest.DecodeFrom(key);&#125;/// 记录最大值compact-&gt;current_output()-&gt;largest.DecodeFrom(key);/// 将不丢弃的key的数据写入sstablecompact-&gt;builder-&gt;Add(key, input-&gt;value());// Close output file if it is big enough/// 如果当前输出的sstable 的大小达到阈值(默认2MB)，结束此sstable文件if (compact-&gt;builder-&gt;FileSize() &gt;= compact-&gt;compaction-&gt;MaxOutputFileSize()) &#123; status = FinishCompactionOutputFile(compact, input); if (!status.ok()) &#123; break; &#125;&#125; 在compaction操作生成所有合并之后的sstable文件之后，会记录相关的统计信息，同时安装新生成的文件到当前版本。 12345678910111213141516171819/// 更新compaction操作统计信息CompactionStats stats;stats.micros = env_-&gt;NowMicros() - start_micros - imm_micros;for (int which = 0; which &lt; 2; which++) &#123; for (int i = 0; i &lt; compact-&gt;compaction-&gt;num_input_files(which); i++) &#123; stats.bytes_read += compact-&gt;compaction-&gt;input(which, i)-&gt;file_size; &#125;&#125;for (size_t i = 0; i &lt; compact-&gt;outputs.size(); i++) &#123; stats.bytes_written += compact-&gt;outputs[i].file_size;&#125;mutex_.Lock();stats_[compact-&gt;compaction-&gt;level() + 1].Add(stats);if (status.ok()) &#123; /// 安装compaction之后产生的新文件 status = InstallCompactionResults(compact);&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb Open和Write流程]]></title>
    <url>%2F2017%2F06%2F24%2Fleveldb-Open%E5%92%8CWrite%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Open总览在leveldb中，DB接口的实现在DBImpl对象中。打开数据库的时候，首先创建DBImpl对象，在这里会初始化各成员，对输入的option选项进行规范化，创建缓存sstable对象的table_cache_，同时创建VersionSet对象用于管理数据库版本。 1234567891011121314151617181920212223242526272829303132333435DBImpl::DBImpl(const Options&amp; raw_options, const std::string&amp; dbname) : env_(raw_options.env), internal_comparator_(raw_options.comparator), internal_filter_policy_(raw_options.filter_policy), options_(SanitizeOptions(dbname, &amp;internal_comparator_, &amp;internal_filter_policy_, raw_options)), /// 是否拥有info_log owns_info_log_(options_.info_log != raw_options.info_log), /// 是否拥有cache owns_cache_(options_.block_cache != raw_options.block_cache), dbname_(dbname), db_lock_(NULL), shutting_down_(NULL), bg_cv_(&amp;mutex_), // background condition variable mem_(NULL), // memtable imm_(NULL), // immutable memtable logfile_(NULL), // log file descriptor logfile_number_(0), // log file number log_(NULL), // logger seed_(0), tmp_batch_(new WriteBatch), // temp batch bg_compaction_scheduled_(false), // 当前是否正有后台compaction正在运行 manual_compaction_(NULL) &#123; // 指代手动compaction操作 has_imm_.Release_Store(NULL); // no immutable memtable // Reserve ten files or so for other uses and give the rest to TableCache. /// 990 const int table_cache_size = options_.max_open_files - kNumNonTableCacheFiles; /// sstable handle cache table_cache_ = new TableCache(dbname_, &amp;options_, table_cache_size); // create version set object versions_ = new VersionSet(dbname_, &amp;options_, table_cache_, &amp;internal_comparator_);&#125; 接下来进入Recover函数，首先尝试对LOCK文件进行上锁，确保只有一个leveldb实例正在数据库路径上运行。若CURRENT文件并不存在，则表明数据库未初始化，根据设置，若启用了create_if_missing选项，则会进行初始化操作。紧接着从manifest文件之中得到之前数据库实例最新的版本信息。根据版本信息，就可以检查数据库路径下是否存在文件缺失。若无缺失，则从log文件之中恢复memtable内保存的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104Status DBImpl::Recover(VersionEdit* edit, bool *save_manifest) &#123; mutex_.AssertHeld(); // Ignore error from CreateDir since the creation of the DB is // committed only when the descriptor is created, and this directory // may already exist from a previous failed creation attempt. /// 创建路径，名称为dbname_ env_-&gt;CreateDir(dbname_); assert(db_lock_ == NULL); /// 持有文件锁, 表明当前数据库正在工作中 Status s = env_-&gt;LockFile(LockFileName(dbname_), &amp;db_lock_); if (!s.ok()) &#123; return s; &#125; /// current文件不存在 if (!env_-&gt;FileExists(CurrentFileName(dbname_))) &#123; /// 当缺失时创建 if (options_.create_if_missing) &#123; /// 初始化数据库 s = NewDB(); if (!s.ok()) &#123; return s; &#125; &#125; else &#123; /// 数据库不存在 return Status::InvalidArgument( dbname_, "does not exist (create_if_missing is false)"); &#125; &#125; else &#123; /// 数据库已经存在 if (options_.error_if_exists) &#123; return Status::InvalidArgument( dbname_, "exists (error_if_exists is true)"); &#125; &#125; // 从manifest文件之中恢复Version设置 s = versions_-&gt;Recover(save_manifest); if (!s.ok()) &#123; return s; &#125; SequenceNumber max_sequence(0); // Recover from all newer log files than the ones named in the // descriptor (new log files may have been added by the previous // incarnation without registering them in the descriptor). // // Note that PrevLogNumber() is no longer used, but we pay // attention to it in case we are recovering a database // produced by an older version of leveldb. const uint64_t min_log = versions_-&gt;LogNumber(); const uint64_t prev_log = versions_-&gt;PrevLogNumber(); std::vector&lt;std::string&gt; filenames; /// 获取数据库路径下的所有文件 s = env_-&gt;GetChildren(dbname_, &amp;filenames); if (!s.ok()) &#123; return s; &#125; std::set&lt;uint64_t&gt; expected; /// 得到当前所有文件对应的numbers versions_-&gt;AddLiveFiles(&amp;expected); uint64_t number; FileType type; std::vector&lt;uint64_t&gt; logs; for (size_t i = 0; i &lt; filenames.size(); i++) &#123; if (ParseFileName(filenames[i], &amp;number, &amp;type)) &#123; expected.erase(number); if (type == kLogFile &amp;&amp; ((number &gt;= min_log) || (number == prev_log))) /// 记录log文件对应的number logs.push_back(number); &#125; &#125; /// 缺失了文件, 崩溃 if (!expected.empty()) &#123; char buf[50]; snprintf(buf, sizeof(buf), "%d missing files; e.g.", static_cast&lt;int&gt;(expected.size())); return Status::Corruption(buf, TableFileName(dbname_, *(expected.begin()))); &#125; // Recover in the order in which the logs were generated std::sort(logs.begin(), logs.end()); for (size_t i = 0; i &lt; logs.size(); i++) &#123; /// 从log文件之中恢复 是最后一个log文件吗？ s = RecoverLogFile(logs[i], (i == logs.size() - 1), save_manifest, edit, &amp;max_sequence); if (!s.ok()) &#123; return s; &#125; // The previous incarnation may not have written any MANIFEST // records after allocating this log number. So we manually // update the file number allocation counter in VersionSet. /// 标识此log文件编号已经使用 versions_-&gt;MarkFileNumberUsed(logs[i]); &#125; /// 设置最大的序列号 if (versions_-&gt;LastSequence() &lt; max_sequence) &#123; versions_-&gt;SetLastSequence(max_sequence); &#125; return Status::OK();&#125; 恢复完成之后，若memtable为NULL，创建并且为其设置log。写入到memtable的数据都会追加到log文件之中以记录。然后更新版本信息，写入到manifest文件。最后尝试删除无用的文件，同时触发compaction操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253Status DB::Open(const Options&amp; options, const std::string&amp; dbname, DB** dbptr) &#123; *dbptr = NULL; // 创建DBImpl对象 DBImpl* impl = new DBImpl(options, dbname); impl-&gt;mutex_.Lock(); VersionEdit edit; // Recover handles create_if_missing, error_if_exists bool save_manifest = false; /// 尝试读取record, 从log文件之中恢复 Status s = impl-&gt;Recover(&amp;edit, &amp;save_manifest); if (s.ok() &amp;&amp; impl-&gt;mem_ == NULL) &#123; // Create new log and a corresponding memtable. uint64_t new_log_number = impl-&gt;versions_-&gt;NewFileNumber(); WritableFile* lfile; s = options.env-&gt;NewWritableFile(LogFileName(dbname, new_log_number), &amp;lfile); if (s.ok()) &#123; edit.SetLogNumber(new_log_number); /// set logfile_ impl-&gt;logfile_ = lfile; /// set logfile_number_ impl-&gt;logfile_number_ = new_log_number; /// set log_ impl-&gt;log_ = new log::Writer(lfile); /// set memtable impl-&gt;mem_ = new MemTable(impl-&gt;internal_comparator_); /// 增加引用计数 impl-&gt;mem_-&gt;Ref(); &#125; &#125; /// save_manifest记录了当前是否需要进行compaction操作 if (s.ok() &amp;&amp; save_manifest) &#123; edit.SetPrevLogNumber(0); // No older logs needed after recovery. edit.SetLogNumber(impl-&gt;logfile_number_); // 将edit应用到当前version，并且保存到manifest文件 s = impl-&gt;versions_-&gt;LogAndApply(&amp;edit, &amp;impl-&gt;mutex_); &#125; if (s.ok()) &#123; /// 删除无用文件 impl-&gt;DeleteObsoleteFiles(); // 触发compaction操作 impl-&gt;MaybeScheduleCompaction(); &#125; impl-&gt;mutex_.Unlock(); if (s.ok()) &#123; assert(impl-&gt;mem_ != NULL); *dbptr = impl; &#125; else &#123; delete impl; &#125; return s;&#125; RecoverLogFile从log文件中恢复时，会从log文件之中遍历读取WriteBatch数据，将其中记载的操作作用在memtable上面。若memtable的大小超出设定值，则将memtable dump成为level-0 table。在遍历log文件的过程之中，会根据当前log文件设置log_和logfile_number_。只有当设定允许重用log文件，且不存在从memtable dump到sstable，才会允许复用log文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log, bool* save_manifest, VersionEdit* edit, SequenceNumber* max_sequence) &#123; struct LogReporter : public log::Reader::Reporter &#123; Env* env; Logger* info_log; const char* fname; Status* status; // NULL if options_.paranoid_checks==false virtual void Corruption(size_t bytes, const Status&amp; s) &#123; Log(info_log, "%s%s: dropping %d bytes; %s", (this-&gt;status == NULL ? "(ignoring error) " : ""), fname, static_cast&lt;int&gt;(bytes), s.ToString().c_str()); if (this-&gt;status != NULL &amp;&amp; this-&gt;status-&gt;ok()) *this-&gt;status = s; &#125; &#125;; mutex_.AssertHeld(); // Open the log file std::string fname = LogFileName(dbname_, log_number); SequentialFile* file; Status status = env_-&gt;NewSequentialFile(fname, &amp;file); if (!status.ok()) &#123; /// 输出此错误，忽略并返回 MaybeIgnoreError(&amp;status); return status; &#125; // Create the log reader. LogReporter reporter; reporter.env = env_; reporter.info_log = options_.info_log; reporter.fname = fname.c_str(); reporter.status = (options_.paranoid_checks ? &amp;status : NULL); // We intentionally make log::Reader do checksumming even if // paranoid_checks==false so that corruptions cause entire commits // to be skipped instead of propagating bad information (like overly // large sequence numbers). log::Reader reader(file, &amp;reporter, true/*checksum*/, 0/*initial_offset*/); Log(options_.info_log, "Recovering log #%llu", (unsigned long long) log_number); // Read all the records and add to a memtable std::string scratch; Slice record; WriteBatch batch; int compactions = 0; // compaction执行的次数 MemTable* mem = NULL; while (reader.ReadRecord(&amp;record, &amp;scratch) &amp;&amp; status.ok()) &#123; // log record太短了，连一个WriteBatch的头部长度都不够 if (record.size() &lt; 12) &#123; reporter.Corruption( record.size(), Status::Corruption("log record too small")); continue; &#125; /// log实际上存储的就是WriteBatch WriteBatchInternal::SetContents(&amp;batch, record); if (mem == NULL) &#123; // create memtable mem = new MemTable(internal_comparator_); mem-&gt;Ref(); &#125; /// 向memtable之中插入记录 status = WriteBatchInternal::InsertInto(&amp;batch, mem); MaybeIgnoreError(&amp;status); if (!status.ok()) &#123; break; &#125; const SequenceNumber last_seq = WriteBatchInternal::Sequence(&amp;batch) + WriteBatchInternal::Count(&amp;batch) - 1; if (last_seq &gt; *max_sequence) &#123; ///更新max_sequence *max_sequence = last_seq; &#125; /// memtable的内存使用量超出4MB if (mem-&gt;ApproximateMemoryUsage() &gt; options_.write_buffer_size) &#123; compactions++; *save_manifest = true; /// 将memtable dump成为level0 table status = WriteLevel0Table(mem, edit, NULL); /// 清空memtable mem-&gt;Unref(); mem = NULL; if (!status.ok()) &#123; // Reflect errors immediately so that conditions like full // file-systems cause the DB::Open() to fail. break; &#125; &#125; &#125; delete file; // See if we should keep reusing the last log file. if (status.ok() &amp;&amp; options_.reuse_logs &amp;&amp; last_log &amp;&amp; compactions == 0) &#123; assert(logfile_ == NULL); assert(log_ == NULL); assert(mem_ == NULL); uint64_t lfile_size; if (env_-&gt;GetFileSize(fname, &amp;lfile_size).ok() &amp;&amp; env_-&gt;NewAppendableFile(fname, &amp;logfile_).ok()) &#123; Log(options_.info_log, "Reusing old log %s \n", fname.c_str()); log_ = new log::Writer(logfile_, lfile_size); logfile_number_ = log_number; if (mem != NULL) &#123; mem_ = mem; mem = NULL; &#125; else &#123; /// 创建memtable // mem can be NULL if lognum exists but was empty. mem_ = new MemTable(internal_comparator_); mem_-&gt;Ref(); &#125; &#125; &#125; if (mem != NULL) &#123; // mem did not get reused; compact it. if (status.ok()) &#123; /// 需要保存manifest文件 *save_manifest = true; /// 将memtable dump成为level0 table status = WriteLevel0Table(mem, edit, NULL); &#125; mem-&gt;Unref(); &#125; return status;&#125; Write在leveldb之中，Put和Delete操作都会将操作记录在WriteBatch之中，转换为Write操作。 12345678// Convenience methodsStatus DBImpl::Put(const WriteOptions&amp; o, const Slice&amp; key, const Slice&amp; val) &#123; return DB::Put(o, key, val);&#125;Status DBImpl::Delete(const WriteOptions&amp; options, const Slice&amp; key) &#123; return DB::Delete(options, key);&#125; 可能会有多个线程同时进行Write操作。leveldb会将WriteBatch操作加入队列之中，只有队列头部所在的线程来负责插入。leveldb中的写操作不是瓶颈，但是可能出现过量的写影响度的效率，所以采取一些措施来限制写。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172Status DBImpl::MakeRoomForWrite(bool force) &#123; mutex_.AssertHeld(); assert(!writers_.empty()); bool allow_delay = !force; Status s; while (true) &#123; if (!bg_error_.ok()) &#123; // Yield previous error s = bg_error_; break; &#125; ///如果当前level-0中文件的数目达到kL0_SlowdownWritesTrigger阈值，则sleep进行delay。此delay只进行一次。 else if ( allow_delay &amp;&amp; versions_-&gt;NumLevelFiles(0) &gt;= config::kL0_SlowdownWritesTrigger) &#123; // We are getting close to hitting a hard limit on the number of // L0 files. Rather than delaying a single write by several // seconds when we hit the hard limit, start delaying each // individual write by 1ms to reduce latency variance. Also, // this delay hands over some CPU to the compaction thread in // case it is sharing the same core as the writer. mutex_.Unlock(); env_-&gt;SleepForMicroseconds(1000); allow_delay = false; // Do not delay a single write more than once mutex_.Lock(); &#125; /// 若当前memtable的size没有达到阈值write_buffer_size,则允许此次写 else if (!force &amp;&amp; (mem_-&gt;ApproximateMemoryUsage() &lt;= options_.write_buffer_size)) &#123; // There is room in current memtable break; &#125; /// 如果memtable已经达到阈值，并且immutable memtable仍然存在，等待compact dump完成 else if (imm_ != NULL) &#123; // We have filled up the current memtable, but the previous // one is still being compacted, so we wait. Log(options_.info_log, "Current memtable full; waiting...\n"); bg_cv_.Wait(); &#125; /// 若level-0中文件数目达到kL0_StopWritesTrigger阈值，等待compact memtable完成 else if (versions_-&gt;NumLevelFiles(0) &gt;= config::kL0_StopWritesTrigger) &#123; // There are too many level-0 files. Log(options_.info_log, "Too many L0 files; waiting...\n"); bg_cv_.Wait(); &#125; else &#123; /// 将当前memtable转为immutable memtable, 生成新的memtable和log file，主动触发compact，允许此次写 // Attempt to switch to a new memtable and trigger compaction of old assert(versions_-&gt;PrevLogNumber() == 0); uint64_t new_log_number = versions_-&gt;NewFileNumber(); WritableFile* lfile = NULL; s = env_-&gt;NewWritableFile(LogFileName(dbname_, new_log_number), &amp;lfile); if (!s.ok()) &#123; // Avoid chewing through file number space in a tight loop. versions_-&gt;ReuseFileNumber(new_log_number); break; &#125; delete log_; delete logfile_; logfile_ = lfile; logfile_number_ = new_log_number; log_ = new log::Writer(lfile); imm_ = mem_; has_imm_.Release_Store(imm_); mem_ = new MemTable(internal_comparator_); mem_-&gt;Ref(); force = false; // Do not force another compaction if have room /// 进行compact，将immutable memtable进行compact处理 MaybeScheduleCompaction(); &#125; &#125; return s;&#125; 如果当前level-0的文件数目达到kL0_SlowdownWritesTrigger阈值，则sleep进行delay，此操作只进行一次。 如果当前memtable的空间没有达到阈值write_buffer_size，则允许此次写。 如果memtable大小达到阈值，且immutable memtable仍存在，则等待compaction操作完成。 如果level-0中的文件数目达到kL0_StopWritesTrigger阈值，则等待compaction完成。 上述条件均不满足，即memtable已经写满，且immutable memtable不存在，则将当前的memtable转为immutable memtable，生成新的memtable和log file，触发compaction操作。 限制写入速度之后，将WriteBatch写入log文件，并将其中的操作应用在memtable之上，更新sequence number。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586Status DBImpl::Write(const WriteOptions&amp; options, WriteBatch* my_batch) &#123; Writer w(&amp;mutex_); w.batch = my_batch; /// 需要进行sync操作吗？ w.sync = options.sync; w.done = false; MutexLock l(&amp;mutex_); /// 将操作加入队列之中 writers_.push_back(&amp;w); /// 若不为队列中的第一项, 等待操作完成, 只有第一个插入才执行后续的操作 while (!w.done &amp;&amp; &amp;w != writers_.front()) &#123; w.cv.Wait(); &#125; if (w.done) &#123; return w.status; &#125; /// 有新的数据被添加进写入队列，为了控制写入队列的大小，进行下述操作 // May temporarily unlock and wait. Status status = MakeRoomForWrite(my_batch == NULL); uint64_t last_sequence = versions_-&gt;LastSequence(); Writer* last_writer = &amp;w; /// NULL batch被用作compaction if (status.ok() &amp;&amp; my_batch != NULL) &#123; // NULL batch is for compactions WriteBatch* updates = BuildBatchGroup(&amp;last_writer); // 设置WriteBatch的SequenceNumber WriteBatchInternal::SetSequence(updates, last_sequence + 1); last_sequence += WriteBatchInternal::Count(updates); // Add to log and apply to memtable. We can release the lock // during this phase since &amp;w is currently responsible for logging // and protects against concurrent loggers and concurrent writes // into mem_. &#123; mutex_.Unlock(); ///将writeBatch中的数据记录log status = log_-&gt;AddRecord(WriteBatchInternal::Contents(updates)); bool sync_error = false; if (status.ok() &amp;&amp; options.sync) &#123; /// 若设置了sync，则对log文件执行sync操作 status = logfile_-&gt;Sync(); if (!status.ok()) &#123; sync_error = true; &#125; &#125; if (status.ok()) &#123; /// 将更新写入memtable之中 status = WriteBatchInternal::InsertInto(updates, mem_); &#125; mutex_.Lock(); if (sync_error) &#123; // The state of the log file is indeterminate: the log record we // just added may or may not show up when the DB is re-opened. // So we force the DB into a mode where all future writes fail. /// 记录后台错误 RecordBackgroundError(status); &#125; &#125; /// 对tmp_batch_进行清空处理 if (updates == tmp_batch_) tmp_batch_-&gt;Clear(); versions_-&gt;SetLastSequence(last_sequence); &#125; while (true) &#123; Writer* ready = writers_.front(); writers_.pop_front(); if (ready != &amp;w) &#123; ready-&gt;status = status; ready-&gt;done = true; /// 通知等待线程，已经完成 ready-&gt;cv.Signal(); &#125; /// 直到一组WriteBatch全部处理完毕 if (ready == last_writer) break; &#125; // Notify new head of write queue if (!writers_.empty()) &#123; /// 通知当前处在队列头的线程，进行插入处理 writers_.front()-&gt;cv.Signal(); &#125; return status;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb VersionSet解析]]></title>
    <url>%2F2017%2F06%2F24%2Fleveldb-VersionSet%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[VersionSetVersionSet负责整个leveldb中各个版本的控制事务。VersionSet维护了一个双向的环形链表，某个Version不再使用时会从链表中删除，其中管理的文件的引用计数也会相应变化，驱动将无用的文件从数据库路径下删除。下图很好地展示了这一点： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206class VersionSet &#123; public: /// constructor of VersionSet VersionSet(const std::string&amp; dbname, const Options* options, TableCache* table_cache, const InternalKeyComparator*); /// destructor of VersionSet ~VersionSet(); // Apply *edit to the current version to form a new descriptor that // is both saved to persistent state and installed as the new // current version. Will release *mu while actually writing to the file. // REQUIRES: *mu is held on entry. // REQUIRES: no other thread concurrently calls LogAndApply() /// 应用当前version，生成新的log文件，保存持久状态，并且安装作为当前的version， /// 在真正写入到文件之后会release *mu Status LogAndApply(VersionEdit* edit, port::Mutex* mu) EXCLUSIVE_LOCKS_REQUIRED(mu); // Recover the last saved descriptor from persistent storage. /// 从存储中恢复最近保存的描述信息 Status Recover(bool *save_manifest); // Return the current version. /// 返回当前的版本 Version* current() const &#123; return current_; &#125; // Return the current manifest file number /// 返回当前manifest文件数目 uint64_t ManifestFileNumber() const &#123; return manifest_file_number_; &#125; // Allocate and return a new file number /// 分配并返回一个新的file number uint64_t NewFileNumber() &#123; return next_file_number_++; &#125; // Arrange to reuse "file_number" unless a newer file number has // already been allocated. // REQUIRES: "file_number" was returned by a call to NewFileNumber(). /// 已经ReuseFileNumber, 故而next_file_number_可以减去1 void ReuseFileNumber(uint64_t file_number) &#123; if (next_file_number_ == file_number + 1) &#123; next_file_number_ = file_number; &#125; &#125; // Return the number of Table files at the specified level. /// 返回指定level的table文件的number int NumLevelFiles(int level) const; // Return the combined file size of all files at the specified level. /// 返回指定level的所有文件合并的文件的大小 int64_t NumLevelBytes(int level) const; // Return the last sequence number. /// 返回上一个sequence number uint64_t LastSequence() const &#123; return last_sequence_; &#125; // Set the last sequence number to s. /// 设置 last sequence number void SetLastSequence(uint64_t s) &#123; assert(s &gt;= last_sequence_); last_sequence_ = s; &#125; // Mark the specified file number as used. /// 标记number指定的文件已经使用, 并据此更新next_file_number_ void MarkFileNumberUsed(uint64_t number); // Return the current log file number. /// 返回当前log文件的number uint64_t LogNumber() const &#123; return log_number_; &#125; // Return the log file number for the log file that is currently // being compacted, or zero if there is no such log file. /// 返回上一个log文件的number uint64_t PrevLogNumber() const &#123; return prev_log_number_; &#125; // Pick level and inputs for a new compaction. // Returns NULL if there is no compaction to be done. // Otherwise returns a pointer to a heap-allocated object that // describes the compaction. Caller should delete the result. /// 选取文件进行Compaction操作 Compaction* PickCompaction(); // Return a compaction object for compacting the range [begin,end] in // the specified level. Returns NULL if there is nothing in that // level that overlaps the specified range. Caller should delete // the result. /// 选取指定level上指定范围的文件进行Compaction操作 Compaction* CompactRange( int level, const InternalKey* begin, const InternalKey* end); // Return the maximum overlapping data (in bytes) at next level for any // file at a level &gt;= 1. /// 返回某level和上级文件最大的overlapping的数据大小 (level &gt;= 1) int64_t MaxNextLevelOverlappingBytes(); // Create an iterator that reads over the compaction inputs for "*c". // The caller should delete the iterator when no longer needed. /// 在给定的compaction对象上创建iterator, 这是对compaction涉及到的sstable合并之后形成的 /// 统一的iterator Iterator* MakeInputIterator(Compaction* c); // Returns true iff some level needs a compaction. /// 是否需要进行Compaction ? bool NeedsCompaction() const &#123; Version* v = current_; /// 若当前版本的compaction_score &gt;= 1 且 需要进行compact的文件不为NULL 才会需要合并 return (v-&gt;compaction_score_ &gt;= 1) || (v-&gt;file_to_compact_ != NULL); &#125; // Add all files listed in any live version to *live. // May also mutate some internal state. /// 将当前存活的文件信息存入live之中 void AddLiveFiles(std::set&lt;uint64_t&gt;* live); // Return the approximate offset in the database of the data for // "key" as of version "v". /// 返回key和version对应的数据在database之中的偏移位置，此值为估计值 uint64_t ApproximateOffsetOf(Version* v, const InternalKey&amp; key); // Return a human-readable short (single-line) summary of the number // of files per level. Uses *scratch as backing store. /// 用于LevelSummary struct LevelSummaryStorage &#123; char buffer[100]; &#125;; /// 返回每个level上文件数目的总结 /// 使用sratch用于backing store const char* LevelSummary(LevelSummaryStorage* scratch) const; private: class Builder; friend class Compaction; friend class Version; bool ReuseManifest(const std::string&amp; dscname, const std::string&amp; dscbase); void Finalize(Version* v); void GetRange(const std::vector&lt;FileMetaData*&gt;&amp; inputs, InternalKey* smallest, InternalKey* largest); void GetRange2(const std::vector&lt;FileMetaData*&gt;&amp; inputs1, const std::vector&lt;FileMetaData*&gt;&amp; inputs2, InternalKey* smallest, InternalKey* largest); void SetupOtherInputs(Compaction* c); // Save current contents to *log Status WriteSnapshot(log::Writer* log); /// 添加version最为当前的version void AppendVersion(Version* v); Env* const env_; const std::string dbname_; // db name const Options* const options_; // options TableCache* const table_cache_; // sstable cache const InternalKeyComparator icmp_; // InternalKey comparator uint64_t next_file_number_; // 下一个file number uint64_t manifest_file_number_; // number of manifest file uint64_t last_sequence_; // 上一个序号 uint64_t log_number_; // log文件的number uint64_t prev_log_number_; // 0 or backing store for memtable being compacted /* 为了重启db后可以恢复退出前的状态，需要将db中的状态保存下来，这些状态信息就保存在manifest文件中。 当db出现异常的时候，为了尽可能多的恢复，manifest中不会只保存当前的状态，而是将历史的状态都保存下来。 又考虑到每次状态的完全保存需要的空间和耗费的时间会较多，当前采用的方式是，只在manifest开始保存完整 的状态信息(VersionSet::WriteSnapshot())，接下来只保存每次compact产生的操作，重启db时，根据开头 的起始状态，依次将后续的VersionEdit replay，即可恢复到退出之前的状态。 */ // Opened lazily // manifest文件的封装 WritableFile* descriptor_file_; // manifest文件的writer log::Writer* descriptor_log_; // 正在服务的Version链表 Version dummy_versions_; // Head of circular doubly-linked list of versions. // 当前最新的Version Version* current_; // == dummy_versions_.prev_ // Per-level key at which the next compaction at that level should start. // Either an empty string, or a valid InternalKey. /// 每一个level的下一次compaction开始进行的key /// empty string 或者 InternalKey /* 为了尽量均匀compact每个level，所以会将这一次compact的end-key作为下一次compact的start-key. compactor_pointer_就保存着每个level下一次compact的start-key.除了current_外的Version，并不会做 compact，所以这个值并不保存在Version中。 */ std::string compact_pointer_[config::kNumLevels]; // No copying allowed VersionSet(const VersionSet&amp;); void operator=(const VersionSet&amp;);&#125;; 重点成员函数上述成员函数中，LogAndApply将edit应用到当前的版本作为当前最新的版本，并且将edit写入到manifest文件之中，以便leveldb重新启动时能够恢复版本控制信息。而Recover函数则是从CURRENT文件之中获取MANIFEST文件名称，读取Version信息。重启的数据库只需要读取并应用VersionEdit到Version，保留一个版本的Version即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132Status VersionSet::Recover(bool *save_manifest) &#123; struct LogReporter : public log::Reader::Reporter &#123; Status* status; virtual void Corruption(size_t bytes, const Status&amp; s) &#123; if (this-&gt;status-&gt;ok()) *this-&gt;status = s; &#125; &#125;; // Read "CURRENT" file, which contains a pointer to the current manifest file std::string current; Status s = ReadFileToString(env_, CurrentFileName(dbname_), &amp;current); if (!s.ok()) &#123; return s; &#125; if (current.empty() || current[current.size()-1] != '\n') &#123; return Status::Corruption("CURRENT file does not end with newline"); &#125; /// 删除末尾的换行符 current.resize(current.size() - 1); std::string dscname = dbname_ + "/" + current; SequentialFile* file; s = env_-&gt;NewSequentialFile(dscname, &amp;file); if (!s.ok()) &#123; return s; &#125; bool have_log_number = false; bool have_prev_log_number = false; bool have_next_file = false; bool have_last_sequence = false; uint64_t next_file = 0; uint64_t last_sequence = 0; uint64_t log_number = 0; uint64_t prev_log_number = 0; Builder builder(this, current_); &#123; LogReporter reporter; reporter.status = &amp;s; log::Reader reader(file, &amp;reporter, true/*checksum*/, 0/*initial_offset*/); Slice record; std::string scratch; while (reader.ReadRecord(&amp;record, &amp;scratch) &amp;&amp; s.ok()) &#123; VersionEdit edit; /// get VersionEdit s = edit.DecodeFrom(record); if (s.ok()) &#123; if (edit.has_comparator_ &amp;&amp; edit.comparator_ != icmp_.user_comparator()-&gt;Name()) &#123; /// 和现有的comparator不匹配 s = Status::InvalidArgument( edit.comparator_ + " does not match existing comparator ", icmp_.user_comparator()-&gt;Name()); &#125; &#125; if (s.ok()) &#123; /// 对version应用edit更新 builder.Apply(&amp;edit); &#125; if (edit.has_log_number_) &#123; log_number = edit.log_number_; have_log_number = true; &#125; if (edit.has_prev_log_number_) &#123; prev_log_number = edit.prev_log_number_; have_prev_log_number = true; &#125; if (edit.has_next_file_number_) &#123; next_file = edit.next_file_number_; have_next_file = true; &#125; if (edit.has_last_sequence_) &#123; last_sequence = edit.last_sequence_; have_last_sequence = true; &#125; &#125; &#125; /// 删除原有manifest文件 delete file; file = NULL; if (s.ok()) &#123; if (!have_next_file) &#123; s = Status::Corruption("no meta-nextfile entry in descriptor"); &#125; else if (!have_log_number) &#123; s = Status::Corruption("no meta-lognumber entry in descriptor"); &#125; else if (!have_last_sequence) &#123; s = Status::Corruption("no last-sequence-number entry in descriptor"); &#125; if (!have_prev_log_number) &#123; prev_log_number = 0; &#125; /// 标记file number已经使用了 MarkFileNumberUsed(prev_log_number); MarkFileNumberUsed(log_number); &#125; if (s.ok()) &#123; Version* v = new Version(this); /// 保存version到v builder.SaveTo(v); // Install recovered version /// 得到compaction操作得分 Finalize(v); /// 此version作为当前version AppendVersion(v); manifest_file_number_ = next_file; next_file_number_ = next_file + 1; last_sequence_ = last_sequence; log_number_ = log_number; prev_log_number_ = prev_log_number; // See if we can reuse the existing MANIFEST file. /// 查看是否能够复用当前存在的MANIFEST文件 if (ReuseManifest(dscname, current)) &#123; // No need to save new manifest &#125; else &#123; /// 需要建立manifest文件 *save_manifest = true; &#125; &#125; return s;&#125; Compaction相关PickCompaction每一次调用LogAndApply，应用VersionEdit到当前Version得到更新之后的Version都会调用Finalize评估每个level文件的compaction_score_。这是为了评估每个level所有sstable文件占用的总空间的大小，若超出限制就做好记录，将低level的文件推到更高的level上。 首先，level-0上的文件总数超出限制kL0_CompactionTrigger，或者以下各level文件的数量超出下述范围，都会被认为是违背平衡，选择其中偏差最大的文件记录下来，后续进行compaction处理。 12345678// level0 10M// level1 10M// level2 100M// level3 1000M// level4 10000M// level5 100000M// level6 1000000M// level7 10000000M 1234567891011121314151617181920212223242526272829303132333435363738394041/// 计算Version内的均衡状态参数: compaction_score_和compaction_level_void VersionSet::Finalize(Version* v) &#123; // Precomputed best level for next compaction int best_level = -1; double best_score = -1; for (int level = 0; level &lt; config::kNumLevels-1; level++) &#123; double score; if (level == 0) &#123; // We treat level-0 specially by bounding the number of files // instead of number of bytes for two reasons: // // (1) With larger write-buffer sizes, it is nice not to do too // many level-0 compactions. // // (2) The files in level-0 are merged on every read and // therefore we wish to avoid too many files when the individual // file size is small (perhaps because of a small write-buffer // setting, or very high compression ratios, or lots of // overwrites/deletions). /// level0文件达到4 score = v-&gt;files_[level].size() / static_cast&lt;double&gt;(config::kL0_CompactionTrigger); &#125; else &#123; // Compute the ratio of current size to size limit. const uint64_t level_bytes = TotalFileSize(v-&gt;files_[level]); /// 其他level文件大小之和达到预设大小 score = static_cast&lt;double&gt;(level_bytes) / MaxBytesForLevel(options_, level); &#125; if (score &gt; best_score) &#123; best_level = level; best_score = score; &#125; &#125; // record compaction level and compaction score v-&gt;compaction_level_ = best_level; v-&gt;compaction_score_ = best_score;&#125; PickCompaction函数中优先处理size_compaction而非seek_compaction。对于size_compaction会选取上一次compaction结束的key之后的文件开始进行，对于seek_compaction会直接选取之前记录seek数量超标的文件。因为level-0的sstable文件可能会互相重叠，将区间重叠的所有level-0文件取出来。这样就完成了compaction level上输入的sstable文件的选取，还要借助SetupOtherInputs函数选取上一个level上的区间重叠的输入文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566Compaction* VersionSet::PickCompaction() &#123; Compaction* c; int level; // We prefer compactions triggered by too much data in a level over // the compactions triggered by seeks. /// 相比seek_compaction, 我们优先处理size_compaction /// 相比由seek产生的不均衡，更优先compact由sstable size / count造成的不平衡 /// 因为文件大小超标而需要进行Compaction操作 const bool size_compaction = (current_-&gt;compaction_score_ &gt;= 1); /// 因为seek次数过多而需要进行Compaction操作 const bool seek_compaction = (current_-&gt;file_to_compact_ != NULL); if (size_compaction) &#123; level = current_-&gt;compaction_level_; assert(level &gt;= 0); assert(level+1 &lt; config::kNumLevels); c = new Compaction(options_, level); // Pick the first file that comes after compact_pointer_[level] /// 选择大于compact_pointer_[level]的文件 for (size_t i = 0; i &lt; current_-&gt;files_[level].size(); i++) &#123; FileMetaData* f = current_-&gt;files_[level][i]; if (compact_pointer_[level].empty() || icmp_.Compare(f-&gt;largest.Encode(), compact_pointer_[level]) &gt; 0) &#123; c-&gt;inputs_[0].push_back(f); break; &#125; &#125; /// 没有输入，就使用对应level的第一个文件输入 if (c-&gt;inputs_[0].empty()) &#123; // Wrap-around to the beginning of the key space c-&gt;inputs_[0].push_back(current_-&gt;files_[level][0]); &#125; &#125; else if (seek_compaction) &#123; level = current_-&gt;file_to_compact_level_; c = new Compaction(options_, level); /// 指定为因为seek而记录的file_to_compact_文件 c-&gt;inputs_[0].push_back(current_-&gt;file_to_compact_); &#125; else &#123; return NULL; &#125; /// 输入的version c-&gt;input_version_ = current_; /// reference it c-&gt;input_version_-&gt;Ref(); // Files in level 0 may overlap each other, so pick up all overlapping ones /// 若为level0可能会互相重叠,取出在level-0中与确定compact的sstable有overlap的文件 //// level0更新inputs_[0] if (level == 0) &#123; InternalKey smallest, largest; GetRange(c-&gt;inputs_[0], &amp;smallest, &amp;largest); // Note that the next call will discard the file we placed in // c-&gt;inputs_[0] earlier and replace it with an overlapping set // which will include the picked file. /// 取出level0与smallest和largest重叠的文件 current_-&gt;GetOverlappingInputs(0, &amp;smallest, &amp;largest, &amp;c-&gt;inputs_[0]); assert(!c-&gt;inputs_[0].empty()); &#125; /// 取得需要的其他sstable SetupOtherInputs(c); return c;&#125; CompactRangeCompactRange函数的存在是为了应对选取指定level和范围的sstable文件作为输入进行compaction的行为。其行为很简单，选择与指定范围重叠的文件作为compaction level输入的sstable文件。但是选取的文件总空间大小被限制在此level的文件大小限制之内。最后依然调用SetupOtherInputs选取level+1层次上区间重叠的sstable文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344Compaction* VersionSet::CompactRange( int level, const InternalKey* begin, const InternalKey* end) &#123; std::vector&lt;FileMetaData*&gt; inputs; /// 获取指定level，指定范围内的范围重叠的文件 current_-&gt;GetOverlappingInputs(level, begin, end, &amp;inputs); /// 如果指定区间内没有文件，直接返回NULL if (inputs.empty()) &#123; return NULL; &#125; // Avoid compacting too much in one shot in case the range is large. // But we cannot do this for level-0 since level-0 files can overlap // and we must not pick one file and drop another older file if the // two files overlap. /// 避免依次compact过多的sstable，控制一个level中参与compact的sstable size不大于MaxFileSizeForLevel() /// 当前是kTargetFileSize if (level &gt; 0) &#123; const uint64_t limit = MaxFileSizeForLevel(options_, level); uint64_t total = 0; for (size_t i = 0; i &lt; inputs.size(); i++) &#123; uint64_t s = inputs[i]-&gt;file_size; total += s; /// 控制输入的文件的大小 if (total &gt;= limit) &#123; inputs.resize(i + 1); break; &#125; &#125; &#125; Compaction* c = new Compaction(options_, level); /// 输入文件的版本 c-&gt;input_version_ = current_; /// 增加引用计数 c-&gt;input_version_-&gt;Ref(); /// 记录输入的文件 c-&gt;inputs_[0] = inputs; /// 获取compaction操作正确的输入文件 SetupOtherInputs(c); return c;&#125; SetupOtherInputs原则上，level+1 compaction操作输入的sstable文件只需要输入与level层区间重叠的文件，保证最后生成的level+1层的sstable文件内部不发生重叠即可。leveldb也是这么做的，但是做了一点操作在不违反非0 level的文件内部不会产生重叠的情况下尽可能扩大输入文件的范围。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/// 取得需要的其他sstable文件/// a. 从level-n中获得的sstable的key-range,然后获得与其有overlap的level-n+1中的sstable/// b. 在不扩大已经获得的所有sstable的key-range的情况下，尝试添加level-n中的sstable/// c. 获得grandparents_/// d. 更新level-n中下一次要compact的start-keyvoid VersionSet::SetupOtherInputs(Compaction* c) &#123; const int level = c-&gt;level(); InternalKey smallest, largest; /// 获得compaction操作所在的level的key的范围 GetRange(c-&gt;inputs_[0], &amp;smallest, &amp;largest); /// 获取level+1上与指定区间重叠的文件，加入c-&gt;inputs_[1] current_-&gt;GetOverlappingInputs(level+1, &amp;smallest, &amp;largest, &amp;c-&gt;inputs_[1]); // Get entire range covered by compaction /// 获取level和level+1上所有文件的区间范围 InternalKey all_start, all_limit; GetRange2(c-&gt;inputs_[0], c-&gt;inputs_[1], &amp;all_start, &amp;all_limit); // See if we can grow the number of inputs in "level" without // changing the number of "level+1" files we pick up. /// 尽可能扩充选中的文件数量，又做到不违背大于1的level内部文件之间发生重叠 if (!c-&gt;inputs_[1].empty()) &#123; std::vector&lt;FileMetaData*&gt; expanded0; /// 获取更新范围之后的level上重叠的文件列表 current_-&gt;GetOverlappingInputs(level, &amp;all_start, &amp;all_limit, &amp;expanded0); const int64_t inputs0_size = TotalFileSize(c-&gt;inputs_[0]); const int64_t inputs1_size = TotalFileSize(c-&gt;inputs_[1]); /// 扩展范围的文件的大小 const int64_t expanded0_size = TotalFileSize(expanded0); if (expanded0.size() &gt; c-&gt;inputs_[0].size() &amp;&amp; inputs1_size + expanded0_size &lt; ExpandedCompactionByteSizeLimit(options_)) &#123; /// 限制compaction操作涉及的文件大小 InternalKey new_start, new_limit; /// 获取expanded之后level文件的取值范围 GetRange(expanded0, &amp;new_start, &amp;new_limit); std::vector&lt;FileMetaData*&gt; expanded1; /// 获取level+1上和[new_start,new_limit]重叠的文件列表 current_-&gt;GetOverlappingInputs(level+1, &amp;new_start, &amp;new_limit, &amp;expanded1); /// level+1上的文件没有发生扩展 if (expanded1.size() == c-&gt;inputs_[1].size()) &#123; Log(options_-&gt;info_log, "Expanding@%d %d+%d (%ld+%ld bytes) to %d+%d (%ld+%ld bytes)\n", level, int(c-&gt;inputs_[0].size()), int(c-&gt;inputs_[1].size()), long(inputs0_size), long(inputs1_size), int(expanded0.size()), int(expanded1.size()), long(expanded0_size), long(inputs1_size)); smallest = new_start; largest = new_limit; /// 记录更新之后输入的文件 c-&gt;inputs_[0] = expanded0; c-&gt;inputs_[1] = expanded1; /// 记录更新之后的level和level+1上的总区间范围到[all_start,all_limit] GetRange2(c-&gt;inputs_[0], c-&gt;inputs_[1], &amp;all_start, &amp;all_limit); &#125; &#125; &#125; // Compute the set of grandparent files that overlap this compaction // (parent == level+1; grandparent == level+2) /// 记录grandparents_在[all_start, all_limit]范围内的重叠的文件 if (level + 2 &lt; config::kNumLevels) &#123; /// 和[all_start,all_limit]区间重叠的grandparent level 文件的列表存入grandparents_之中 current_-&gt;GetOverlappingInputs(level + 2, &amp;all_start, &amp;all_limit, &amp;c-&gt;grandparents_); &#125; /// never happen if (false) &#123; Log(options_-&gt;info_log, "Compacting %d '%s' .. '%s'", level, smallest.DebugString().c_str(), largest.DebugString().c_str()); &#125; // Update the place where we will do the next compaction for this level. // We update this immediately instead of waiting for the VersionEdit // to be applied so that if the compaction fails, we will try a different // key range next time. /// 记录当前level compact操作后最大的key compact_pointer_[level] = largest.Encode().ToString(); c-&gt;edit_.SetCompactPointer(level, largest);&#125; if (!c-&gt;inputs_[1].empty()) {之后的代码是干什么的呢？是为了尽可能在遵守现有规则的情况下扩大输入文件的范围。 上图中，根据level n的输入文件A，可以选中level n+1上与A区间重叠的3个文件作为输入一起进行compaction操作。我们可以发现实际上可以将level n上的E文件加入，而不会扩充level n+1层需要输入的文件。 但是，在如图下述情况下，就不能把文件E加入作为level n上的输入文件。因为，这样就需要把level n+1上的F文件牵扯进来，这不是我们想要的。 可是，下述情况却是可以的，因为我们没有牵扯到level n+1上更多的文件。 当然，扩充之后的文件空间大小之和也不可以超出限制： 12inputs1_size + expanded0_size &lt; ExpandedCompactionByteSizeLimit(options_)]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[leveldb Version和VersionEdit]]></title>
    <url>%2F2017%2F06%2F24%2Fleveldb-Version%E5%92%8CVersionEdit%2F</url>
    <content type="text"><![CDATA[leveldb中的版本控制在leveldb之中，随着插入的数据不断增加，数据从memtable不断向更高level的sstable迁移，leveldb内部管理的各个level的文件内容不断发生变化，这种数据的迁移在leveldb内部通过版本控制进行管理。 版本管理通过3个数据结构进行管理，Version表示某一个特定的版本，包括这个版本各个level的文件以及其他数据库相关文件等，VersionEdit表示从上一个版本变更到下一个版本的变化量，将VersionEdit应用到上一个Version之上就得到了更新之后的Version。而VersionSet则用于leveldb的版本管理，其中维护了当前使用的各种版本，特别是最新版本。 VersionVersion类定义如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150class Version &#123; public: // Append to *iters a sequence of iterators that will // yield the contents of this Version when merged together. // REQUIRES: This version has been saved (see VersionSet::SaveTo) /// 向iters加入当前Version的内容对应的iterator，在合并之前内容不会修改 /// 对level0和其他level做了区分处理 /// 当前level所有文件的iterator加入iters中 void AddIterators(const ReadOptions&amp;, std::vector&lt;Iterator*&gt;* iters); struct GetStats &#123; FileMetaData* seek_file; // 查找的文件 int seek_file_level; // 查找的文件的level &#125;; // Lookup the value for key. If found, store it in *val and // return OK. Else return a non-OK status. Fills *stats. // REQUIRES: lock is not held /// 查找key的value，若找到了存储在*val之中，并返回OK，否则返回non-OK status。记录stats。 /// 要求：没有持有锁 Status Get(const ReadOptions&amp;, const LookupKey&amp; key, std::string* val, GetStats* stats); // Adds "stats" into the current state. Returns true if a new // compaction may need to be triggered, false otherwise. // REQUIRES: lock is held /// 将stats添加到当前的state之中。如果需要compaction返回true，否则返回false。 /// 要求：已经持有锁 bool UpdateStats(const GetStats&amp; stats); // Record a sample of bytes read at the specified internal key. // Samples are taken approximately once every config::kReadBytesPeriod // bytes. Returns true if a new compaction may need to be triggered. // REQUIRES: lock is held /// 读 指定key的a sample of bytes 。具体读多少数据取决于config::kReadBytesPeriod /// 如果触发了新的compaction就返回true。 /// 要求：持有锁 bool RecordReadSample(Slice key); // Reference count management (so Versions do not disappear out from // under live iterators) /// 引用计数管理, 所以对应iterator存活时，Versions不会消失 void Ref(); void Unref(); /// 在*input保存所有level对应的和[begin,end]overlap的文件 void GetOverlappingInputs( int level, const InternalKey* begin, // NULL means before all keys const InternalKey* end, // NULL means after all keys std::vector&lt;FileMetaData*&gt;* inputs); // Returns true iff some file in the specified level overlaps // some part of [*smallest_user_key,*largest_user_key]. // smallest_user_key==NULL represents a key smaller than all keys in the DB. // largest_user_key==NULL represents a key largest than all keys in the DB. /// 若指定level中的文件和[*smallest_user_key,*largest_user_key]区间重叠就返回true bool OverlapInLevel(int level, const Slice* smallest_user_key, const Slice* largest_user_key); // Return the level at which we should place a new memtable compaction // result that covers the range [smallest_user_key,largest_user_key]. /// 新的dump的memtable的结果涵盖的key的范围是[smallest_user_key,largest_user_key] /// 返回应该被放置在哪一个level之上 int PickLevelForMemTableOutput(const Slice&amp; smallest_user_key, const Slice&amp; largest_user_key); /// 返回对应level的文件数目 int NumFiles(int level) const &#123; return files_[level].size(); &#125; // Return a human readable string that describes this version's contents. /// debug 字符串 std::string DebugString() const; private: friend class Compaction; friend class VersionSet; class LevelFileNumIterator; Iterator* NewConcatenatingIterator(const ReadOptions&amp;, int level) const; // Call func(arg, level, f) for every file that overlaps user_key in // order from newest to oldest. If an invocation of func returns // false, makes no more calls. // // REQUIRES: user portion of internal_key == user_key. /// 按照由新到旧的顺序，和user_key重合的file，都执行函数func(arg, level, f), 若执行func的结果 /// 为false，就break void ForEachOverlapping(Slice user_key, Slice internal_key, void* arg, bool (*func)(void*, int, FileMetaData*)); /// 当前Version属于哪一个VersionSet VersionSet* vset_; // VersionSet to which this Version belongs /// 链表中的下一个version Version* next_; // Next version in linked list /// 链表中的上一个version Version* prev_; // Previous version in linked list /// 引用计数 int refs_; // Number of live refs to this version // List of files per level /// 每个level对应的链表 std::vector&lt;FileMetaData*&gt; files_[config::kNumLevels]; /* sstable的seek次数达到一定的阈值的时候，可以认为它处在不最优的情况，而我们认为compact后 会倾向于均衡的状态，所以在一个sstable的seek次数达到一定的阈值后，主动对其进行compact是合理的。 */ /* 这个具体 seek 次数阈值(allowed_seeks)的确定，依赖于 sas 盘的 IO 性能: a. 一次磁盘寻道seek耗费10ms。 b. 读或者写 1M 数据耗费 10ms (按 100M/s IO 吞吐能力)。 c. compact 1M 的数据需要 25M 的 IO:从 level-n 中读 1M 数据，从 level-n+1 中读 10~12M 数据，写入 level-n+1 中 10~12M 数据。 所以，compact 1M 的数据的时间相当于做 25 次磁盘 seek，反过来说就是，1 次 seek 相当于 compact 40k 数据。那么，可以得到 seek 阈值 allowed_seeks=sstable_size / 40k。保守设置， 当前实际的 allowed_seeks = sstable_size / 10k。 每次 compact 完成，构造新的 Version 时 (Builder::Apply()),每个 sstable 的 allowed_seeks 会计算出来保存在 FileMetaData。 在每次 get 操作的时候，如果有超过一个 sstable 文件进行了 IO，会将最后一个 IO 的 sstable 的 allowed_seeks 减一， 并检查其是否已经用光了 allowed_seeks,若是，则将该 sstable 记录成当前 Version 的 file_to_compact_,并记录其所在的 level(file_to_compact_level_)。 */ // Next file to compact based on seek stats. /// 经seek stats评估的下一个需要compact的文件 FileMetaData* file_to_compact_; /// 将要compact的文件的level int file_to_compact_level_; // Level that should be compacted next and its compaction score. // Score &lt; 1 means compaction is not strictly needed. These fields // are initialized by Finalize(). /// compaction 评分，Score &lt; 1 意味着compaction在严格意义上不需要 double compaction_score_; /// compaction 操作所在的level int compaction_level_; explicit Version(VersionSet* vset) : vset_(vset), next_(this), prev_(this), refs_(0), file_to_compact_(NULL), file_to_compact_level_(-1), compaction_score_(-1), compaction_level_(-1) &#123; &#125; /// destructor of Version ~Version(); // No copying allowed Version(const Version&amp;); void operator=(const Version&amp;);&#125;; 每一个Version主要管理当前版本的文件，即files_。leveldb在进行版本管理时，将所有的Version当做链表中的一个结点连接起来，其中链表的头结点对应当前最新的Version。 AddIteratorsAddIterators方法将当前Version管理的所有文件的迭代器返回给调用者。因为level-0上的sstable文件内部可能会重叠，而其他level内部的文件不会重叠，重叠只会发生在不同level之间。因而，level-0级别的sstable每一个文件需要生成一个迭代器，其他level每个level生成一个迭代器。 123456789101112131415161718192021void Version::AddIterators(const ReadOptions&amp; options, std::vector&lt;Iterator*&gt;* iters) &#123; /// 将所有level0对应的iterators加入iters // Merge all level zero files together since they may overlap for (size_t i = 0; i &lt; files_[0].size(); i++) &#123; /// two level iterator，from index block handle iterator to record iters-&gt;push_back( vset_-&gt;table_cache_-&gt;NewIterator( options, files_[0][i]-&gt;number, files_[0][i]-&gt;file_size)); &#125; // For levels &gt; 0, we can use a concatenating iterator that sequentially // walks through the non-overlapping files in the level, opening them // lazily. for (int level = 1; level &lt; config::kNumLevels; level++) &#123; if (!files_[level].empty()) &#123; /// two level itertor, from LevelFileNumIterator to sstable iterator iters-&gt;push_back(NewConcatenatingIterator(options, level)); &#125; &#125;&#125; ConcatenatingIterator实际上本质上是一个TwoLevelIterator，完成从LevelFileNumIterator到sstable Iterator之间的转换。 12345678910111213141516171819202122static Iterator* GetFileIterator(void* arg, const ReadOptions&amp; options, const Slice&amp; file_value) &#123; TableCache* cache = reinterpret_cast&lt;TableCache*&gt;(arg); // file number and file size 占用空间大小为16bytes if (file_value.size() != 16) &#123; return NewErrorIterator( Status::Corruption("FileReader invoked with unexpected value")); &#125; else &#123; /// 返回file_number和file_size指定的sstable文件的iterator return cache-&gt;NewIterator(options, DecodeFixed64(file_value.data()), // file number DecodeFixed64(file_value.data() + 8)); // file size &#125;&#125;Iterator* Version::NewConcatenatingIterator(const ReadOptions&amp; options, int level) const &#123; /// same level file -&gt; sstable iterator return NewTwoLevelIterator( new LevelFileNumIterator(vset_-&gt;icmp_, &amp;files_[level]), &amp;GetFileIterator, vset_-&gt;table_cache_, options);&#125; GetGet函数从当前Version管理的sstable文件之中获取key对应的value。它依次遍历每个level的sstable文件进行查找，直到找到指定的key。对于level-0，它将和key区间重叠的每个sstable文件都取出来查找。而因为其他level内部文件不会发生区间重叠，因而只会取出一个和key区间重叠的文件进行查找。level-0的sstable，优先处理更新的文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117/// 从当前version所管理的sstable之中进行搜索/// 查找key的value，若找到了存储在*val之中，并返回OK，否则返回non-OK status。记录stats。/// 要求：没有持有锁Status Version::Get(const ReadOptions&amp; options, const LookupKey&amp; k, std::string* value, GetStats* stats) &#123; /// get internal_key slice from k Slice ikey = k.internal_key(); /// get user key from k Slice user_key = k.user_key(); const Comparator* ucmp = vset_-&gt;icmp_.user_comparator(); Status s; stats-&gt;seek_file = NULL; stats-&gt;seek_file_level = -1; FileMetaData* last_file_read = NULL; int last_file_read_level = -1; // We can search level-by-level since entries never hop across // levels. Therefore we are guaranteed that if we find data // in an smaller level, later levels are irrelevant. /// 因为level更小的记录的sequence number更大，因此只需要沿着level从小到大进行搜索 std::vector&lt;FileMetaData*&gt; tmp; FileMetaData* tmp2; for (int level = 0; level &lt; config::kNumLevels; level++) &#123; size_t num_files = files_[level].size(); if (num_files == 0) continue; // Get the list of files to search in this level FileMetaData* const* files = &amp;files_[level][0]; if (level == 0) &#123; // Level-0 files may overlap each other. Find all files that // overlap user_key and process them in order from newest to oldest. tmp.reserve(num_files); for (uint32_t i = 0; i &lt; num_files; i++) &#123; FileMetaData* f = files[i]; if (ucmp-&gt;Compare(user_key, f-&gt;smallest.user_key()) &gt;= 0 &amp;&amp; ucmp-&gt;Compare(user_key, f-&gt;largest.user_key()) &lt;= 0) &#123; // 发生了重叠 tmp.push_back(f); &#125; &#125; if (tmp.empty()) continue; /// 优先按照sequence number更大level0文件来查找 /// 按照sequence number进行排序, std::sort(tmp.begin(), tmp.end(), NewestFirst); /// 返回sequence最大的哪一个 files = &amp;tmp[0]; /// file的数目 num_files = tmp.size(); &#125; else &#123; // Binary search to find earliest index whose largest key &gt;= ikey. uint32_t index = FindFile(vset_-&gt;icmp_, files_[level], ikey); if (index &gt;= num_files) &#123; files = NULL; num_files = 0; &#125; else &#123; tmp2 = files[index]; /// user_key &lt; files[index] -&gt; smallest.user_key() 不满足条件, 没有发生重叠 if (ucmp-&gt;Compare(user_key, tmp2-&gt;smallest.user_key()) &lt; 0) &#123; // All of "tmp2" is past any data for user_key files = NULL; num_files = 0; &#125; else &#123; files = &amp;tmp2; num_files = 1; &#125; &#125; &#125; for (uint32_t i = 0; i &lt; num_files; ++i) &#123; /// 记录上一次seek的file以及对应的seek_file_level if (last_file_read != NULL &amp;&amp; stats-&gt;seek_file == NULL) &#123; // We have had more than one seek for this read. Charge the 1st file. /// 记录查找到记录所对应的文件以及其所在的level stats-&gt;seek_file = last_file_read; stats-&gt;seek_file_level = last_file_read_level; &#125; FileMetaData* f = files[i]; /// 上次读取的file last_file_read = f; /// 上次读取的level last_file_read_level = level; Saver saver; saver.state = kNotFound; saver.ucmp = ucmp; saver.user_key = user_key; saver.value = value; /// 获取对应sstable，将读取的结果使用saver进行保存 s = vset_-&gt;table_cache_-&gt;Get(options, f-&gt;number, f-&gt;file_size, ikey, &amp;saver, SaveValue); if (!s.ok()) &#123; return s; &#125; /// 实际上，若第一次循环便返回，后续循环也不会进行了 switch (saver.state) &#123; case kNotFound: ///!!! 继续在其他文件之中搜索 break; // Keep searching in other files case kFound: return s; /// the same as kNotFound case kDeleted: s = Status::NotFound(Slice()); // Use empty error message for speed return s; case kCorrupt: s = Status::Corruption("corrupted key for ", user_key); return s; &#125; &#125; &#125; // 没有找到对应的key return Status::NotFound(Slice()); // Use an empty error message for speed&#125; PickLevelForMemTableOutput对于新生成的sstable文件，此函数用于选取其应该放置的level。优先将新生成的sstable文件放置在level-0上，除非其和上一级的文件没有发生重叠，并且和grandparents level的sstable重叠区间的文件体积没有超出预设值。当然，输出的level值还受到kMaxMemCompactLevel的限制。 12345678910111213141516171819202122232425262728293031323334353637/// 如果新生成的sstable与level-0中的文件有overlap，选level 0/// 向上尝试不大于kMaxMemCompactLevel的level，如果与level产生overlap，即返回/// 对于不产生overlap的level，同时考虑kMaxGrandParentOverlapBytes的阈值判断/// 对于memtable，选取其放置的levelint Version::PickLevelForMemTableOutput( const Slice&amp; smallest_user_key, const Slice&amp; largest_user_key) &#123; int level = 0; /// 若在level0上没有重叠 if (!OverlapInLevel(0, &amp;smallest_user_key, &amp;largest_user_key)) &#123; // Push to next level if there is no overlap in next level, // and the #bytes overlapping in the level after that are limited. InternalKey start(smallest_user_key, kMaxSequenceNumber, kValueTypeForSeek); InternalKey limit(largest_user_key, 0, static_cast&lt;ValueType&gt;(0)); std::vector&lt;FileMetaData*&gt; overlaps; // memtable dump成的sstable，允许推向的最高level, 默认设置为2 while (level &lt; config::kMaxMemCompactLevel) &#123; /// 若和level + 1发生了重叠，那么break if (OverlapInLevel(level + 1, &amp;smallest_user_key, &amp;largest_user_key)) &#123; break; &#125; if (level + 2 &lt; config::kNumLevels) &#123; // Check that file does not overlap too many grandparent bytes. GetOverlappingInputs(level + 2, &amp;start, &amp;limit, &amp;overlaps); const int64_t sum = TotalFileSize(overlaps); /// 重叠的文件总空间是否超出指定值20MB /// 为了限制和grandparent level overlap的数据的总量 if (sum &gt; MaxGrandParentOverlapBytes(vset_-&gt;options_)) &#123; break; &#125; &#125; level++; &#125; &#125; /// 若在level0上发生了重叠，那么新dump的memtable文件也加入level0 return level;&#125; RecordReadSample在leveldb中认为更高level的sstable文件更加倾向于平衡，能够减少查询时访问的文件的数目。若为了访问某个值，从某个文件开始进行查找，并且不在这个文件之中，那么说明此文件应该被推向更高的level，来减少未来更多的seek操作的开销。在leveldb之中，每个sstable文件预设的阈值为max(sstable_size / 10K)，若某文件seek操作符合上述情况达到此次数，就会被标记，未来会在后台线程之中被进行compaction处理。RecordReadSample函数就是为了记录此情况而设的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445/// 对于输入的internalkey在重叠的文件上都执行Match函数，记录对于internal_key重叠的次数/// 次数达到2次，就执行UpdateStats，减少f的allowed_seeks, 递减到0，就将其作为我们执行compaction的起点bool Version::RecordReadSample(Slice internal_key) &#123; ParsedInternalKey ikey; /// 解析InternalKey失败 if (!ParseInternalKey(internal_key, &amp;ikey)) &#123; return false; &#125; struct State &#123; GetStats stats; // Holds first matching file int matches; static bool Match(void* arg, int level, FileMetaData* f) &#123; State* state = reinterpret_cast&lt;State*&gt;(arg); state-&gt;matches++; /// 只记住第一次match时所对应的文件和level if (state-&gt;matches == 1) &#123; // Remember first match. state-&gt;stats.seek_file = f; state-&gt;stats.seek_file_level = level; &#125; // We can stop iterating once we have a second match. /// 如果已经发生了两次level级别的重叠，那么直接暂停，不再尝试寻找 /// 新的overlapping return state-&gt;matches &lt; 2; &#125; &#125;; State state; state.matches = 0; ForEachOverlapping(ikey.user_key, internal_key, &amp;state, &amp;State::Match); // Must have at least two matches since we want to merge across // files. But what if we have a single file that contains many // overwrites and deletions? Should we have another mechanism for // finding such files? /// 如果和两个以上的level发生重叠，那么调用UpdateStats，减少allowed_seeks /// 若递减到0，就需要触发compaction if (state.matches &gt;= 2) &#123; // 1MB cost is about 1 seek (see comment in Builder::Apply). return UpdateStats(state.stats); &#125; return false;&#125; VersionEditVersion之中，管理每个特定的sstable文件使用此数据结构进行描述：12345678910struct FileMetaData &#123; int refs; // reference count int allowed_seeks; // Seeks allowed until compaction compact之前允许的seek次数 uint64_t number; // number of file uint64_t file_size; // File size in bytes InternalKey smallest; // Smallest internal key served by table / sstable文件的最小key InternalKey largest; // Largest internal key served by table / sstable文件的最大key FileMetaData() : refs(0), allowed_seeks(1 &lt;&lt; 30), file_size(0) &#123; &#125;&#125;; VersionEdit记录了下一个Version相对于上一个Version之间的变化。它有自己的序列化和反序列化方法，序列化之后的字符串会记录在manifest文件之中，记录数据库最新的版本信息。 VersionEdit的主要成员如下所示： 12345678910111213141516std::string comparator_; // 比较器的名称uint64_t log_number_; // 日志文件编号uint64_t prev_log_number_; // 上一个日志文件编号uint64_t next_file_number_; // 下一个日志文件编号SequenceNumber last_sequence_; // 上一个序列号bool has_comparator_; // 是否有比较器bool has_log_number_; // 是否有log numberbool has_prev_log_number_; // 是否有上一个log numberbool has_next_file_number_; // 是否有下一个file numberbool has_last_sequence_; // 是否有上一个sequence// 压缩点&lt;层次，InternalKey键&gt;std::vector&lt; std::pair&lt;int, InternalKey&gt; &gt; compact_pointers_;// 删除文件集合DeletedFileSet deleted_files_;// 新添加的文件集合std::vector&lt; std::pair&lt;int, FileMetaData&gt; &gt; new_files_; 按照上图格式定义，就能很轻松地看懂序列化和反序列化的相关代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/// Encode VersionEdit into string specified by dstvoid VersionEdit::EncodeTo(std::string* dst) const &#123; /// has comparator, put tag and comparator name into dst if (has_comparator_) &#123; PutVarint32(dst, kComparator); PutLengthPrefixedSlice(dst, comparator_); &#125; /// has log number, put kLogNumber tag and log_number_ if (has_log_number_) &#123; PutVarint32(dst, kLogNumber); PutVarint64(dst, log_number_); &#125; /// has prev log number, put kPrevLogNumber tag and prev_log_number_ if (has_prev_log_number_) &#123; PutVarint32(dst, kPrevLogNumber); PutVarint64(dst, prev_log_number_); &#125; /// has next file number, put kNextFileNumber tag and next_file_number_ if (has_next_file_number_) &#123; PutVarint32(dst, kNextFileNumber); PutVarint64(dst, next_file_number_); &#125; /// has last_sequence, put kLastSequence tag and last_sequence_ if (has_last_sequence_) &#123; PutVarint32(dst, kLastSequence); PutVarint64(dst, last_sequence_); &#125; /// put kCompactPointer tag and pair&lt;level, InternelKey&gt; of each elem of compact_pointers_ for (size_t i = 0; i &lt; compact_pointers_.size(); i++) &#123; PutVarint32(dst, kCompactPointer); PutVarint32(dst, compact_pointers_[i].first); // level PutLengthPrefixedSlice(dst, compact_pointers_[i].second.Encode()); &#125; /// put kDeletedFile tag and pair&lt;level, file number&gt; of each elem of deleted_files_ for (DeletedFileSet::const_iterator iter = deleted_files_.begin(); iter != deleted_files_.end(); ++iter) &#123; PutVarint32(dst, kDeletedFile); PutVarint32(dst, iter-&gt;first); // level PutVarint64(dst, iter-&gt;second); // file number &#125; /// put kNewFile tag and FileMetaData of each elem of new_files_ for (size_t i = 0; i &lt; new_files_.size(); i++) &#123; const FileMetaData&amp; f = new_files_[i].second; PutVarint32(dst, kNewFile); PutVarint32(dst, new_files_[i].first); // level PutVarint64(dst, f.number); PutVarint64(dst, f.file_size); PutLengthPrefixedSlice(dst, f.smallest.Encode()); PutLengthPrefixedSlice(dst, f.largest.Encode()); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111/// Decode VersionEdit from string specified by srcStatus VersionEdit::DecodeFrom(const Slice&amp; src) &#123; /// 首先进行清理 Clear(); Slice input = src; /// 用于记录出错消息 const char* msg = NULL; uint32_t tag; // Temporary storage for parsing /// temporary usage int level; uint64_t number; FileMetaData f; Slice str; InternalKey key; while (msg == NULL &amp;&amp; GetVarint32(&amp;input, &amp;tag)) &#123; /// 读取tag switch (tag) &#123; case kComparator: if (GetLengthPrefixedSlice(&amp;input, &amp;str)) &#123; comparator_ = str.ToString(); has_comparator_ = true; &#125; else &#123; msg = "comparator name"; &#125; break; case kLogNumber: if (GetVarint64(&amp;input, &amp;log_number_)) &#123; has_log_number_ = true; &#125; else &#123; msg = "log number"; &#125; break; case kPrevLogNumber: if (GetVarint64(&amp;input, &amp;prev_log_number_)) &#123; has_prev_log_number_ = true; &#125; else &#123; msg = "previous log number"; &#125; break; case kNextFileNumber: if (GetVarint64(&amp;input, &amp;next_file_number_)) &#123; has_next_file_number_ = true; &#125; else &#123; msg = "next file number"; &#125; break; case kLastSequence: if (GetVarint64(&amp;input, &amp;last_sequence_)) &#123; has_last_sequence_ = true; &#125; else &#123; msg = "last sequence number"; &#125; break; /// get compact pointer case kCompactPointer: if (GetLevel(&amp;input, &amp;level) &amp;&amp; GetInternalKey(&amp;input, &amp;key)) &#123; compact_pointers_.push_back(std::make_pair(level, key)); &#125; else &#123; msg = "compaction pointer"; &#125; break; /// get deleted files case kDeletedFile: if (GetLevel(&amp;input, &amp;level) &amp;&amp; GetVarint64(&amp;input, &amp;number)) &#123; deleted_files_.insert(std::make_pair(level, number)); &#125; else &#123; msg = "deleted file"; &#125; break; /// get elem of new_files_ case kNewFile: if (GetLevel(&amp;input, &amp;level) &amp;&amp; GetVarint64(&amp;input, &amp;f.number) &amp;&amp; GetVarint64(&amp;input, &amp;f.file_size) &amp;&amp; GetInternalKey(&amp;input, &amp;f.smallest) &amp;&amp; GetInternalKey(&amp;input, &amp;f.largest)) &#123; new_files_.push_back(std::make_pair(level, f)); &#125; else &#123; msg = "new-file entry"; &#125; break; default: msg = "unknown tag"; break; &#125; &#125; /// 输入没有读取完，并且记录的出错消息为NULL if (msg == NULL &amp;&amp; !input.empty()) &#123; msg = "invalid tag"; &#125; Status result; /// 出错了 if (msg != NULL) &#123; result = Status::Corruption("VersionEdit", msg); &#125; return result;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb table_cache解析]]></title>
    <url>%2F2017%2F06%2F23%2Fleveldb-table-cache%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介leveldb在打开sstable的时候，会将这个sstable对应的table 句柄存入cache。cache内部基于LRU算法进行管理，默认cache的容积为990，也就是说leveldb默认情况下最多能同时打开的sstable文件的数目为990个。在执行compaction操作时，创建的sstable也会加入此cache。同样，在执行sstable上的查找时，所打开的sstable文件也会存入table cache之中。在leveldb中，默认执行随机文件读写操作是基于PosixMmapReadableFile。若table cache之中的一条记录离开了，会执行下述函数： 12345678/// delete table, file, and TableAndFile object allocated on heapstatic void DeleteEntry(const Slice&amp; key, void* value) &#123; TableAndFile* tf = reinterpret_cast&lt;TableAndFile*&gt;(value); delete tf-&gt;table; /// 此处关闭了打开的文件 delete tf-&gt;file; delete tf;&#125; leveldb基于lru cache限制了打开文件的数目，减少了对内存的占用。 实现TableCache使用file_number作为key来存储sstable的句柄信息。在执行查找table操作时，若没有找到对应的记录，会根据输入的file_number打开对应的sstable文件，并且将其存入TableCache之中。 123456789101112131415161718192021222324252627282930313233343536373839404142Status TableCache::FindTable(uint64_t file_number, uint64_t file_size, Cache::Handle** handle) &#123; Status s; /// use file_number as key char buf[sizeof(file_number)]; EncodeFixed64(buf, file_number); Slice key(buf, sizeof(buf)); *handle = cache_-&gt;Lookup(key); if (*handle == NULL) &#123; std::string fname = TableFileName(dbname_, file_number); RandomAccessFile* file = NULL; Table* table = NULL; ///首先尝试ldb文件，再尝试sst文件 s = env_-&gt;NewRandomAccessFile(fname, &amp;file); if (!s.ok()) &#123; std::string old_fname = SSTTableFileName(dbname_, file_number); if (env_-&gt;NewRandomAccessFile(old_fname, &amp;file).ok()) &#123; s = Status::OK(); &#125; &#125; if (s.ok()) &#123; /// 打开sstable s = Table::Open(*options_, file, file_size, &amp;table); &#125; if (!s.ok()) &#123; assert(table == NULL); delete file; // We do not cache error results so that if the error is transient, // or somebody repairs the file, we recover automatically. &#125; else &#123; /// 记录sstable，file object TableAndFile* tf = new TableAndFile; tf-&gt;file = file; tf-&gt;table = table; /// 占用cache_的空间为1，表示一条记录。 /// 通过cache_控制打开的文件的数目 *handle = cache_-&gt;Insert(key, tf, 1, &amp;DeleteEntry); &#125; &#125; return s;&#125; 从TableCache之中删除记录，将输入的file_number作为key，在TableCache中删除对应的记录。 123456/// 从cache中删除file_number对应的记录void TableCache::Evict(uint64_t file_number) &#123; char buf[sizeof(file_number)]; EncodeFixed64(buf, file_number); cache_-&gt;Erase(Slice(buf, sizeof(buf)));&#125; 获取file_number指定文件的sstable的Iterator，首先执行FindTable获取对应sstable的句柄，然后返回sstable的Iterator。在Iterator存活期间，此记录在TableCache之中不能被删除。在Iterator被析构时，需要执行Release操作，通知Cache此sstable对应的记录可以被安全地清理。 1234567891011121314151617181920212223242526272829303132333435Iterator* TableCache::NewIterator(const ReadOptions&amp; options, uint64_t file_number, uint64_t file_size, Table** tableptr) &#123; if (tableptr != NULL) &#123; *tableptr = NULL; &#125; Cache::Handle* handle = NULL; Status s = FindTable(file_number, file_size, &amp;handle); if (!s.ok()) &#123; return NewErrorIterator(s); &#125; /// 获取sstable对象 Table* table = reinterpret_cast&lt;TableAndFile*&gt;(cache_-&gt;Value(handle))-&gt;table; Iterator* result = table-&gt;NewIterator(options); // when destruct, release from cache result-&gt;RegisterCleanup(&amp;UnrefEntry, cache_, handle); if (tableptr != NULL) &#123; /// 记录对应的sstable *tableptr = table; &#125; return result;&#125;/// 注册的清理函数static void UnrefEntry(void* arg1, void* arg2) &#123; /// get cache ptr Cache* cache = reinterpret_cast&lt;Cache*&gt;(arg1); /// get cache data Cache::Handle* h = reinterpret_cast&lt;Cache::Handle*&gt;(arg2); /// release data to cache cache-&gt;Release(h);&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb snapshot解析]]></title>
    <url>%2F2017%2F06%2F23%2Fleveldb-snapshot%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介在leveldb之中，提供了快照机制，保证不同时刻定义的iterator能够获得与当前时刻保持一致的视图，在遍历访问数据库时仍然可以对数据库进行修改，而不用锁死整个数据库。 获取快照实际上是返回当前最新的读写记录的sequence number，并将这个值记录在链表之中。 12345const Snapshot* DBImpl::GetSnapshot() &#123; /// 记录当前version构建snapshot对象，并将其插入链表之中 MutexLock l(&amp;mutex_); return snapshots_.New(versions_-&gt;LastSequence());&#125; 除非进行compaction操作，否则具有相同key但是sequence number不同的记录不会精简只保留sequence number最大的哪一个。leveldb保证在compaction操作时，不会将user key相同，但sequence number大于取出的snapshots列表中最小的那个snapshot的记录删除。 1234567891011121314151617181920212223242526272829// db/db_impl.cc DoCompactionWork... if (snapshots_.empty()) &#123; /// 记录最小的snapshots_编号 compact-&gt;smallest_snapshot = versions_-&gt;LastSequence(); &#125; else &#123; /// 取snapshot列表之中最小的sequence number compact-&gt;smallest_snapshot = snapshots_.oldest()-&gt;number_; &#125;... /// 若sequence number 小于 snapshot list中最小的那个sequence number if (last_sequence_for_key &lt;= compact-&gt;smallest_snapshot) &#123; // Hidden by an newer entry for same user key drop = true; // (A) &#125; /// key是删除的，并且该key不位于指定的Snapshot之内，并且key在level-n+1以上的level中 /// 不存在，则丢弃 else if (ikey.type == kTypeDeletion &amp;&amp; ikey.sequence &lt;= compact-&gt;smallest_snapshot &amp;&amp; compact-&gt;compaction-&gt;IsBaseLevelForKey(ikey.user_key)) &#123; // For this user key: // (1) there is no data in higher levels // (2) data in lower levels will have larger sequence numbers // (3) data in layers that are being compacted here and have // smaller sequence numbers will be dropped in the next // few iterations of this loop (by rule (A) above). // Therefore this deletion marker is obsolete and can be dropped. drop = true; &#125; 实现snapshot的实现是基于一个简单的双向链表，链表中每一个结点都记录一个sequence number。双向链表的末尾对应的是sequence number最小的snapshot。 1234567891011121314/// snapshots存在DB的双向链表之中，每一个SnapshotImpl对应一个结点class SnapshotImpl : public Snapshot &#123; public: SequenceNumber number_; // const after creation private: friend class SnapshotList; // SnapshotImpl is kept in a doubly-linked circular list SnapshotImpl* prev_; SnapshotImpl* next_; SnapshotList* list_; // just for sanity checks&#125;; 双向环形链表： 12345678910111213141516171819202122232425262728293031323334353637class SnapshotList &#123; public: SnapshotList() &#123; list_.prev_ = &amp;list_; list_.next_ = &amp;list_; &#125; bool empty() const &#123; return list_.next_ == &amp;list_; &#125; SnapshotImpl* oldest() const &#123; assert(!empty()); return list_.next_; &#125; SnapshotImpl* newest() const &#123; assert(!empty()); return list_.prev_; &#125; /// 在链表头部插入一个新的结点 const SnapshotImpl* New(SequenceNumber seq) &#123; /// 创建结点 SnapshotImpl* s = new SnapshotImpl; /// 记录sequence s-&gt;number_ = seq; s-&gt;list_ = this; s-&gt;next_ = &amp;list_; s-&gt;prev_ = list_.prev_; s-&gt;prev_-&gt;next_ = s; s-&gt;next_-&gt;prev_ = s; return s; &#125; /// 从list中删除s所对应的节点 void Delete(const SnapshotImpl* s) &#123; assert(s-&gt;list_ == this); s-&gt;prev_-&gt;next_ = s-&gt;next_; s-&gt;next_-&gt;prev_ = s-&gt;prev_; delete s; &#125; private: // Dummy head of doubly-linked list of snapshots SnapshotImpl list_;&#125;;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[leveldb WriteBatch解析]]></title>
    <url>%2F2017%2F06%2F23%2Fleveldb-WriteBatch%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[介绍在leveldb之中，包括put，delete等操作都是基于对WriteBatch的操作。当多线程同时调用put时，会将put操作组合起来合并成为一个WriteBatch对象，统一写入到memtable之中。 WriteBatch的具体格式如下所示： 从图中可以发现，WriteBatch由sequence number，count和records构成，其中count记载了record的数目。sequence number是第一条record所对应的sequence number。 记录的类型有两种，分别对应添加和删除两种操作，这两种记录的格式如下所示： Put Delete 实现在WriteBatch之中，内部使用一个string存放所有的记录。按照WriteBatch的格式定义，对于Put和Delete操作，很容易理解以下代码。 12345678910111213141516171819void WriteBatch::Put(const Slice&amp; key, const Slice&amp; value) &#123; /// 更新count值 WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1); /// 类型为kTypeValue rep_.push_back(static_cast&lt;char&gt;(kTypeValue)); /// key PutLengthPrefixedSlice(&amp;rep_, key); /// value PutLengthPrefixedSlice(&amp;rep_, value);&#125;void WriteBatch::Delete(const Slice&amp; key) &#123; /// 更新Count值 WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1); /// 类型为kTypeDeletion rep_.push_back(static_cast&lt;char&gt;(kTypeDeletion)); /// 存储key PutLengthPrefixedSlice(&amp;rep_, key);&#125; 在WriteBatch之中，还提供了Iterate操作，其实质上是从前往后依次遍历WriteBatch之中内部存储的记录，将所记录的操作通过handler在memtable上执行。如果执行的record数目与count不同，说明发生了错误。 12345678910111213141516171819202122232425262728293031323334353637383940414243Status WriteBatch::Iterate(Handler* handler) const &#123; Slice input(rep_); /// rep_的大小不可能小于kHeader if (input.size() &lt; kHeader) &#123; return Status::Corruption("malformed WriteBatch (too small)"); &#125; input.remove_prefix(kHeader); Slice key, value; int found = 0; while (!input.empty()) &#123; found++; char tag = input[0]; input.remove_prefix(1); switch (tag) &#123; case kTypeValue: if (GetLengthPrefixedSlice(&amp;input, &amp;key) &amp;&amp; GetLengthPrefixedSlice(&amp;input, &amp;value)) &#123; /// 向memtable中进行插入 handler-&gt;Put(key, value); &#125; else &#123; return Status::Corruption("bad WriteBatch Put"); &#125; break; case kTypeDeletion: if (GetLengthPrefixedSlice(&amp;input, &amp;key)) &#123; /// 从memtable之中删除 handler-&gt;Delete(key); &#125; else &#123; return Status::Corruption("bad WriteBatch Delete"); &#125; break; default: return Status::Corruption("unknown WriteBatch tag"); &#125; &#125; /// iterate的数量不一致 if (found != WriteBatchInternal::Count(this)) &#123; return Status::Corruption("WriteBatch has wrong count"); &#125; else &#123; return Status::OK(); &#125;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb memtable解析]]></title>
    <url>%2F2017%2F06%2F23%2Fleveldb-memtable%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介在leveldb之中，写入的数据会首先写入到memtable之中。如果memtable写入达到上限，会转换成为immutable memtable。之后通过compaction操作，将memtable转换成为sstable进行存储。整个系统的架构如下所示： leveldb中的memtable和immutable memtable都是由数据结构skiplist来组织的。跳表中存储的数据包含用户输入的key和value，但是为了判断前后关系只需要取出key来进行比较。因而，需要自定义comparator来实现正确的比较方式。 相关操作在memtable之中，为了存储key和value的值，将二者组合起来存储需要记录二者的长度。因而，skiplist中存储的记录包含：key长度 + key + value长度 + value。此key还包括sequence number以及type。所以添加记录需要进行如下处理： 123456789101112131415161718192021222324252627void MemTable::Add(SequenceNumber s, ValueType type, const Slice&amp; key, const Slice&amp; value) &#123; // Format of an entry is concatenation of: // key_size : varint32 of internal_key.size() // key bytes : char[internal_key.size()] // value_size : varint32 of value.size() // value bytes : char[value.size()] size_t key_size = key.size(); size_t val_size = value.size(); /// sequence number + value type (bytes) size_t internal_key_size = key_size + 8; ///实际存储: internal key length + internal key + data length + data const size_t encoded_len = VarintLength(internal_key_size) + internal_key_size + VarintLength(val_size) + val_size; char* buf = arena_.Allocate(encoded_len); char* p = EncodeVarint32(buf, internal_key_size); memcpy(p, key.data(), key_size); p += key_size; EncodeFixed64(p, (s &lt;&lt; 8) | type); p += 8; p = EncodeVarint32(p, val_size); memcpy(p, value.data(), val_size); assert((p + val_size) - buf == encoded_len); table_.Insert(buf);&#125; 而搜索需要输入的是LookupKey，这是skiplist内部用于搜索的key。其中包含的是整个key的长度，user key以及value type 和 sequence number。借助skiplist提供的迭代器进行搜索，根据返回key的值和类型返回结果。 1234567891011121314151617181920212223242526272829303132333435363738bool MemTable::Get(const LookupKey&amp; key, std::string* value, Status* s) &#123; // key length, key, sequence number + value type Slice memkey = key.memtable_key(); Table::Iterator iter(&amp;table_); iter.Seek(memkey.data()); if (iter.Valid()) &#123; // entry format is: // klength varint32 // userkey char[klength] // tag uint64 // vlength varint32 // value char[vlength] // Check that it belongs to same user key. We do not check the // sequence number since the Seek() call above should have skipped // all entries with overly large sequence numbers. const char* entry = iter.key(); uint32_t key_length; const char* key_ptr = GetVarint32Ptr(entry, entry+5, &amp;key_length); if (comparator_.comparator.user_comparator()-&gt;Compare( Slice(key_ptr, key_length - 8), key.user_key()) == 0) &#123; // Correct user key const uint64_t tag = DecodeFixed64(key_ptr + key_length - 8); switch (static_cast&lt;ValueType&gt;(tag &amp; 0xff)) &#123; case kTypeValue: &#123; Slice v = GetLengthPrefixedSlice(key_ptr + key_length); value-&gt;assign(v.data(), v.size()); return true; &#125; /// 删除的记录，其标记是kTypeDeletion case kTypeDeletion: *s = Status::NotFound(Slice()); return true; &#125; &#125; &#125; return false;&#125; memtable对外提供范文的Iterator实际上是对skiplist迭代器的封装，使其符合Iterator接口。 12345678910111213141516171819202122232425262728class MemTableIterator: public Iterator &#123; public: explicit MemTableIterator(MemTable::Table* table) : iter_(table) &#123; &#125; virtual bool Valid() const &#123; return iter_.Valid(); &#125; /// seek要将key 转换为internal key virtual void Seek(const Slice&amp; k) &#123; iter_.Seek(EncodeKey(&amp;tmp_, k)); &#125; virtual void SeekToFirst() &#123; iter_.SeekToFirst(); &#125; virtual void SeekToLast() &#123; iter_.SeekToLast(); &#125; virtual void Next() &#123; iter_.Next(); &#125; virtual void Prev() &#123; iter_.Prev(); &#125; virtual Slice key() const &#123; return GetLengthPrefixedSlice(iter_.key()); &#125; virtual Slice value() const &#123; Slice key_slice = GetLengthPrefixedSlice(iter_.key()); /// 存储value 也是长度(varint32) + 数据 return GetLengthPrefixedSlice(key_slice.data() + key_slice.size()); &#125; virtual Status status() const &#123; return Status::OK(); &#125; private: MemTable::Table::Iterator iter_; std::string tmp_; // For passing to EncodeKey // No copying allowed MemTableIterator(const MemTableIterator&amp;); void operator=(const MemTableIterator&amp;);&#125;; skiplist内部使用的比较器是基于user key, sequence number以及value type进行比较的，如下所示： int MemTable::KeyComparator::operator()(const char* aptr, const char* bptr) const { // Internal keys are encoded as length-prefixed strings. Slice a = GetLengthPrefixedSlice(aptr); Slice b = GetLengthPrefixedSlice(bptr); /// compare internal key return comparator.Compare(a, b); }]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb log模块解析]]></title>
    <url>%2F2017%2F06%2F23%2Fleveldb-log%E6%A8%A1%E5%9D%97%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介leveldb在写入数据的时候，不仅将数据写入memtable，而且写入到log文件之后才认为写入完成。log是通过追加写入，保证了写入速度；数据落盘之后才对外提供访问，保证了数据的完整性。数据库在重新打开时，会从log文件之中恢复memtable文件的数据。 leveldb在存储log记录的时候，log文件内部的格式如下图所示： 整个log文件由很多个数据块构成，如果一条记录能够完整地存储在当前数据块之中，其类型应该为FULL。如果一条record分散地存储在不同的数据块之中，则他会被分解成几个record，每个record的类型分别按照先后顺序对应FIRST，MIDDLE或者LAST。 1234567891011enum RecordType &#123; // Zero is reserved for preallocated files kZeroType = 0, kFullType = 1, // 记录在块内部已经完整了 // For fragments kFirstType = 2, // 开头 kMiddleType = 3, // 中间 kLastType = 4 // 结尾&#125;; 为了保证每一条数据的数据完整性，记录数据类型，每一条具体的记录又由检验码，记录长度，类型和数据构成。 写入log记录写入记录时，若当前块剩余空间小于kHeaderSize，填充全0。对于写入的记录，根据当前块剩余大小以及剩余要写入的数据量的大小确定其所属的类型，然后将其写入到log文件之中。每一次写入之后都会flush文件，保证数据完整落盘。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/// 向数据块之中添加记录Status Writer::AddRecord(const Slice&amp; slice) &#123; const char* ptr = slice.data(); // 剩余需要写入的数据量 size_t left = slice.size(); // Fragment the record if necessary and emit it. Note that if slice // is empty, we still want to iterate once to emit a single // zero-length record /// 如果slice是空的，我们仍然会产生一个0长度的记录 Status s; bool begin = true; do &#123; /// 剩余空间 const int leftover = kBlockSize - block_offset_; assert(leftover &gt;= 0); /// 剩余空间不足以写入header，填充全0 if (leftover &lt; kHeaderSize) &#123; // Switch to a new block if (leftover &gt; 0) &#123; // Fill the trailer (literal below relies on kHeaderSize being 7) assert(kHeaderSize == 7); /// 块剩余的空间填充全0 dest_-&gt;Append(Slice("\x00\x00\x00\x00\x00\x00", leftover)); &#125; block_offset_ = 0; &#125; // Invariant: we never leave &lt; kHeaderSize bytes in a block. assert(kBlockSize - block_offset_ - kHeaderSize &gt;= 0); /// 可用空间 const size_t avail = kBlockSize - block_offset_ - kHeaderSize; /// 分段长度 const size_t fragment_length = (left &lt; avail) ? left : avail; RecordType type; const bool end = (left == fragment_length); if (begin &amp;&amp; end) &#123; // 全部放入此数据块中 type = kFullType; &#125; else if (begin) &#123; // 数据的开始部分放入此数据块中 type = kFirstType; &#125; else if (end) &#123; // 数据的结束部分放入此数据块中 type = kLastType; &#125; else &#123; type = kMiddleType; // 数据的中间部分放入此数据块中 &#125; s = EmitPhysicalRecord(type, ptr, fragment_length); ptr += fragment_length; left -= fragment_length; begin = false; &#125; while (s.ok() &amp;&amp; left &gt; 0); return s;&#125;/// 存储物理记录Status Writer::EmitPhysicalRecord(RecordType t, const char* ptr, size_t n) &#123; assert(n &lt;= 0xffff); // Must fit in two bytes assert(block_offset_ + kHeaderSize + n &lt;= kBlockSize); // Format the header char buf[kHeaderSize]; /// 存储记录的长度 /// 末尾1byte buf[4] = static_cast&lt;char&gt;(n &amp; 0xff); /// 开头处1byte buf[5] = static_cast&lt;char&gt;(n &gt;&gt; 8); // type buf[6] = static_cast&lt;char&gt;(t); // Compute the crc of the record type and the payload. uint32_t crc = crc32c::Extend(type_crc_[t], ptr, n); crc = crc32c::Mask(crc); // Adjust for storage EncodeFixed32(buf, crc); // Write the header and the payload Status s = dest_-&gt;Append(Slice(buf, kHeaderSize)); if (s.ok()) &#123; /// 写入数据部分 s = dest_-&gt;Append(Slice(ptr, n)); if (s.ok()) &#123; // flush data into file /// 保证数据落盘 s = dest_-&gt;Flush(); &#125; &#125; // 更新block_offset_ block_offset_ += kHeaderSize + n; return s;&#125; 读log文件对于自定义数据格式文件来说，为了应对各种错误，读操作比写入操作实现起来需要注意更多细节。因为可能会在写入log文件的过程之中，突然因为各种原因崩溃，导致log文件写入不完整，因而读取这一部分操作需要能够正确的处理，这种错误需要进行特殊对待。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/// 读取物理记录unsigned int Reader::ReadPhysicalRecord(Slice* result) &#123; // loop forever while (true) &#123; if (buffer_.size() &lt; kHeaderSize) &#123; if (!eof_) &#123; // Last read was a full read, so this is a trailer to skip buffer_.clear(); /// 读取下一个数据块 Status status = file_-&gt;Read(kBlockSize, &amp;buffer_, backing_store_); /// 更新块级别的offset end_of_buffer_offset_ += buffer_.size(); if (!status.ok()) &#123; buffer_.clear(); ReportDrop(kBlockSize, status); eof_ = true; return kEof; &#125; else if (buffer_.size() &lt; kBlockSize) &#123; /// 读取的数据小于块大小，EOF eof_ = true; &#125; continue; &#125; else &#123; /// EOF &amp;&amp; buffer_.size() &lt; kHeaderSize // Note that if buffer_ is non-empty, we have a truncated header at the // end of the file, which can be caused by the writer crashing in the // middle of writing the header. Instead of considering this an error, // just report EOF. /// 如果buffer_不为空，可能是因为writer在写入header的过程中崩溃了，这不是错误， /// 将这种情况也视为EOF buffer_.clear(); return kEof; &#125; &#125; // Parse the header const char* header = buffer_.data(); const uint32_t a = static_cast&lt;uint32_t&gt;(header[4]) &amp; 0xff; const uint32_t b = static_cast&lt;uint32_t&gt;(header[5]) &amp; 0xff; const unsigned int type = header[6]; // 获取length记录 const uint32_t length = a | (b &lt;&lt; 8); /// 一条记录的长度不可能超出数据块，除非发生错误 if (kHeaderSize + length &gt; buffer_.size()) &#123; size_t drop_size = buffer_.size(); buffer_.clear(); if (!eof_) &#123; ReportCorruption(drop_size, "bad record length"); return kBadRecord; &#125; // If the end of the file has been reached without reading |length| bytes // of payload, assume the writer died in the middle of writing the record. // Don't report a corruption. /// 假设writer在写入的过程之中崩溃，不认为是错误 return kEof; &#125; /// Zero type 的长度不可能为0，这是一个错误, record 有问题 if (type == kZeroType &amp;&amp; length == 0) &#123; // Skip zero length record without reporting any drops since // such records are produced by the mmap based writing code in // env_posix.cc that preallocates file regions. buffer_.clear(); return kBadRecord; &#125; // Check crc if (checksum_) &#123; uint32_t expected_crc = crc32c::Unmask(DecodeFixed32(header)); uint32_t actual_crc = crc32c::Value(header + 6, 1 + length); /// 报告校验失败 if (actual_crc != expected_crc) &#123; // Drop the rest of the buffer since "length" itself may have // been corrupted and if we trust it, we could find some // fragment of a real log record that just happens to look // like a valid log record. size_t drop_size = buffer_.size(); buffer_.clear(); ReportCorruption(drop_size, "checksum mismatch"); return kBadRecord; &#125; &#125; /// remove 前缀 buffer_.remove_prefix(kHeaderSize + length); // Skip physical record that started before initial_offset_ /// warning: buffer_ 已经remove了这条记录 if (end_of_buffer_offset_ - buffer_.size() - kHeaderSize - length &lt; initial_offset_) &#123; result-&gt;clear(); return kBadRecord; &#125; /// only return the record only *result = Slice(header + kHeaderSize, length); return type; &#125;&#125; 读取log记录时，根据读取的数据记录的类型，将分散的记录组合成为完整的record返回给调用者。当出现错误或者读到文件末尾时，此函数都会返回false。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133// 读取recordbool Reader::ReadRecord(Slice* record, std::string* scratch) &#123; if (last_record_offset_ &lt; initial_offset_) &#123; /// 调到initial_offset_对应的block if (!SkipToInitialBlock()) &#123; return false; &#125; &#125; scratch-&gt;clear(); record-&gt;clear(); bool in_fragmented_record = false; // 上条记录是否完整 // Record offset of the logical record that we're reading // 0 is a dummy value to make compilers happy uint64_t prospective_record_offset = 0; // 记录的偏移量 Slice fragment; while (true) &#123; /// 读取物理record const unsigned int record_type = ReadPhysicalRecord(&amp;fragment); // ReadPhysicalRecord may have only had an empty trailer remaining in its // internal buffer. Calculate the offset of the next physical record now // that it has returned, properly accounting for its header size. /// 物理记录的偏移, 指向结尾位置 uint64_t physical_record_offset = end_of_buffer_offset_ - buffer_.size() - kHeaderSize - fragment.size(); if (resyncing_) &#123; if (record_type == kMiddleType) &#123; continue; &#125; else if (record_type == kLastType) &#123; resyncing_ = false; continue; &#125; else &#123; // kFullType resyncing_ = false; &#125; &#125; switch (record_type) &#123; case kFullType: if (in_fragmented_record) &#123; // Handle bug in earlier versions of log::Writer where // it could emit an empty kFirstType record at the tail end // of a block followed by a kFullType or kFirstType record // at the beginning of the next block. if (scratch-&gt;empty()) &#123; in_fragmented_record = false; &#125; else &#123; ReportCorruption(scratch-&gt;size(), "partial record without end(1)"); &#125; &#125; prospective_record_offset = physical_record_offset; scratch-&gt;clear(); *record = fragment; last_record_offset_ = prospective_record_offset; return true; case kFirstType: if (in_fragmented_record) &#123; // Handle bug in earlier versions of log::Writer where // it could emit an empty kFirstType record at the tail end // of a block followed by a kFullType or kFirstType record // at the beginning of the next block. if (scratch-&gt;empty()) &#123; in_fragmented_record = false; &#125; else &#123; ReportCorruption(scratch-&gt;size(), "partial record without end(2)"); &#125; &#125; prospective_record_offset = physical_record_offset; // 将record记录加入scratch之中 scratch-&gt;assign(fragment.data(), fragment.size()); in_fragmented_record = true; break; case kMiddleType: // 上条记录不完整，报错 if (!in_fragmented_record) &#123; ReportCorruption(fragment.size(), "missing start of fragmented record(1)"); &#125; else &#123; // 添加中间的数据块 scratch-&gt;append(fragment.data(), fragment.size()); &#125; break; case kLastType: // 上条记录不完整，报错退出 if (!in_fragmented_record) &#123; ReportCorruption(fragment.size(), "missing start of fragmented record(2)"); &#125; else &#123; scratch-&gt;append(fragment.data(), fragment.size()); // 记录最终的结果 *record = Slice(*scratch); last_record_offset_ = prospective_record_offset; return true; &#125; break; case kEof: if (in_fragmented_record) &#123; // This can be caused by the writer dying immediately after // writing a physical record but before completing the next; don't // treat it as a corruption, just ignore the entire logical record. scratch-&gt;clear(); &#125; return false; case kBadRecord: if (in_fragmented_record) &#123; ReportCorruption(scratch-&gt;size(), "error in middle of record"); in_fragmented_record = false; scratch-&gt;clear(); &#125; break; // 未知的类型 default: &#123; char buf[40]; snprintf(buf, sizeof(buf), "unknown record type %u", record_type); ReportCorruption( (fragment.size() + (in_fragmented_record ? scratch-&gt;size() : 0)), buf); in_fragmented_record = false; scratch-&gt;clear(); break; &#125; &#125; &#125; return false;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb dbformat解析]]></title>
    <url>%2F2017%2F06%2F22%2Fleveldb-dbformat%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介在leveldb中dbformat中，定义了几种不同类型的key，这几种类型的key的格式都是在dbformat之中定义的。在leveldb之中，会在用户定义的key后面附加上sequence number，用于标志key的先后顺序。在leveldb之中，删除key并不会真正将其从硬盘文件之中删除，而是将其类型标识为已经删除。的类型如下所示： 123456enum ValueType &#123; // 数据已经删除 kTypeDeletion = 0x0, // 是有效的value值 kTypeValue = 0x1&#125;; 实际上，ValueType是和SequenceNumber组合在一起存储的，共占据64bit，其中sequence number占据前56位，后面8位用于标志value的类型。 各种类型的keyInternalKeyInternalKey的格式是输入的user_key后面再加上sequence number和标志类型的ValueType。整个key的格式是：user key + sequence number + value type。因而，由ParsedInternalKey存储为字符串需要进行如下操作： 12345678910// 将sequence number 和 value type 组合成为 uint64_tstatic uint64_t PackSequenceAndType(uint64_t seq, ValueType t) &#123; assert(seq &lt;= kMaxSequenceNumber); assert(t &lt;= kValueTypeForSeek); return (seq &lt;&lt; 8) | t;&#125;void AppendInternalKey(std::string* result, const ParsedInternalKey&amp; key) &#123; result-&gt;append(key.user_key.data(), key.user_key.size()); PutFixed64(result, PackSequenceAndType(key.sequence, key.type));&#125; LookupKeyLookupKey相比InternalKey，在前面使用varint32格式记录了整个InternalKey所占据的空间大小。整个key的格式是：length + user key + sequence number + value_type。 1234567891011121314151617181920212223242526272829303132333435class LookupKey &#123; public: // Initialize *this for looking up user_key at a snapshot with // the specified sequence number. LookupKey(const Slice&amp; user_key, SequenceNumber sequence); ~LookupKey(); // Return a key suitable for lookup in a MemTable. Slice memtable_key() const &#123; return Slice(start_, end_ - start_); &#125; // Return an internal key (suitable for passing to an internal iterator) Slice internal_key() const &#123; return Slice(kstart_, end_ - kstart_); &#125; // Return the user key Slice user_key() const &#123; return Slice(kstart_, end_ - kstart_ - 8); &#125; private: /// lookup key 内部format如下所示 // We construct a char array of the form: // klength varint32 &lt;-- start_ // userkey char[klength] &lt;-- kstart_ // tag uint64 // &lt;-- end_ // The array is a suitable MemTable key. // The suffix starting with "userkey" can be used as an InternalKey. const char* start_; const char* kstart_; const char* end_; char space_[200]; // Avoid allocation for short keys // No copying allowed LookupKey(const LookupKey&amp;); void operator=(const LookupKey&amp;);&#125;; LookupKey类内部，start_标志整个LookupKey的开始位置，kstart_指向user_key的开始位置，end_指向整个LookupKey的结束位置。按照LookupKey格式，初始化各类成员，可以理解构造函数。 1234567891011121314151617181920212223242526LookupKey::LookupKey(const Slice&amp; user_key, SequenceNumber s) &#123; size_t usize = user_key.size(); /// varint32 + sequence number + value type size_t needed = usize + 13; // A conservative estimate char* dst; // 空间足够了 if (needed &lt;= sizeof(space_)) &#123; dst = space_; &#125; else &#123; // new 分配空间 dst = new char[needed]; &#125; start_ = dst; // encode length dst = EncodeVarint32(dst, usize + 8); // start_ 指向user key的开始处 kstart_ = dst; // encode user key memcpy(dst, user_key.data(), usize); dst += usize; // encode sequence number and type EncodeFixed64(dst, PackSequenceAndType(s, kValueTypeForSeek)); dst += 8; // 指向数据结束处 end_ = dst;&#125; InternalKeyComparator因为在InternalKey中引入了sequence number和value type，因而需要在Comparator的基础之上引入对Comparator相关接口实现进行改动才能适应。 在进行比较的时候，优先按照user key进行比较，若user key一样，则按照sequence number进行排序，sequence number更大的被视为较小。 12345678910111213141516171819/// 优先按照user key进行升序排序，然后按照sequence number 降序排序/// node-&gt;key keyint InternalKeyComparator::Compare(const Slice&amp; akey, const Slice&amp; bkey) const &#123; // Order by: // increasing user key (according to user-supplied comparator) // decreasing sequence number // decreasing type (though sequence# should be enough to disambiguate) int r = user_comparator_-&gt;Compare(ExtractUserKey(akey), ExtractUserKey(bkey)); if (r == 0) &#123; const uint64_t anum = DecodeFixed64(akey.data() + akey.size() - 8); const uint64_t bnum = DecodeFixed64(bkey.data() + bkey.size() - 8); if (anum &gt; bnum) &#123; r = -1; &#125; else if (anum &lt; bnum) &#123; r = +1; &#125; &#125; return r;&#125; 对于FindShortestSeparator和FindShortSuccessor操作，需要在基类的基础之上再加上sequence number和value type，sequence number取最大值。 12345678910111213141516171819202122232425262728293031323334void InternalKeyComparator::FindShortestSeparator( std::string* start, const Slice&amp; limit) const &#123; // Attempt to shorten the user portion of the key Slice user_start = ExtractUserKey(*start); Slice user_limit = ExtractUserKey(limit); std::string tmp(user_start.data(), user_start.size()); /// 找到比user_start大，比user_limit小的key user_comparator_-&gt;FindShortestSeparator(&amp;tmp, user_limit); if (tmp.size() &lt; user_start.size() &amp;&amp; user_comparator_-&gt;Compare(user_start, tmp) &lt; 0) &#123; // User key has become shorter physically, but larger logically. // Tack on the earliest possible number to the shortened user key. PutFixed64(&amp;tmp, PackSequenceAndType(kMaxSequenceNumber,kValueTypeForSeek)); assert(this-&gt;Compare(*start, tmp) &lt; 0); assert(this-&gt;Compare(tmp, limit) &lt; 0); start-&gt;swap(tmp); &#125;&#125;void InternalKeyComparator::FindShortSuccessor(std::string* key) const &#123; Slice user_key = ExtractUserKey(*key); std::string tmp(user_key.data(), user_key.size()); /// 找到比key大的key, 存于tmp中 user_comparator_-&gt;FindShortSuccessor(&amp;tmp); if (tmp.size() &lt; user_key.size() &amp;&amp; user_comparator_-&gt;Compare(user_key, tmp) &lt; 0) &#123; // User key has become shorter physically, but larger logically. // Tack on the earliest possible number to the shortened user key. PutFixed64(&amp;tmp, PackSequenceAndType(kMaxSequenceNumber,kValueTypeForSeek)); assert(this-&gt;Compare(*key, tmp) &lt; 0); key-&gt;swap(tmp); &#125;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb跳表]]></title>
    <url>%2F2017%2F06%2F22%2Fleveldb%E8%B7%B3%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[基本介绍跳跃链表允许快速查询一个有序连续元素的数据链表。快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集。基于并联的链表，其效率可以比拟二叉查找树。在leveldb之中，基本的memtable和immutable memtable就是基于跳表实现的。leveldb内部键值对的有序性也是基于跳表的从前到后的有序性实现的。 基本的跳表结构如下所示: 我们可以发现，跳表之中每一个结点的高度是随机的，相同高度的节点按照key的先后顺序前后相连，高层次的链表中的节点更加稀疏。因此，在执行搜索的时候，不要从底层的链表开始一次遍历，只需要首先沿着高层链表依次往后遍历，直到刚好到达整个跳表尾端前面刚好大于等于要搜索的key的位置，然后再往下在低层的链表中继续按照此策略搜索，直至到达最底层的链表顺序遍历搜索。可以发现，采取这种搜索策略，大大加快了搜索的速度。实际上，跳表的搜索效率是和平衡二叉树一致的，都是nlogn级别。 实现简介原子指针在leveldb之中，为了支持对memtable的并发访问，在实现跳表的时候，使用了原子指针数据结构。其实现主要是利用内存屏障，在对指针变量有更新的时候，使用内存屏障保证先后顺序，并且使得其他线程cache中的指针值失效，触发从内存之中重新读取。同样，在load指针值的时候，也使用内存屏障，保证先后顺序，保证读操作之前的所有写入操作生效之后，再从内存之中读取最新的指针值。 123456789inline void* Acquire_Load() const &#123; void* result = rep_; MemoryBarrier(); return result;&#125;inline void Release_Store(void* v) &#123; MemoryBarrier(); rep_ = v;&#125; 跳表之中每个结点都是由一个port::AtomicPointer类型的数组构成，数组中的每一个成员对应跳表中某一层次的节点。关于指针的存取，为了充分提升性能，定义了非原子操作和原子操作的版本，区别使用。 1234567891011121314151617181920212223242526272829303132333435363738394041// Implementation details followtemplate&lt;typename Key, class Comparator&gt;struct SkipList&lt;Key,Comparator&gt;::Node &#123; explicit Node(const Key&amp; k) : key(k) &#123; &#125; // 键 Key const key; // Accessors/mutators for links. Wrapped in methods so we can // add the appropriate barriers as necessary. // 获取n对应level的链表结点 Node* Next(int n) &#123; assert(n &gt;= 0); // Use an 'acquire load' so that we observe a fully initialized // version of the returned Node. return reinterpret_cast&lt;Node*&gt;(next_[n].Acquire_Load()); &#125; // 设置n对应level上的链表结点 void SetNext(int n, Node* x) &#123; assert(n &gt;= 0); // Use a 'release store' so that anybody who reads through this // pointer observes a fully initialized version of the inserted node. next_[n].Release_Store(x); &#125; /// No-barrier version // No-barrier variants that can be safely used in a few locations. Node* NoBarrier_Next(int n) &#123; assert(n &gt;= 0); return reinterpret_cast&lt;Node*&gt;(next_[n].NoBarrier_Load()); &#125; void NoBarrier_SetNext(int n, Node* x) &#123; assert(n &gt;= 0); next_[n].NoBarrier_Store(x); &#125; private: // Array of length equal to the node height. next_[0] is lowest level link. // 指向第一个level，实质上此数组的大小并不为1，这是c中struct的一个tricky port::AtomicPointer next_[1];&#125;; 在创建新节点的时候，使用内置的Arena内存分配器分配内存。节点中数组的大小为kMaxHeight，这是整个跳表所能够支持的最高层级。 123456789template&lt;typename Key, class Comparator&gt;typename SkipList&lt;Key,Comparator&gt;::Node*SkipList&lt;Key,Comparator&gt;::NewNode(const Key&amp; key, int height) &#123; /// 数组的capacity为height //调用Arena内存分配器进行分配 char* mem = arena_-&gt;AllocateAligned( sizeof(Node) + sizeof(port::AtomicPointer) * (height - 1)); return new (mem) Node(key);&#125; 查找在跳表之中，查找主要基于FindGreaterOrEqual和FindLessThan方法。查找大于或者等于key的节点方式是：从最高层往前遍历，直到x所指向的位置比key小，且next指向的位置比key大。如果当前所处的level为0，则next位置则为恰好大于或者等于key的位置，否则，继续在下层链表之中进行搜索。 1234567891011121314151617181920212223242526272829template&lt;typename Key, class Comparator&gt;typename SkipList&lt;Key,Comparator&gt;::Node* SkipList&lt;Key,Comparator&gt;::FindGreaterOrEqual(const Key&amp; key, Node** prev) const &#123; Node* x = head_; int level = GetMaxHeight() - 1; while (true) &#123; Node* next = x-&gt;Next(level); /// 优先从高层链表往后遍历找到正确的位置 // 还没有找到正确的位置，继续往前遍历链表 /// key在链表结点next的后面 if (KeyIsAfterNode(key, next)) &#123; // Keep searching in this list x = next; &#125; /// key在链表结点next的前面，在x结点的后面 /// key的prev节点应该指向x else &#123; if (prev != NULL) prev[level] = x; // 若已经是最底层的链表，直接返回这个结点 if (level == 0) &#123; return next; &#125; else &#123; // Switch to next list /// 进入更底层的链表，继续查找，直到第0层链表 level--; &#125; &#125; &#125;&#125; 上述函数还有一个参数是一个Node*类型的数组，他存放的是每一个level级别链表输入的key的前一个节点的指针。其实就是每个level上，x小于key, 但是x-&gt;next 大于等于key的那个结点x。 请注意，当输入key的sequence number大于或者等于跳表之中的节点，而user key部分一致，上述函数返回的节点指向的是跳表中sequence number较小，但user key部分一致的节点。FindLessThan的实现和FindGreaterOrEqual差不多，都是沿着高层链表往后遍历，直到next指向的节点比key大，并且当前位于第0层链表。不同于FindLessThan的是，FindGreaterOrEqual返回的是x结点，即next结点的上一个结点。 123456789101112131415161718192021222324template&lt;typename Key, class Comparator&gt;typename SkipList&lt;Key,Comparator&gt;::Node*SkipList&lt;Key,Comparator&gt;::FindLessThan(const Key&amp; key) const &#123; Node* x = head_; int level = GetMaxHeight() - 1; while (true) &#123; // 断言当前x为head_结点，否则必有x-&gt;key &lt; key 成立 assert(x == head_ || compare_(x-&gt;key, key) &lt; 0); // 拿到当前level层的下一个结点 Node* next = x-&gt;Next(level); // 若next指向NULL，或者next-&gt;key &gt;= key if (next == NULL || compare_(next-&gt;key, key) &gt;= 0) &#123; // 已经是最底层的链表，直接返回对应的结点 if (level == 0) &#123; return x; &#125; else &#123; // 转向更底层的链表 // Switch to next list level--; &#125; // next &amp;&amp; compare_(next-&gt;key, key) &lt; 0, 继续遍历到下一个结点 &#125; else &#123; x = next; &#125; &#125;&#125; 若要定位到跳表的head节点，直接返回其head节点即可。定位到last节点由FindLast实现，从上到下，依次往后遍历，直到到达level 0，且x节点的后一个节点指向NULL，则x为跳表的最后一个节点。 1234567891011121314151617181920// 首先在最上层链表遍历到尾端，再转向底层结点，直到到达最低层链表的末尾结点template&lt;typename Key, class Comparator&gt;typename SkipList&lt;Key,Comparator&gt;::Node* SkipList&lt;Key,Comparator&gt;::FindLast() const &#123; Node* x = head_; int level = GetMaxHeight() - 1; while (true) &#123; Node* next = x-&gt;Next(level); if (next == NULL) &#123; if (level == 0) &#123; return x; &#125; else &#123; // Switch to next list level--; &#125; &#125; else &#123; x = next; &#125; &#125;&#125; 插入相比跳表的搜索，跳表的插入会稍显复杂。跳表每次插入的时候，新节点的高度实际上是随机产生的。插入会首先获取条表中大于或者等于key节点的第一个节点，并记录每一个对应level的前一个节点的地址保存在prev之中。最后更新prev数组中各节点的next值以及要插入的节点的next值即可。 123456789101112131415161718192021222324252627282930313233343536373839// 向skiplist中插入keytemplate&lt;typename Key, class Comparator&gt;void SkipList&lt;Key,Comparator&gt;::Insert(const Key&amp; key) &#123; // TODO(opt): We can use a barrier-free variant of FindGreaterOrEqual() // here since Insert() is externally synchronized. Node* prev[kMaxHeight]; Node* x = FindGreaterOrEqual(key, prev); // Our data structure does not allow duplicate insertion assert(x == NULL || !Equal(key, x-&gt;key)); int height = RandomHeight(); if (height &gt; GetMaxHeight()) &#123; // 更高层的结点，其prev指向head_ for (int i = GetMaxHeight(); i &lt; height; i++) &#123; prev[i] = head_; &#125; //fprintf(stderr, "Change height from %d to %d\n", max_height_, height); // It is ok to mutate max_height_ without any synchronization // with concurrent readers. A concurrent reader that observes // the new value of max_height_ will see either the old value of // new level pointers from head_ (NULL), or a new value set in // the loop below. In the former case the reader will // immediately drop to the next level since NULL sorts after all // keys. In the latter case the reader will use the new node. max_height_.NoBarrier_Store(reinterpret_cast&lt;void*&gt;(height)); &#125; x = NewNode(key, height); for (int i = 0; i &lt; height; i++) &#123; // NoBarrier_SetNext() suffices since we will add a barrier when // we publish a pointer to "x" in prev[i]. // 复制prev数组 x-&gt;NoBarrier_SetNext(i, prev[i]-&gt;NoBarrier_Next(i)); // prev-&gt;next 也指向key prev[i]-&gt;SetNext(i, x); &#125;&#125; 迭代器跳表内部迭代器的接口定义和leveldb头文件中Iterator基本一致，但是没有继承头文件中的迭代器接口。 12345678910111213141516171819202122232425262728293031323334353637383940class Iterator &#123; public: // Initialize an iterator over the specified list. // The returned iterator is not valid. explicit Iterator(const SkipList* list); // Returns true iff the iterator is positioned at a valid node. bool Valid() const; // Returns the key at the current position. // REQUIRES: Valid() const Key&amp; key() const; // Advances to the next position. // REQUIRES: Valid() void Next(); // Advances to the previous position. // REQUIRES: Valid() void Prev(); // Advance to the first entry with a key &gt;= target // 此操作之后，指向第一条key &gt;= target的记录 void Seek(const Key&amp; target); // Position at the first entry in list. // Final state of iterator is Valid() iff list is not empty. void SeekToFirst(); // Position at the last entry in list. // Final state of iterator is Valid() iff list is not empty. void SeekToLast(); private: // itertor从属的链表 const SkipList* list_; // 链表中的结点 Node* node_; // Intentionally copyable &#125;; 我们可以发现，跳表中Iterator的相关操作基本上是对搜索操作的一次转调用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// constructor of Iterator inside skiplisttemplate&lt;typename Key, class Comparator&gt;inline SkipList&lt;Key,Comparator&gt;::Iterator::Iterator(const SkipList* list) &#123; list_ = list; node_ = NULL;&#125;// 若node_不为nil，那么Iterator是Valid的template&lt;typename Key, class Comparator&gt;inline bool SkipList&lt;Key,Comparator&gt;::Iterator::Valid() const &#123; return node_ != NULL;&#125;// 返回node_对应的key_template&lt;typename Key, class Comparator&gt;inline const Key&amp; SkipList&lt;Key,Comparator&gt;::Iterator::key() const &#123; assert(Valid()); return node_-&gt;key;&#125;// 移动node_指向链表中的下一个结点template&lt;typename Key, class Comparator&gt;inline void SkipList&lt;Key,Comparator&gt;::Iterator::Next() &#123; assert(Valid()); node_ = node_-&gt;Next(0);&#125;// Iterator指向上一个结点template&lt;typename Key, class Comparator&gt;inline void SkipList&lt;Key,Comparator&gt;::Iterator::Prev() &#123; // Instead of using explicit "prev" links, we just search for the // last node that falls before key. assert(Valid()); // node_应该指向恰好小于当前key的节点 // 此操作是在skiplist的层面进行 node_ = list_-&gt;FindLessThan(node_-&gt;key); // 若链表为空，node_指向null，iterator 已经不再 valid了 if (node_ == list_-&gt;head_) &#123; node_ = NULL; &#125;&#125;// 转调用skiplist中的FindGreaterOrEqual函数，node指向第一个大于等于target的节点template&lt;typename Key, class Comparator&gt;inline void SkipList&lt;Key,Comparator&gt;::Iterator::Seek(const Key&amp; target) &#123; node_ = list_-&gt;FindGreaterOrEqual(target, NULL);&#125;// iterator指向head_对应的结点template&lt;typename Key, class Comparator&gt;inline void SkipList&lt;Key,Comparator&gt;::Iterator::SeekToFirst() &#123; node_ = list_-&gt;head_-&gt;Next(0);&#125;// node_是skiplist中最后的节点template&lt;typename Key, class Comparator&gt;inline void SkipList&lt;Key,Comparator&gt;::Iterator::SeekToLast() &#123; node_ = list_-&gt;FindLast(); // 判断链表是否为空，设置iterator的状态 if (node_ == list_-&gt;head_) &#123; node_ = NULL; &#125;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb bloom filter]]></title>
    <url>%2F2017%2F06%2F13%2Fleveldb-bloom-filter%2F</url>
    <content type="text"><![CDATA[bloom过滤器在1970年由布隆提出。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于快速检索一个元素是否在一个集合中。使用布隆过滤器能够确定某个元素不在集合之中，但是布隆过滤器可能会误报，将本来不在集合中的元素归类为在集合之中的元素。 在leveldb的布隆过滤器，需要指定每个key需要的向量位数，如下所示： 12345678910explicit BloomFilterPolicy(int bits_per_key) : bits_per_key_(bits_per_key)&#123; // we intentionally round down to reduce probing cost a little bit k_ = static_cast&lt;size_t&gt;(bits_per_key * 0.69); // 0.69 =~ ln(2) if (k_ &lt; 1) k_ = 1; if (k_ &gt; 30) k_ = 30;&#125; leveldb 会在向量的最后记录k_的值,k_代表每个key需要设置hash位的次数。 对于创建filter，leveldb会根据key的个数和bits_per_key_设置计算总共需要的二进制位数，将其向上取整到byte为单位，并且最小为8byte。对于每个key，重复设置k_次对应bit位，每次hash值加上delta const uint32_t delta = (h &gt;&gt; 17) | (h &lt;&lt; 15); 123456789101112131415161718192021222324252627282930313233343536virtual void CreateFilter(const Slice *keys, int n, std::string *dst) const&#123; // compute bloom filter size (in both bits and bytes) size_t bits = n * bits_per_key_; // for small n, we can see a very high false positive rate. Fix it by enforcing // a minimum bloom filter length. if (bits &lt; 64) bits = 64; size_t bytes = (bits + 7) / 8; bits = bytes * 8; const size_t init_size = dst-&gt;size(); dst-&gt;resize(init_size + bytes, 0); dst-&gt;push_back(static_cast&lt;char&gt;(k_)); // remember # of probes in filter // 因为采用的是push_back, 所以现在dst的实际大小为 init_size + 1 + bytes // 最后一个byte用于存放k_ char *array = &amp;(*dst)[init_size]; for (int i = 0; i &lt; n; ++i) &#123; // use double-hashing to generate a sequence of hash values. // se analysis in [Kirsch,Mitzenmacher 2006]. uint32_t h = BloomHash(keys[i]); const uint32_t delta = (h &gt;&gt; 17) | (h &lt;&lt; 15); // rotate right 17 bits for (size_t j = 0; j &lt; k_; j++) &#123; const uint32_t bitpos = h % bits; // 设置对应位 array[bitpos/8] |= (1 &lt;&lt; (bitpos % 8)); // h+= delta h += delta; &#125; &#125;&#125; 至于KeyMayMatch操作，就是对于给定key，首先拿到k_的值，然后进行k_次比较，比较每次计算得出的hash值对应的向量位是否设置为1，若k_次比较完毕之后，对应bit都设置为1，那么有理由相信这个key符合要求，否则，此key一定不在bloom集合之中。这里对k_做了特殊处理，对于k_大于30的情况，统一认定为符合filter，这是保留用途。 1234567891011121314151617181920212223242526virtual bool KeyMayMatch(const Slice&amp; key, const Slice&amp; bloom_filter) const &#123; const size_t len = bloom_filter.size(); if (len &lt; 2) return false; const char* array = bloom_filter.data(); const size_t bits = (len - 1) * 8; // use the encoded k so that we can read filters generated by bloom filters created using different parameters. const size_t k = array[len - 1]; if (k &gt; 30) &#123; // reserved for potentially new encodings for short bloom filters. // consider it a match return true; &#125; uint32_t h = BloomHash(key); const uint32_t delta = (h &gt;&gt; 17) | (h &lt;&lt; 15); for(size_t j = 0; j &lt; k; j++) &#123; const uint32_t bitpos = h % bits; if((array[bitpos/8] &amp; (1 &lt;&lt; (bitpos %8))) == 0) return false; h += delta; &#125; return true; &#125; 求hash值的操作实际上是对hash操作的简单封装，指定seed为0xbc9f1d34。 1234static uint32_t BloomHash(const Slice &amp;key)&#123; return Hash(key.data(), key.size(), 0xbc9f1d34);&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb Arena内存分配器]]></title>
    <url>%2F2017%2F06%2F13%2Fleveldb-Arena%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%2F</url>
    <content type="text"><![CDATA[leveldb使用vector存放使用malloc分配的内存。在析构的时候，对这些分配的内存统一进行释放。 在分配内存时，首先判断上一个剩余块空间是否足够，足够就直接从剩余空间之中分配内存，否则调用AllocateFallback, 分配一块的新的内存。 123456789101112inline char* Arena::Allocate(size_t bytes)&#123; assert(bytes &gt; 0); if(bytes &lt;= alloc_bytes_remaining_) &#123; char* result = alloc_ptr_; alloc_ptr_ += bytes; alloc_bytes_remaining_ -= bytes; return result; &#125; return AllocateFallback(bytes);&#125; 在分配新的内存时，判断要分配的内存是否大于分配内存块大小kBlockSize的1/4，若大于，直接分配此大小的内存。否则分配一块kBlockSize大小的内存，从此内存块之中分配需要的内存，记录当前块剩余空间，以便下次内存分配能够利用剩余的空间。 123456789101112131415161718char* Arena::AllocateFallback(size_t bytes)&#123; if(bytes &gt; kBlockSize / 4) &#123; // object is more than a quarter of our block size. Allocate it separately to // avoid wasting too much space in leftover bytes. char* result = AllocateNewBlock(bytes); return result; &#125; // we waste the remaining space in the current block alloc_ptr_ = AllocateNewBlock(kBlockSize); alloc_bytes_remaining_ = kBlockSize; char* result = alloc_ptr_; alloc_ptr_ += bytes; alloc_bytes_remaining_ -= bytes; return result;&#125; 还有一种需求是分配的内存需要对齐，这需要保证分配的内存地址能够整除8（64位cpu），所以可能需要跳过一段内存区域，返回对齐的地址空间。 1234567891011121314151617181920212223char* Arena::AllocateAligned(size_t bytes)&#123; const int align = (sizeof(void*) &gt; 8) ? sizeof(void*) : 8; assert((align &amp; (align - 1)) == 0); // pointer size should be a power of 2 size_t current_mod = reinterpret_cast&lt;uintptr_t&gt;(alloc_ptr_) &amp; (align - 1); size_t slop = (current_mod == 0 ? 0 : align - current_mod); size_t needed = bytes + slop; char* result; if(needed &lt;= alloc_bytes_remaining_) &#123; result = alloc_ptr_ + slop; alloc_ptr_ += needed; alloc_bytes_remaining_ -= needed; &#125; else &#123; // AllocateFallback always returned aligned memory result = AllocateFallback(bytes); &#125; assert((reinterpret_cast&lt;uintptr_t&gt;(result) &amp; (align - 1)) == 0); return result;&#125; 至于分配块内存，是直接调用new运算符来分配，其实质是利用malloc。在此过程中还记录了内存空间的总用量，注意要包括vector中记录内存地址占用的内存大小。 12345678char* Arena::AllocateNewBlock(size_t block_bytes)&#123; char* result = new char[block_bytes]; blocks_.push_back(result); // also add pointer size at blocks_ memory_usage_.NoBarrier_Store(reinterpret_cast&lt;void*&gt;(MemoryUsage() + block_bytes + sizeof(char*))); return result;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb测试夹具]]></title>
    <url>%2F2017%2F06%2F13%2Fleveldb%E6%B5%8B%E8%AF%95%E5%A4%B9%E5%85%B7%2F</url>
    <content type="text"><![CDATA[一直以来，都想实现一个简单的单元测试工具，从根本上理解单元测试框架的实现原理。今天看了leveldb中的源码testharness.cc，感觉已经彻底理解了。 核心技术和log实现一样，实现单元测试框架的核心是要用好宏。如果对宏没有清晰的认知，恐怕连相关的代码都无法理解。 以下主要补充说明#和##在宏中的作用：1#define WARN_IF(EXP) do &#123; if(EXP) fprintf(stderr, "Warning! "#EXP"\n"); &#125; while(0) #对他后面的变量左右添加双引号，所以上述宏定义之中可以将表达式转换为字符串输出。 1#define CONCAT(X, Y) X##Y ##则用于连接两个变量。上述宏定义是一个简单的连接操作。 断言的实现断言的实现是基于类Tester完成的，类成员中由std::stringstream ss_ 来记录输出的错误信息。如果Tester中的用于测试的成员函数出错了，会记录状态为出错，这样在析构的时候就会将ss_的错误信息输出到stderr之中, 并且调用exit退出。 为了避免重复输入内容完全一样，仅仅名称和比较运算符不同的测试函数，在这里使用了宏定义进行简化。1234567891011121314151617#define BINARY_OP(name,op) \ template &lt;class X, class Y&gt; \ Tester&amp; name(const X&amp; x, const Y&amp; y) &#123; \ if (! (x op y)) &#123; \ ss_ &lt;&lt; " failed: " &lt;&lt; x &lt;&lt; (" " #op " ") &lt;&lt; y; \ ok_ = false; \ &#125; \ return *this; \ &#125; BINARY_OP(IsEq, ==) BINARY_OP(IsNe, !=) BINARY_OP(IsGe, &gt;=) BINARY_OP(IsGt, &gt;) BINARY_OP(IsLe, &lt;=) BINARY_OP(IsLt, &lt;)#undef BINARY_OP 对于后续不再使用的宏定义要及时将其undef，这里符合了google的编程规范。 通过代码可以发现，对于ASSERT_TRUE, ASSERT_OK, ASSERT_EQ, ASSERT_NE的调用原理实际上是创建一个Tester临时成员，并且立即调用对应的比较函数。这样若检查失败，那么临时对象在析构的时候会输出错误信息，并且程序终止运行。 增加测试案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// testharness.h#define TCONCAT(a,b) TCONCAT1(a,b)#define TCONCAT1(a,b) a##b#define TEST(base,name) \class TCONCAT(_Test_,name) : public base &#123; \ public: \ void _Run(); \ static void _RunIt() &#123; \ TCONCAT(_Test_,name) t; \ t._Run(); \ &#125; \&#125;; \bool TCONCAT(_Test_ignored_,name) = \ ::leveldb::test::RegisterTest(#base, #name, &amp;TCONCAT(_Test_,name)::_RunIt); \void TCONCAT(_Test_,name)::_Run()// Register the specified test. Typically not used directly, but// invoked via the macro expansion of TEST.extern bool RegisterTest(const char* base, const char* name, void (*func)());//testharness.ccstruct Test &#123; const char* base; const char* name; void (*func)();&#125;;std::vector&lt;Test&gt;* tests;&#125;bool RegisterTest(const char* base, const char* name, void (*func)()) &#123; if (tests == NULL) &#123; tests = new std::vector&lt;Test&gt;; &#125; Test t; t.base = base; t.name = name; t.func = func; tests-&gt;push_back(t); return true;&#125;int RunAllTests() &#123; const char* matcher = getenv("LEVELDB_TESTS"); int num = 0; if (tests != NULL) &#123; for (size_t i = 0; i &lt; tests-&gt;size(); i++) &#123; const Test&amp; t = (*tests)[i]; if (matcher != NULL) &#123; std::string name = t.base; name.push_back('.'); name.append(t.name); if (strstr(name.c_str(), matcher) == NULL) &#123; continue; &#125; &#125; fprintf(stderr, "==== Test %s.%s\n", t.base, t.name); (*t.func)(); ++num; &#125; &#125; fprintf(stderr, "==== PASSED %d tests\n", num); return 0;&#125; 在leveldb中，每个测试案例对应一个struct test实例，其成员包括base(基础名称), name, 以及一个无参的void类型函数。测试所有案例就是依次调用所有案例的测试函数。 以下代码演示了测试的具体使用方法： 1234567891011121314151617181920// 有删减#include "util/crc32c.h"#include "util/testharness.h"namespace leveldb &#123;namespace crc32c &#123;class CRC &#123; &#125;;TEST(CRC, StandardResults) &#123; // From rfc3720 section B.4. char buf[32]; memset(buf, 0, sizeof(buf));&#125;&#125;&#125;int main(int argc, char** argv) &#123; return leveldb::test::RunAllTests();&#125; 拆解前述代码的宏定义，可以发现，每次调用依次test就是定义一个与之相关的class，宏定义将具体的Run_实现交给用户进行。宏定义TEST中已经将此类的static成员函数定义好了，此成员函数是创建一个此类的对象，并且调用其Run_方法。这样只需将此类的static函数作为struct Test中的函数指针指向的函数，在进行测试的时候，调用此静态函数就会调用用户定义的测试方法。虽然过程比较百转千折，但是实现非常精妙！]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MergingIterator和TwoLevelIterator]]></title>
    <url>%2F2017%2F06%2F13%2FMergingIterator%E5%92%8CTwoLevelIterator%2F</url>
    <content type="text"><![CDATA[MergingIterator概述MergingIterator的存在能够将多个iterator对应的数据结合起来，统一成一个iterator对外提供服务。迭代器的先后顺序仍然表示数据的大小关系，但是MegingIterator并不会对输入的迭代器进行去重处理。 通过构造函数可以发现，若没有输入任何迭代器，则返回一个empty iterator；若只输入了一个迭代器，则返回这个迭代器；在其他情况下才会创建MergingIterator对象。 1234567891011// 输入0，返回空的iterator，1，返回本身，n返回合并iteratorIterator* NewMergingIterator(const Comparator* cmp, Iterator** list, int n) &#123; assert(n &gt;= 0); if (n == 0) &#123; return NewEmptyIterator(); &#125; else if (n == 1) &#123; return list[0]; &#125; else &#123; return new MergingIterator(cmp, list, n); &#125;&#125; 实现解析SeekToFirst，SeekToLast 和 Seek先从简单的讲起，SeekToFirst操作对所有输入的迭代器执行SeekToFirst操作，然后找到其中最小的一个就是第一个迭代器，并且记录迭代器前进方向为kForward。SeekToLast实现同理。 12345678910111213141516171819virtual void SeekToFirst() &#123; for (int i = 0; i &lt; n_; i++) &#123; children_[i].SeekToFirst(); &#125; // 找到最小的 FindSmallest(); // 方向是前进 direction_ = kForward; &#125; virtual void SeekToLast() &#123; for (int i = 0; i &lt; n_; i++) &#123; children_[i].SeekToLast(); &#125; // 找到最大的 FindLargest(); // 方向是后退 direction_ = kReverse; &#125; Seek操作是对所有输入的迭代器统一执行Seek操作，找到其中最小的迭代器返回。 123456789virtual void Seek(const Slice&amp; target) &#123; for (int i = 0; i &lt; n_; i++) &#123; children_[i].Seek(target); &#125; // 找到最小的 FindSmallest(); // 方向是前进 direction_ = kForward; &#125; FindSmallest函数遍历所有输入的迭代器，记录key最小的迭代器为current_;FindLargest遍历所有输入的迭代器，记录key最大的迭代器为current_。 123456789101112131415161718192021222324252627282930// 简单的O(n)遍历查找void MergingIterator::FindSmallest() &#123; IteratorWrapper* smallest = NULL; for (int i = 0; i &lt; n_; i++) &#123; IteratorWrapper* child = &amp;children_[i]; if (child-&gt;Valid()) &#123; if (smallest == NULL) &#123; smallest = child; &#125; else if (comparator_-&gt;Compare(child-&gt;key(), smallest-&gt;key()) &lt; 0) &#123; smallest = child; &#125; &#125; &#125; current_ = smallest;&#125;void MergingIterator::FindLargest() &#123; IteratorWrapper* largest = NULL; for (int i = n_-1; i &gt;= 0; i--) &#123; IteratorWrapper* child = &amp;children_[i]; if (child-&gt;Valid()) &#123; if (largest == NULL) &#123; largest = child; &#125; else if (comparator_-&gt;Compare(child-&gt;key(), largest-&gt;key()) &gt; 0) &#123; largest = child; &#125; &#125; &#125; current_ = largest;&#125; Prev 和 NextPrev操作是找到从左边最接近当前key的迭代器位置。若当前迭代器的遍历方向是kReverse，那么children_记录的除了current_之外的迭代器都current_小。因而其他迭代器都不用移动，只需current_向前移动一位，这样所有迭代器都比当前位置的key小，其中最大的就是最接近当前位置的迭代器。 在其他情况下，就要对其他迭代器先执行Seek(key())操作，再执行Prev操作，移动到刚好小于当前key的位置。对于当前迭代器仍然只执行Prev操作。这样所有迭代器都是刚好比key小的位置，其中最大的就是最接近当前位置的迭代器。 123456789101112131415161718192021222324252627282930virtual void Prev() &#123; assert(Valid()); /// Ensure that all children are positioned before key(). /// reverse 情况下，其他child的key都比current小 // If we are moving in the reverse direction, it is already // true for all of the non-current_ children since current_ is // the largest child and key() == current_-&gt;key(). Otherwise, // we explicitly position the non-current_ children. if (direction_ != kReverse) &#123; for (int i = 0; i &lt; n_; i++) &#123; IteratorWrapper* child = &amp;children_[i]; if (child != current_) &#123; child-&gt;Seek(key()); if (child-&gt;Valid()) &#123; // Child is at first entry &gt;= key(). Step back one to be &lt; key() child-&gt;Prev(); &#125; else &#123; // Child has no entries &gt;= key(). Position at last entry. child-&gt;SeekToLast(); &#125; &#125; &#125; direction_ = kReverse; &#125; current_-&gt;Prev(); // 找其中最大的 FindLargest(); &#125; Next的实现方式同理，下面仅列出代码： 12345678910111213141516171819202122232425262728virtual void Next() &#123; assert(Valid()); /// Ensure that all children are positioned after key(). /// forward 情况下，其他child的key都比current大 // If we are moving in the forward direction, it is already // true for all of the non-current_ children since current_ is // the smallest child and key() == current_-&gt;key(). Otherwise, // we explicitly position the non-current_ children. if (direction_ != kForward) &#123; for (int i = 0; i &lt; n_; i++) &#123; IteratorWrapper* child = &amp;children_[i]; if (child != current_) &#123; child-&gt;Seek(key()); if (child-&gt;Valid() &amp;&amp; comparator_-&gt;Compare(key(), child-&gt;key()) == 0) &#123; // child指向比key()大的位置 child-&gt;Next(); &#125; &#125; &#125; direction_ = kForward; &#125; // current指向下一位 current_-&gt;Next(); // 找其中最小的 FindSmallest(); &#125; TwoLevelIterator概述TwoLevelIterator输入Index block 对应的iterator，以及输入的BlockReader函数，将index iterator所管理的数据块整合成为一个iterator，对外提供数据服务。 初始化data iterator初始化data iterator的操作很简单，获取index_iter_当前位置的值作为block handle来初始化data iterator。在此过程中会记录此handle的值。若data_iter_不为空，且handle与记录的值不变，则不会重新初始化data_iter_。 12345678910111213141516171819202122232425// initialize data iteratorvoid TwoLevelIterator::InitDataBlock() &#123; if (!index_iter_.Valid()) &#123; SetDataIterator(NULL); &#125; else &#123; Slice handle = index_iter_.value(); if (data_iter_.iter() != NULL &amp;&amp; handle.compare(data_block_handle_) == 0) &#123; // data_iter_ is already constructed with this iterator, so // no need to change anything &#125; else &#123; // 获取data iter Iterator* iter = (*block_function_)(arg_, options_, handle); // 保存创建data_iter的handle信息 data_block_handle_.assign(handle.data(), handle.size()); // 设置data iterator SetDataIterator(iter); &#125; &#125;&#125;// 设置data itervoid TwoLevelIterator::SetDataIterator(Iterator* data_iter) &#123; if (data_iter_.iter() != NULL) SaveError(data_iter_.status()); data_iter_.Set(data_iter);&#125; iterator的Seek相关操作iterator的Seek相关操作也非常简单，首先根据不同的Seek操作对index_iter_进行相应的移动，根据当前index_iter_的值初始化data_iter_，再移动到正确的位置上。 1234567891011121314151617181920void TwoLevelIterator::Seek(const Slice&amp; target) &#123; index_iter_.Seek(target); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.Seek(target); SkipEmptyDataBlocksForward();&#125;void TwoLevelIterator::SeekToFirst() &#123; index_iter_.SeekToFirst(); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.SeekToFirst(); SkipEmptyDataBlocksForward();&#125;void TwoLevelIterator::SeekToLast() &#123; index_iter_.SeekToLast(); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.SeekToLast(); SkipEmptyDataBlocksBackward();&#125; 向前后移动以及Skip操作data_iter_在移动过程中，有可能因为已经遍历过数据块的最后一条record，data_iter_需要继续移动，指向下一个数据块，而且index_iter_也可能指向空的数据块。对于这些情况，都需要跳过一些数据块，即如下代码所示： 123456789101112131415161718192021222324252627// 向前跳过空的data_iter_void TwoLevelIterator::SkipEmptyDataBlocksForward() &#123; while (data_iter_.iter() == NULL || !data_iter_.Valid()) &#123; // Move to next block if (!index_iter_.Valid()) &#123; SetDataIterator(NULL); return; &#125; index_iter_.Next(); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.SeekToFirst(); &#125;&#125;// 向后跳过空的data_iter_void TwoLevelIterator::SkipEmptyDataBlocksBackward() &#123; while (data_iter_.iter() == NULL || !data_iter_.Valid()) &#123; // Move to next block if (!index_iter_.Valid()) &#123; SetDataIterator(NULL); return; &#125; index_iter_.Prev(); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.SeekToLast(); &#125;&#125; 在上述基础上，Prev和Next操作只需要在移动data_iter_移动之后，进行相应的跳空处理即可。 1234567891011void TwoLevelIterator::Next() &#123; assert(Valid()); data_iter_.Next(); SkipEmptyDataBlocksForward();&#125;void TwoLevelIterator::Prev() &#123; assert(Valid()); data_iter_.Prev(); SkipEmptyDataBlocksBackward();&#125; 至此，leveldb table路径下所有代码分析完毕，下面转入db路径，深入到leveldb的实际建构之中。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb sstable 读取解析]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-sstable-%E8%AF%BB%E5%8F%96%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[leveldb sstable 读取解析结构化数据的读取比写入实现起来更为复杂，levledb中的sstable读取又一次说明了这一点。sstable的读取操作定义在table.h和table.cc之中。在这一节代码中主要实现了sstable的打开操作，以及如何从index handle得到对应block 的interator。 Opensstable的打开先从footer开始，校验是否是sstable文件。读取meta_block index 和 index block handle。若无误，则根据footer中的信息来创建Rep对象。请注意，这里生成了cache_id，cache_id是采用全局递增的算法产生的，在整个系统中独一无二，后续会在cache之中使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758Status Table::Open(const Options&amp; options, RandomAccessFile* file, uint64_t size, Table** table) &#123; *table = NULL; // sstable的文件大小需要大于Footer if (size &lt; Footer::kEncodedLength) &#123; return Status::Corruption("file is too short to be an sstable"); &#125; char footer_space[Footer::kEncodedLength]; Slice footer_input; // 读取footer Status s = file-&gt;Read(size - Footer::kEncodedLength, Footer::kEncodedLength, &amp;footer_input, footer_space); if (!s.ok()) return s; Footer footer; // decode from footer Slice s = footer.DecodeFrom(&amp;footer_input); if (!s.ok()) return s; // Read the index block BlockContents contents; Block* index_block = NULL; if (s.ok()) &#123; ReadOptions opt; // 如果设置了paranoid_checks, 那么需要检查校验码 if (options.paranoid_checks) &#123; opt.verify_checksums = true; &#125; // 读取index block s = ReadBlock(file, opt, footer.index_handle(), &amp;contents); if (s.ok()) &#123; index_block = new Block(contents); &#125; &#125; if (s.ok()) &#123; // We've successfully read the footer and the index block: we're // ready to serve requests. Rep* rep = new Table::Rep; rep-&gt;options = options; rep-&gt;file = file; rep-&gt;metaindex_handle = footer.metaindex_handle(); rep-&gt;index_block = index_block; rep-&gt;cache_id = (options.block_cache ? options.block_cache-&gt;NewId() : 0); rep-&gt;filter_data = NULL; rep-&gt;filter = NULL; *table = new Table(rep); // 读取meta 元数据 (*table)-&gt;ReadMeta(footer); &#125; else &#123; delete index_block; &#125; return s;&#125; 读取meta block会首先查找有没有filter block handle，若有的话读取filter block，创建FilterBlockReader成员。 123456789101112131415161718192021222324252627282930void Table::ReadMeta(const Footer&amp; footer) &#123; // 没有设置filter_policy, return if (rep_-&gt;options.filter_policy == NULL || footer.metaindex_handle().size() == 0) &#123; return; // Do not need any metadata &#125; ReadOptions opt; if (rep_-&gt;options.paranoid_checks) &#123; opt.verify_checksums = true; &#125; BlockContents contents; if (!ReadBlock(rep_-&gt;file, opt, footer.metaindex_handle(), &amp;contents).ok()) &#123; // Do not propagate errors since meta info is not needed for operation return; &#125; // meta index block Block* meta = new Block(contents); Iterator* iter = meta-&gt;NewIterator(BytewiseComparator()); std::string key = "filter."; key.append(rep_-&gt;options.filter_policy-&gt;Name()); // 查找filter 策略对应的filter index block iter-&gt;Seek(key); if (iter-&gt;Valid() &amp;&amp; iter-&gt;key() == Slice(key)) &#123; ReadFilter(iter-&gt;value()); &#125; delete iter; delete meta;&#125; 1234567891011121314151617181920212223void Table::ReadFilter(const Slice&amp; filter_handle_value) &#123; Slice v = filter_handle_value; BlockHandle filter_handle; if (!filter_handle.DecodeFrom(&amp;v).ok()) &#123; return; &#125; // We might want to unify with ReadBlock() if we start // requiring checksum verification in Table::Open. ReadOptions opt; if (rep_-&gt;options.paranoid_checks) &#123; opt.verify_checksums = true; &#125; BlockContents block; if (!ReadBlock(rep_-&gt;file, opt, filter_handle, &amp;block).ok()) &#123; return; &#125; if (block.heap_allocated) &#123; rep_-&gt;filter_data = block.data.data(); // Will need to delete later &#125; // 创建filter rep_-&gt;filter = new FilterBlockReader(rep_-&gt;options.filter_policy, block.data);&#125; BlockReaderBlockReader函数根据index_value指定的handle信息，首先尝试从cache中查找block。查找的key是cache_id以及块偏移的组合键。找不到就直接从文件之中读取。根据读取的块创建这个数据块上的iterator。如果是从文件中读取的数据块，在iterator析构的时候，需要将数据块释放给内存；如果是从cache中读取的数据块，在iterator被析构时，需要进行release。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Convert an index iterator value (i.e., an encoded BlockHandle)// into an iterator over the contents of the corresponding block.Iterator* Table::BlockReader(void* arg, const ReadOptions&amp; options, const Slice&amp; index_value) &#123; Table* table = reinterpret_cast&lt;Table*&gt;(arg); Cache* block_cache = table-&gt;rep_-&gt;options.block_cache; Block* block = NULL; Cache::Handle* cache_handle = NULL; BlockHandle handle; Slice input = index_value; // decode block handle from input Status s = handle.DecodeFrom(&amp;input); // We intentionally allow extra stuff in index_value so that we // can add more features in the future. if (s.ok()) &#123; BlockContents contents; if (block_cache != NULL) &#123; char cache_key_buffer[16]; // cache_id + handle.offset -&gt; key EncodeFixed64(cache_key_buffer, table-&gt;rep_-&gt;cache_id); EncodeFixed64(cache_key_buffer+8, handle.offset()); Slice key(cache_key_buffer, sizeof(cache_key_buffer)); cache_handle = block_cache-&gt;Lookup(key); if (cache_handle != NULL) &#123; // 尝试从缓存之中获取handle对应的block block = reinterpret_cast&lt;Block*&gt;(block_cache-&gt;Value(cache_handle)); &#125; else &#123; // 直接从文件之中读取 s = ReadBlock(table-&gt;rep_-&gt;file, options, handle, &amp;contents); if (s.ok()) &#123; block = new Block(contents); // 缓存it if (contents.cachable &amp;&amp; options.fill_cache) &#123; cache_handle = block_cache-&gt;Insert( key, block, block-&gt;size(), &amp;DeleteCachedBlock); &#125; &#125; &#125; &#125; else &#123; s = ReadBlock(table-&gt;rep_-&gt;file, options, handle, &amp;contents); if (s.ok()) &#123; block = new Block(contents); &#125; &#125; &#125; Iterator* iter; if (block != NULL) &#123; iter = block-&gt;NewIterator(table-&gt;rep_-&gt;options.comparator); if (cache_handle == NULL) &#123; // 注册cleanup function 为 DeleteBlock iter-&gt;RegisterCleanup(&amp;DeleteBlock, block, NULL); &#125; else &#123; // 注册cleanup function 为ReleaseBlock iter-&gt;RegisterCleanup(&amp;ReleaseBlock, block_cache, cache_handle); &#125; &#125; else &#123; // 否则创建非法的空的iterator iter = NewErrorIterator(s); &#125; return iter;&#125; NewIterator由Table对象返回的Iterator实际上是一个TwoLevelIterator，其具体实现会在后面进行讲解，这个iterator实际上涉及到从index handle到对应data block之间的转换，转换函数就是前面的BlockReader函数。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb table builder 解析]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-table-builder-%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[leveldb table_builder解析在leveldb之中，为了维持接口的简单，不暴露太多的实现细节，大量使用了impl机制，将具体实现定义在内部类之中，table_builder又是一例。 table_builder实际上对应的是sstable的建立过程，包括相关block的存储处理。首先，有必要重温一下sstable文件的具体格式。 成员和构造函数table_builder数据成员如下所示： 12345678910111213141516171819202122232425262728293031Options options;Options index_block_options;WritableFile* file;uint64_t offset;Status status;BlockBuilder data_block;BlockBuilder index_block;std::string last_key;int64_t num_entries;bool closed; // Either Finish() or Abandon() has been called.// FilterBlockFilterBlockBuilder* filter_block;// We do not emit the index entry for a block until we have seen the// first key for the next data block. This allows us to use shorter// keys in the index block. For example, consider a block boundary// between the keys "the quick brown fox" and "the who". We can use// "the r" as the key for the index block entry since it is &gt;= all// entries in the first block and &lt; all entries in subsequent// blocks.//// Invariant: r-&gt;pending_index_entry is true only if data_block is empty.// 是否需要更新index block ?// 若data_block为空，那么pending_index_entry为truebool pending_index_entry;// add 进入 index block 的handleBlockHandle pending_handle; // Handle to add to index block// compressed output// snappy压缩的输出存放地std::string compressed_output; 可见，相关数据成员和sstable文件中的各类型block基本一一对应，其他项用途由注释可知。 在构造函数中，根据输入的参数初始化各成员变量。注意，对于index block，restart间隔被设置为1，也就是每一个record都存储完整的record值。 上面说到的数据成员和构造函数都是内部类Rep的，实际上，TableBuilder通过建立Rep对象，将相关的操作转发给此对象，实现都是在Rep之中。 1234567TableBuilder::TableBuilder(const Options&amp; options, WritableFile* file) : rep_(new Rep(options, file)) &#123; if (rep_-&gt;filter_block != NULL) &#123; // 初始化filter block rep_-&gt;filter_block-&gt;StartBlock(0); &#125;&#125; AddAdd操作是TableBuilder中的重点，占据了大部分篇幅。Add操作也需要保证添加key的顺序是升序。若当前data block为空，将新的data block的handle信息保存在index block之中。请注意，这里对handle的key采用的是比last_key_大，比当前key小的字符串。 若制定了filter_policy，就将这个key加入filter_block，同时记录last_key，更新添加的key的总数，向data block插入这条键值对。若data block的大小超出option限定的值（默认为4K），就调用Flush，将这一数据块写入文件。 123456789101112131415161718192021222324252627282930313233343536373839void TableBuilder::Add(const Slice&amp; key, const Slice&amp; value) &#123; Rep* r = rep_; assert(!r-&gt;closed); if (!ok()) return; // 断言Add的key比之前的更大 if (r-&gt;num_entries &gt; 0) &#123; assert(r-&gt;options.comparator-&gt;Compare(key, Slice(r-&gt;last_key)) &gt; 0); &#125; if (r-&gt;pending_index_entry) &#123; assert(r-&gt;data_block.empty()); // 找到比last_key大，比key小的key，存放在last_key之中 r-&gt;options.comparator-&gt;FindShortestSeparator(&amp;r-&gt;last_key, key); std::string handle_encoding; // 记录第一个data block，保存进入index_block之中 r-&gt;pending_handle.EncodeTo(&amp;handle_encoding); // 在index block之中添加这个block的handle信息 r-&gt;index_block.Add(r-&gt;last_key, Slice(handle_encoding)); r-&gt;pending_index_entry = false; &#125; // 向filter_block之中add key if (r-&gt;filter_block != NULL) &#123; r-&gt;filter_block-&gt;AddKey(key); &#125; // 记录last key r-&gt;last_key.assign(key.data(), key.size()); // 记录add key的总数 r-&gt;num_entries++; // 向data block之中添加这一条记录 r-&gt;data_block.Add(key, value); const size_t estimated_block_size = r-&gt;data_block.CurrentSizeEstimate(); // 若data block的大小超出设定值，Flush 4K if (estimated_block_size &gt;= r-&gt;options.block_size) &#123; Flush(); &#125;&#125; Flush操作如下： 12345678910111213141516171819void TableBuilder::Flush() &#123; Rep* r = rep_; assert(!r-&gt;closed); if (!ok()) return; if (r-&gt;data_block.empty()) return; // data block 不为空 assert(!r-&gt;pending_index_entry); WriteBlock(&amp;r-&gt;data_block, &amp;r-&gt;pending_handle); if (ok()) &#123; // 需要写入新的数据块 r-&gt;pending_index_entry = true; // flush r-&gt;status = r-&gt;file-&gt;Flush(); &#125; // 若filter_block不为空，那么开始对r-&gt;offset段写入滤值 if (r-&gt;filter_block != NULL) &#123; r-&gt;filter_block-&gt;StartBlock(r-&gt;offset); &#125;&#125; Flush首先写入数据块，更新新的数据块对应的handle位置，并且通知filter policy开始对新的offset生成filter。 在WriteBlock中，根据option设定，对data block进行可选的压缩处理。只有当压缩选项被设置，而且压缩可用，压缩减小的空间大小高于12.5%，才会进行压缩。 123456789101112131415161718192021222324252627282930313233343536void TableBuilder::WriteBlock(BlockBuilder* block, BlockHandle* handle) &#123; // File format contains a sequence of blocks where each block has: // block_data: uint8[n] // type: uint8 // crc: uint32 assert(ok()); Rep* r = rep_; Slice raw = block-&gt;Finish(); Slice block_contents; CompressionType type = r-&gt;options.compression; // TODO(postrelease): Support more compression options: zlib? switch (type) &#123; case kNoCompression: block_contents = raw; break; case kSnappyCompression: &#123; std::string* compressed = &amp;r-&gt;compressed_output; // 使用snappy压缩成功，并且压缩的空间大于12.5% if (port::Snappy_Compress(raw.data(), raw.size(), compressed) &amp;&amp; compressed-&gt;size() &lt; raw.size() - (raw.size() / 8u)) &#123; block_contents = *compressed; &#125; else &#123; // Snappy not supported, or compressed less than 12.5%, so just // store uncompressed form block_contents = raw; type = kNoCompression; &#125; break; &#125; &#125; WriteRawBlock(block_contents, type, handle); r-&gt;compressed_output.clear(); block-&gt;Reset();&#125; WriteRawBlock中，还为写入的data block添加了crc校验码以及type信息。 12345678910111213141516171819202122void TableBuilder::WriteRawBlock(const Slice&amp; block_contents, CompressionType type, BlockHandle* handle) &#123; Rep* r = rep_; // 设置offset和size, 其实设置在r-&gt;pending_handle之中 handle-&gt;set_offset(r-&gt;offset); handle-&gt;set_size(block_contents.size()); // 向file中写入block r-&gt;status = r-&gt;file-&gt;Append(block_contents); if (r-&gt;status.ok()) &#123; char trailer[kBlockTrailerSize]; trailer[0] = type; uint32_t crc = crc32c::Value(block_contents.data(), block_contents.size()); crc = crc32c::Extend(crc, trailer, 1); // Extend crc to cover block type EncodeFixed32(trailer+1, crc32c::Mask(crc)); // 写入trailer r-&gt;status = r-&gt;file-&gt;Append(Slice(trailer, kBlockTrailerSize)); if (r-&gt;status.ok()) &#123; r-&gt;offset += block_contents.size() + kBlockTrailerSize; &#125; &#125;&#125; Finish finish操作会将数据块都写入到文件，并且依照sstable文件格式，依次写入filter block，filter index block，index block，footer，完成收尾工作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Status TableBuilder::Finish() &#123; Rep* r = rep_; Flush(); assert(!r-&gt;closed); r-&gt;closed = true; BlockHandle filter_block_handle, metaindex_block_handle, index_block_handle; // Write filter block // 记录filter block 的handle if (ok() &amp;&amp; r-&gt;filter_block != NULL) &#123; WriteRawBlock(r-&gt;filter_block-&gt;Finish(), kNoCompression, &amp;filter_block_handle); &#125; // Write metaindex block if (ok()) &#123; BlockBuilder meta_index_block(&amp;r-&gt;options); if (r-&gt;filter_block != NULL) &#123; // Add mapping from "filter.Name" to location of filter data std::string key = "filter."; key.append(r-&gt;options.filter_policy-&gt;Name()); std::string handle_encoding; filter_block_handle.EncodeTo(&amp;handle_encoding); // 将filter block的信息加入mata_index_block meta_index_block.Add(key, handle_encoding); &#125; // TODO(postrelease): Add stats and other meta blocks WriteBlock(&amp;meta_index_block, &amp;metaindex_block_handle); &#125; // Write index block if (ok()) &#123; if (r-&gt;pending_index_entry) &#123; r-&gt;options.comparator-&gt;FindShortSuccessor(&amp;r-&gt;last_key); std::string handle_encoding; r-&gt;pending_handle.EncodeTo(&amp;handle_encoding); // 添加最后一个data block的handle信息 r-&gt;index_block.Add(r-&gt;last_key, Slice(handle_encoding)); r-&gt;pending_index_entry = false; &#125; // 写入index block WriteBlock(&amp;r-&gt;index_block, &amp;index_block_handle); &#125; // Write footer if (ok()) &#123; Footer footer; footer.set_metaindex_handle(metaindex_block_handle); footer.set_index_handle(index_block_handle); std::string footer_encoding; footer.EncodeTo(&amp;footer_encoding); r-&gt;status = r-&gt;file-&gt;Append(footer_encoding); if (r-&gt;status.ok()) &#123; r-&gt;offset += footer_encoding.size(); &#125; &#125; return r-&gt;status;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb format解析]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-format%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[leveldb format 解析下面解析的是leveldb中的源文件format.h和format.cc，这一节代码主要围绕handle的存储和解析，footer的存储和解析，以及block的读取。 handlehandle 是对block文件之中位移和大小封装的数据结构，有了它，就能迅速对block进行定位。因为采取varint64存储这两个值，所以占据的大小最大为10bytes。 12345678910111213141516171819202122232425class BlockHandle &#123; public: BlockHandle(); // The offset of the block in the file. uint64_t offset() const &#123; return offset_; &#125; void set_offset(uint64_t offset) &#123; offset_ = offset; &#125; // The size of the stored block uint64_t size() const &#123; return size_; &#125; void set_size(uint64_t size) &#123; size_ = size; &#125; // 向dst指定的地址位置存入offset和size void EncodeTo(std::string* dst) const; // 从input指定的地址位置获取offset和size Status DecodeFrom(Slice* input); // Maximum encoding length of a BlockHandle // 两个varint64数占用的空间最大为20bytes enum &#123; kMaxEncodedLength = 10 + 10 &#125;; private: uint64_t offset_; uint64_t size_;&#125;; FooterFooter位于整个sstable文件的底部，由footer可以快速获取sstable中的metaindex block，index block的位置信息，通过比较魔数，能够快速判断是否是leveldb之中使用的sstable文件。 在Footer之中，前面40bytes存储Metaindex_handle和Index_handle，若空间不足40bytes就用0补齐。之后存放leveldb中定义的魔数0xdb4775248b80fb57ull。 1234567891011121314151617181920// footer// metaindex_handle// index_handle// padding// magic numbervoid Footer::EncodeTo(std::string* dst) const &#123; const size_t original_size = dst-&gt;size(); // 此处存放的是varint64 metaindex_handle_.EncodeTo(dst); index_handle_.EncodeTo(dst); dst-&gt;resize(2 * BlockHandle::kMaxEncodedLength); // Padding // 加上padding，为 40 bytes // 再加上8bytes对应的魔数 // 先存低 4bytes PutFixed32(dst, static_cast&lt;uint32_t&gt;(kTableMagicNumber &amp; 0xffffffffu)); // 再存高 4 bytes PutFixed32(dst, static_cast&lt;uint32_t&gt;(kTableMagicNumber &gt;&gt; 32)); assert(dst-&gt;size() == original_size + kEncodedLength); (void)original_size; // Disable unused variable warning.&#125; 在读取footer时，首先读取魔数，没有问题才继续读取meta index handle和index handle。 1234567891011121314151617181920212223// input输入的是整个footerStatus Footer::DecodeFrom(Slice* input) &#123; const char* magic_ptr = input-&gt;data() + kEncodedLength - 8; const uint32_t magic_lo = DecodeFixed32(magic_ptr); const uint32_t magic_hi = DecodeFixed32(magic_ptr + 4); const uint64_t magic = ((static_cast&lt;uint64_t&gt;(magic_hi) &lt;&lt; 32) | (static_cast&lt;uint64_t&gt;(magic_lo))); // 魔数不匹配 if (magic != kTableMagicNumber) &#123; return Status::Corruption("not an sstable (bad magic number)"); &#125; Status result = metaindex_handle_.DecodeFrom(input); if (result.ok()) &#123; result = index_handle_.DecodeFrom(input); &#125; if (result.ok()) &#123; // We skip over any leftover data (just padding for now) in "input" const char* end = magic_ptr + 8; *input = Slice(end, input-&gt;data() + input-&gt;size() - end); &#125; return result;&#125; blockleveldb在存储block的时候，实际上还要记录block的类型和当前block的CRC校验值在后面进行校验。block格式如下所示： 读取block时，首先根据option要求进行可选的crc校验，再根据type查看是压缩数据块还是raw block，对压缩数据块进行解压缩。若成功读取将读取处理之后的block记录在result之中，失败了就返回相应的状态码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// block - type - crcStatus ReadBlock(RandomAccessFile* file, const ReadOptions&amp; options, const BlockHandle&amp; handle, BlockContents* result) &#123; result-&gt;data = Slice(); result-&gt;cachable = false; result-&gt;heap_allocated = false; // Read the block contents as well as the type/crc footer. // See table_builder.cc for the code that built this structure. size_t n = static_cast&lt;size_t&gt;(handle.size()); char* buf = new char[n + kBlockTrailerSize]; Slice contents; Status s = file-&gt;Read(handle.offset(), n + kBlockTrailerSize, &amp;contents, buf); // 读取失败 if (!s.ok()) &#123; delete[] buf; return s; &#125; // 读取的block大小和handle不一致 if (contents.size() != n + kBlockTrailerSize) &#123; delete[] buf; return Status::Corruption("truncated block read"); &#125; // 检查block+type计算得到的crc值是否和记录的所一致 // Check the crc of the type and the block contents const char* data = contents.data(); // Pointer to where Read put the data if (options.verify_checksums) &#123; const uint32_t crc = crc32c::Unmask(DecodeFixed32(data + n + 1)); const uint32_t actual = crc32c::Value(data, n + 1); if (actual != crc) &#123; delete[] buf; s = Status::Corruption("block checksum mismatch"); return s; &#125; &#125; // 针对block的不同类型，采取不同的操作 switch (data[n]) &#123; case kNoCompression: if (data != buf) &#123; // File implementation gave us pointer to some other data. // Use it directly under the assumption that it will be live // while the file is open. // 内部文件操作返回的buf不是之前分配的 delete[] buf; result-&gt;data = Slice(data, n); result-&gt;heap_allocated = false; result-&gt;cachable = false; // Do not double-cache &#125; else &#123; result-&gt;data = Slice(buf, n); result-&gt;heap_allocated = true; result-&gt;cachable = true; &#125; // Ok break; // 是压缩的类型，获取解压的长度，解压block case kSnappyCompression: &#123; size_t ulength = 0; if (!port::Snappy_GetUncompressedLength(data, n, &amp;ulength)) &#123; delete[] buf; return Status::Corruption("corrupted compressed block contents"); &#125; char* ubuf = new char[ulength]; if (!port::Snappy_Uncompress(data, n, ubuf)) &#123; delete[] buf; delete[] ubuf; return Status::Corruption("corrupted compressed block contents"); &#125; delete[] buf; result-&gt;data = Slice(ubuf, ulength); result-&gt;heap_allocated = true; result-&gt;cachable = true; break; &#125; default: delete[] buf; return Status::Corruption("bad block type"); &#125; return Status::OK();&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb data block 建立]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-data-block-%E5%BB%BA%E7%AB%8B%2F</url>
    <content type="text"><![CDATA[leveldb data block 建立总览相比data block的读取来说，data block的建立比较简单，因为不涉及到查找的操作。下面的所有操作都是根据data block 内部的组织格式进行的，如下图所示。 data block record leveldb data block 建立相关的代码是data_block.h和data_block.c。 实现类成员类成员如下所示，buffers存放最终生成的data block，restarts\对应restarts数组，counter是自从上一次restart以来添加的key的计数，last_key_记录了上一次add的key。Options对应传入的参数，其中定义了restart的间隔大小限制。 12345678const Options* options_;std::string buffer_; // Destination buffer// 所有的restart数组的元素std::vector&lt;uint32_t&gt; restarts_; // Restart points// restart之后已经加入的entry的数目int counter_; // Number of entries emitted since restartbool finished_; // Has Finish() been called?std::string last_key_; 辅助类成员函数CurrentSizeEstimate() 返回当前估计的data block的大小，empty判断当前数据块是否为空，Reset重置所有状态，丢弃所有添加的key。 1234567891011// Reset the contents as if the BlockBuilder was just constructed.void Reset();// Returns an estimate of the current (uncompressed) size of the block// we are building.size_t CurrentSizeEstimate() const;// Return true iff no entries have been added since the last Reset()bool empty() const &#123; return buffer_.empty();&#125; Add和Finish操作data block在BlockBuilder类对象初始化之后，通过Add方法向block中添加键值对记录，数据块建立完成之后，调用Finish返回完整的数据块数据。 Add操作要求添加的key的顺序应该是升序的。在Add中，首先检查是否达到restart间隔。若达到了，那么shared key的长度为0，否则和last key比较得到shared key的长度。之后则将共享key，非共享key，value的长度值写入buffer之中，同时也将非共享key和value的值写入buffer，更新last key。 123456789101112131415161718192021222324252627282930313233343536373839void BlockBuilder::Add(const Slice&amp; key, const Slice&amp; value) &#123; Slice last_key_piece(last_key_); assert(!finished_); assert(counter_ &lt;= options_-&gt;block_restart_interval); // 要求key比last_key要大 assert(buffer_.empty() // No values yet? || options_-&gt;comparator-&gt;Compare(key, last_key_piece) &gt; 0); size_t shared = 0; if (counter_ &lt; options_-&gt;block_restart_interval) &#123; // See how much sharing to do with previous string const size_t min_length = std::min(last_key_piece.size(), key.size()); // 计算shared 的key的长度 while ((shared &lt; min_length) &amp;&amp; (last_key_piece[shared] == key[shared])) &#123; shared++; &#125; &#125; else &#123; // Restart compression restarts_.push_back(buffer_.size()); counter_ = 0; &#125; // 不共享的key的长度 const size_t non_shared = key.size() - shared; // Add "&lt;shared&gt;&lt;non_shared&gt;&lt;value_size&gt;" to buffer_ PutVarint32(&amp;buffer_, shared); PutVarint32(&amp;buffer_, non_shared); PutVarint32(&amp;buffer_, value.size()); // Add string delta to buffer_ followed by value buffer_.append(key.data() + shared, non_shared); buffer_.append(value.data(), value.size()); // Update state // 设置last key last_key_.resize(shared); last_key_.append(key.data() + shared, non_shared); assert(Slice(last_key_) == key); counter_++;&#125; Finish操作则是将所有的restarts数组元素写入到block之中，同时在block之中写入数组的size信息，返回整个block对应的Slice。 1234567891011// 调用finish，设置restarts数组和restarts数组的个数，返回此data blockSlice BlockBuilder::Finish() &#123; // Append restart array for (size_t i = 0; i &lt; restarts_.size(); i++) &#123; PutFixed32(&amp;buffer_, restarts_[i]); &#125; // put restarts_.size() PutFixed32(&amp;buffer_, restarts_.size()); finished_ = true; return Slice(buffer_);&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb data block 读取解析]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-data-block-%E8%AF%BB%E5%8F%96%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[leveldb data block 读取解析下面解析的代码是block.h和block.cc，这一部分代码的功能是读取data block，并且提供一个基于data block中存储数据之上的迭代器。这一部分代码的实现首先基于data block内部存储格式，并且借助了data block数据有序的特性。 data block 内部格式 record 格式 BlockBlock的基本第一很简单，主要逻辑是一个迭代器的实现，定义在在内部类Iter中。 12345678910111213141516171819202122232425class Block &#123; public: // Initialize the block with the specified contents. explicit Block(const BlockContents&amp; contents); ~Block(); size_t size() const &#123; return size_; &#125; // Return new Iterator of given comparator Iterator* NewIterator(const Comparator* comparator); private: uint32_t NumRestarts() const; const char* data_; // 指向data block 开始处 size_t size_; // data block的大小 uint32_t restart_offset_; // Offset in data_ of restart array bool owned_; // Block owns data_[], if own need to call free when destruction // No copying allowed Block(const Block&amp;); void operator=(const Block&amp;); // 内部实现实际定义在Iter中 class Iter;&#125;; 在构造函数中，读取restarts数组的数目，判断是否合理，即存储的数组大小不可超出max_restarts_allowed。 1234567891011121314151617181920// 读取contents对应的block// 实际上读取的是data blockBlock::Block(const BlockContents&amp; contents) : data_(contents.data.data()), size_(contents.data.size()), owned_(contents.heap_allocated) &#123; if (size_ &lt; sizeof(uint32_t)) &#123; size_ = 0; // Error marker &#125; else &#123; // 最大允许的restarts的数目 size_t max_restarts_allowed = (size_-sizeof(uint32_t)) / sizeof(uint32_t); if (NumRestarts() &gt; max_restarts_allowed) &#123; // The size is too small for NumRestarts() size_ = 0; &#125; else &#123; // 指向restart数组开始的位置 restart_offset_ = size_ - (1 + NumRestarts()) * sizeof(uint32_t); &#125; &#125;&#125; 如果输入块的大小不足以容纳存放restarts数组大小的数，那么返回空的Error Iterator，若restarts数组数目为0，返回空的Iterator，否则返回内部类Iter中实现的Iterator。 123456789101112131415Iterator* Block::NewIterator(const Comparator* cmp) &#123; // 块的大小无法存储restarts数组的数目 if (size_ &lt; sizeof(uint32_t)) &#123; return NewErrorIterator(Status::Corruption("bad block contents")); &#125; // restarts数组的元素数目 const uint32_t num_restarts = NumRestarts(); // 返回一个空的iterator if (num_restarts == 0) &#123; return NewEmptyIterator(); &#125; else &#123; // 返回iterator return new Iter(cmp, data_, restart_offset_, num_restarts); &#125;&#125; Iter内部类Iter的成员如下所示： 12345678910111213const Comparator* const comparator_; const char* const data_; // underlying block contents // 指向restart数组的第一个元素 uint32_t const restarts_; // Offset of restart array (list of fixed32) uint32_t const num_restarts_; // Number of uint32_t entries in restart array // current_ is offset in data_ of current entry. &gt;= restarts_ if !Valid uint32_t current_; // 当前current_位置对应的restart数组的index uint32_t restart_index_; // Index of restart block in which current_ falls std::string key_; Slice value_; Status status_; 在构造函数之中，根据输入参数对类内部成员进行初始化，并且断言restarts数组的数目不为0。current_指向当前遍历到的record的开头位置。 12345678910111213Iter(const Comparator* comparator, const char* data, uint32_t restarts, uint32_t num_restarts) : comparator_(comparator), // 比较器 data_(data), // data restarts_(restarts), // 指向restart数组的开头位置 num_restarts_(num_restarts), // restart数组的元素个数 current_(restarts_), // current_ is offset in data_ of current entry. restart_index_(num_restarts_) &#123; // restart index // 断言restarts数组中的元素个数大于0 assert(num_restarts_ &gt; 0); &#125; 解析record的时候，调用ParseNextKey，首先判断当前record的位置是否有效，然后获取共享，不共享key的长度，value的长度，设置当前entry对应的key和value，并且设置下一个key对应的restart_index。 123456789101112131415161718192021222324252627282930313233343536373839// 解析下一个值的实现 bool ParseNextKey() &#123; // 下一个entry的offset current_ = NextEntryOffset(); const char* p = data_ + current_; // 不可能越过restarts数组 const char* limit = data_ + restarts_; // Restarts come right after data // 没有更多的entry，设置current和restart_index_，并且返回 if (p &gt;= limit) &#123; // No more entries to return. Mark as invalid. current_ = restarts_; restart_index_ = num_restarts_; return false; &#125; // Decode next entry uint32_t shared, non_shared, value_length; // 现在p指向non_shared key p = DecodeEntry(p, limit, &amp;shared, &amp;non_shared, &amp;value_length); // 解析失败，或者key的长度小于共享key的长度 // 产生了崩溃错误，返回失败 if (p == NULL || key_.size() &lt; shared) &#123; CorruptionError(); return false; &#125; else &#123; // 设置key_和value_ key_.resize(shared); key_.append(p, non_shared); // 这里的value_存放的是对应的value值 value_ = Slice(p + non_shared, value_length); // 跳过无效的restart数组元素，下一个restart数组元素指向的offset需要大于当前current_对应的偏移 while (restart_index_ + 1 &lt; num_restarts_ &amp;&amp; GetRestartPoint(restart_index_ + 1) &lt; current_) &#123; ++restart_index_; &#125; return true; &#125; &#125;&#125;; 结合record格式，对于DecodeEntry的实现可以有清晰的认识： DecodeEntry实际上是解析出共享key，非共享key和value的长度，使得p指向value开头的位置。因为key的长度一般不超过128，而且存储长度使用了varint32格式，所以这里首先尝试fast path。 123456789101112131415161718192021222324252627static inline const char* DecodeEntry(const char* p, const char* limit, uint32_t* shared, uint32_t* non_shared, uint32_t* value_length) &#123; // 不够存放key共享长度，key非共享长度和value长度 // 3个varint32数，最少需要的空间是3byte if (limit - p &lt; 3) return NULL; // 取出key共享长度，非共享长度以及value的长度 // 这几个长度都是使用varint32进行存放 *shared = reinterpret_cast&lt;const unsigned char*&gt;(p)[0]; *non_shared = reinterpret_cast&lt;const unsigned char*&gt;(p)[1]; *value_length = reinterpret_cast&lt;const unsigned char*&gt;(p)[2]; if ((*shared | *non_shared | *value_length) &lt; 128) &#123; // Fast path: all three values are encoded in one byte each p += 3; &#125; else &#123; if ((p = GetVarint32Ptr(p, limit, shared)) == NULL) return NULL; if ((p = GetVarint32Ptr(p, limit, non_shared)) == NULL) return NULL; if ((p = GetVarint32Ptr(p, limit, value_length)) == NULL) return NULL; &#125; // 若剩余的字符串长度不足以存放non_shared key和value，返回 NULL if (static_cast&lt;uint32_t&gt;(limit - p) &lt; (*non_shared + *value_length)) &#123; return NULL; &#125; // 返回指向non_shared key字符串开始位置对应的指针 return p;&#125; 相比而言，Prev的实现稍微复杂一点。首先获取上一个entry对应的restarts数组的index值，然后调整到对应的offset，遍历entry，直到entry的右边界和Prev操作之前的entry的offset重合，就找到了上一个entry。 123456789101112131415161718192021222324// iterator 往前移动一位 virtual void Prev() &#123; assert(Valid()); // Scan backwards to a restart point before current_ const uint32_t original = current_; // 设置正确的restart_index_ // 若越过了，就轮转 while (GetRestartPoint(restart_index_) &gt;= original) &#123; if (restart_index_ == 0) &#123; // No more entries current_ = restarts_; restart_index_ = num_restarts_; return; &#125; restart_index_--; &#125; // 调整到正确的restart_index_对应的位置 SeekToRestartPoint(restart_index_); // 循环直到当前entry结束的位置和original entry对应的位置相同 do &#123; // Loop until end of current entry hits the start of original entry &#125; while (ParseNextKey() &amp;&amp; NextEntryOffset() &lt; original); &#125; Seek操作利用了data block中的record有序的特性，首先利用二分查找找到小于target但是最接近target的restarts数组的偏移位置。在此偏移位置的基础之上，往后遍历直到对应entry的key大于等于target，迭代器就移动到了第一个大于或等于target的位置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748virtual void Seek(const Slice&amp; target) &#123; // Binary search in restart array to find the last restart point // with a key &lt; target // 进行二分查找，找到最后的restart point, key &lt; target uint32_t left = 0; uint32_t right = num_restarts_ - 1; // loop until left hit right while (left &lt; right) &#123; // middle uint32_t mid = (left + right + 1) / 2; uint32_t region_offset = GetRestartPoint(mid); uint32_t shared, non_shared, value_length; // 解析middle restart的第一个key const char* key_ptr = DecodeEntry(data_ + region_offset, data_ + restarts_, &amp;shared, &amp;non_shared, &amp;value_length); // 发生错误，或者第一个key shared的长度不为0 if (key_ptr == NULL || (shared != 0)) &#123; CorruptionError(); return; &#125; Slice mid_key(key_ptr, non_shared); // 在右半部分 if (Compare(mid_key, target) &lt; 0) &#123; // Key at "mid" is smaller than "target". Therefore all // blocks before "mid" are uninteresting. left = mid; &#125; // 在左半部分 else &#123; // Key at "mid" is &gt;= "target". Therefore all blocks at or // after "mid" are uninteresting. right = mid - 1; &#125; &#125; // Linear search (within restart block) for first key &gt;= target SeekToRestartPoint(left); // 找到第一个 &gt;= target的key while (true) &#123; if (!ParseNextKey()) &#123; return; &#125; if (Compare(key_, target) &gt;= 0) &#123; return; &#125; &#125; &#125; 相比而言SeekToFirst和SeekToLast的实现比较简单，如代码所示： 12345678910111213// 指向第一个restarts数组元素对应的offset，然后解析获取值virtual void SeekToFirst() &#123; SeekToRestartPoint(0); ParseNextKey();&#125;// 指向最后一个restarts数组元素对应的offset，然后解析所有剩余的keyvirtual void SeekToLast() &#123; SeekToRestartPoint(num_restarts_ - 1); while (ParseNextKey() &amp;&amp; NextEntryOffset() &lt; restarts_) &#123; // Keep skipping &#125;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++运行时类型识别]]></title>
    <url>%2F2017%2F06%2F11%2FC-%E8%BF%90%E8%A1%8C%E6%97%B6%E7%B1%BB%E5%9E%8B%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[C++ 运行时类型识别C++中运行时类型识别(run-time type identification, RTTI)的功能由两个运算符实现。 typeid运算符，用于返回表达式的类型。 dynamic_cast运算符，用于将基类的指针或引用安全地转换成派生类的指针或者引用。 这两个运算符特别适用于以下情况：我们想使用基类对象的指针或引用执行某个派生类操作并且该操作不是虚函数。一般来说，只要有可能我们应该尽量使用虚函数。当操作被定义成为虚函数时，编译器将根据对象的动态类型根据对象的动态类型自动选择正确的函数版本。 dynamic_cast运算符dynamic_cast运算符的使用形式如下所示： 123dynamic_cast&lt;type*&gt;(e);dynamic_cast&lt;type&amp;&gt;(e);dynamic_cast&lt;type&amp;&amp;&gt;(e); type必须是一个类类型，并且通常情况下该类型应该含有虚函数。 在上面的所有形式之中，e的类型必须符合下面3个条件之中的任意一个： e的类型是目标type的公有派生类 e的类型是目标type的公有基类 e的类型就是目标type的类型。 如果符合，则类型转换就可以成功。否则，转换失败。如果一条dynamica_cast语句的转换目标是指针类型并且失败了，则结果为0。如果转换目标是引用类型并且失败了，则dynamic_cast运算符将抛出一个bad_cast的异常。 使用举例： 指针类型的dynamic_cast 12345678if (Derived* dp = dynamic_cast&lt;Derived*&gt;(bp))&#123; // 使用dp指向的Derived对象 &#125;else&#123; // 转换失败，使用bp指向的Base对象&#125; 引用类型的dynamic_cast 1234567891011void f(const Base&amp; b)&#123; try &#123; const Derived&amp; d = dynamic_cast&lt;const Derived&amp;&gt;(b); // 使用b引用的Derived对象 &#125; catch(bad_cast) &#123; // 处理类型转换失败的情况 &#125;&#125; typeid运算符为RTTI提供的第二个运算符是typeid运算符，它允许程序向表达式提问，你是什么类型？ typeid表达式的形式是typeid(e)，其中e可以是任意表达式或者类型的名字。typeid操作的结果是一个常量对象的引用，该对象的类型是标准库类型type_info或者type_info的公有派生类型。 可以通过下述方式比较两条表达式的类型是否相同，或者比较一条表达式的类型是否与指定类型相同。 123456789101112Derived* dp = new Derived;Base* bp = dp;if(typeid(*bp) == typeid(*dp))&#123; // bp和dp指向同一类型的对象&#125;// 检查运行时类型是否是某种指定的类型// 请注意，typeid应该作用于对象而不是指针。if(typeid(*bp) == typeid(Derived))&#123; // bp 实际指向Derived对象&#125; type_info类type_info类的精确定义和编译器的实现有关。C++标准规定type_info类必须定义在typeinfo头文件中，并且至少提供以下操作： 操作 说明 t1 == t2 若type_info对象t1和t2表示同一类型，返回true，否则返回false t1 != t2 如果type_info对象t1和t2表示不同的类型，返回true，否则返回false t.name() 返回一个C风格字符串，表示类型名字的可打印形式。类型名字的生成方式因系统而定 t1.before(t2) 返回一个bool值，表示t1是否位于t2之前。before所采用的顺序关系是依赖于编译器的 示例程序： 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;typeinfo&gt;using namespace std;class test&#123; public:&#125;;int main()&#123; int arr[10]; string str; cout &lt;&lt; typeid(42).name() &lt;&lt; endl; cout &lt;&lt; typeid(arr).name() &lt;&lt; endl; cout &lt;&lt; typeid(str).name() &lt;&lt; endl; return 0;&#125; 输出(macos, clang)： 1234iA10_iNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE4test]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++内存模型]]></title>
    <url>%2F2017%2F06%2F11%2FC-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[C++ std::atomic 原子类型原子操作：一个不可分割的操作。标准原子类型可以在头文件之中找到，在这种类型上的所有操作都是原子的。它们都有一个is_lock_free()的成员函数，让用户决定在给定类型上的操作是否用原子指令完成。唯一不提供is_lock_free()成员函数的类型是std::atomic_flag,在此类型上的操作要求是无锁的。可以利用std::atomic_flag实现一个简单的锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;atomic&gt;#include &lt;assert.h&gt;class spinlock_mutex&#123; public: spinlock_mutex() : flag_(ATOMIC_FLAG_INIT) &#123; &#125; void lock() &#123; while(flag_.test_and_set(std::memory_order_acquire)) ; &#125; void unlock() &#123; flag_.clear(std::memory_order_release); &#125; private: std::atomic_flag flag_;&#125;;int value = 0;spinlock_mutex mutex;void test_function()&#123; for(int i = 0; i &lt; 100000; i++) &#123; std::unique_lock&lt;spinlock_mutex&gt; lock(mutex); ++ value; &#125;&#125;int main()&#123; std::thread t1(test_function); std::thread t2(test_function); t1.join(); t2.join(); assert(value == 200000); return 0;&#125; C++ 11中的内存模型都是围绕std::atomic展开的，下面依次介绍C++ 11中引入的内存顺序。参考: Memory Model 顺序一致顺序默认的的顺序被命名为顺序一致，因为这意味着程序的行为和一个简单的世界观是一致的。如果所有原子类型实例上的操作是顺序一致的，多线程的行为就好像是所有这些操作由单个线程以某种特定的顺序进行执行的一样。在一个带有多处理器的弱顺序的机器上，它可能导致显著的性能惩罚，因为操作的整体顺序必须与处理器之间保持一致，可能需要处理器之间进行密集的同步操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x()&#123; x.store(true, std::memory_order_seq_cst);&#125;void write_y()&#123; y.store(true, std::memory_order_seq_cst);&#125;void read_x_then_y()&#123; while(!x.load(std::memory_order_seq_cst)) ; if(y.load(std::memory_order_seq_cst)) &#123; printf("x,y\n"); ++ z; &#125;&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_seq_cst)) ; if(x.load(std::memory_order_seq_cst)) &#123; printf("y,x\n"); ++ z; &#125;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load() != 0); return 0;&#125; 上述代码中的assert永远不会触发，因为while循环总能保证x或者y的值已经修改为true，如果线程c或d中有一个线程if条件不满足，那么另一个线程的if条件总能保障，所以最后z的值一定不为0。请注意memory_order_seq_cst的语义需要在所有标记memory_order_seq_cst的操作上有单一的总体顺序。 顺序一致是最直观的顺序，但是也是最为昂贵的内存顺序，因为它要求所有线程之间的全局同步。在多处理器系统中，这可能需要处理器之间相当密集和耗时的通信。 松散顺序以松散顺序执行的原子类型上的操作不参与synchronizes-with关系。单线程中的同一变量的操作仍然服从happens-before的关系，但相对于其他线程的顺序几乎没有任何要求。唯一的要求是，从同一线程对单个原子变量的访问不能重排，一旦给定的线程已经看到了原子变量的特定值，该线程之后的读取就不能获取该变量更早的值。以下程序展现了这种松散性。 123456789101112131415161718192021222324252627282930313233#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x_then_y()&#123; x.store(true, std::memory_order_relaxed); y.store(true, std::memory_order_relaxed);&#125;void read_x_then_y()&#123; while(!y.load(std::memory_order_relaxed)) ; if(x.load(std::memory_order_relaxed)) ++ z;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x_then_y); std::thread b(read_x_then_y); a.join(); b.join(); assert(z.load() != 0);&#125; 这一次，assert可能会触发。因为x和y是不同的变量，每个操作所产生的值的可见性没有顺序的保证。 为了理解松散顺序是如何工作的，可以想象每个变量是一个小隔间里使用记事本的人。在他的记事本上有一列值。你可以打电话给他，要求他给你一个值，或者你可以告诉他写下了一个新值。如果你告诉他写下新值，他就将其写在列表的底部。如果你向他要一个值，他就为你从列表之中读取一个数字。第一次你和这个人交谈，如果你向他要一个值，此时他可能从他的记事本上的列表里任意选一个给你。如果你接着向他要另一个值，他可能会再给你同一个值，或者从列表的下方给一个给你。他永远不会给你一个在列表上更上面的值。 获取释放顺序获取释放顺序是松散顺序的进步，操作仍然没有总的顺序，但是引入了一些同步。在这个顺序模型下，原子载入是acquire操作memory_order_acquire，原子存储是release操作memory_order_release，原子的读，修改，写操作是获取，释放或者两者兼有memory_order_acq_rel。不同的线程仍然可以看到不同的顺序，但是这些顺序受到了限制。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x()&#123; x.store(true, std::memory_order_release);&#125;void write_y()&#123; y.store(true, std::memory_order_release);&#125;void read_x_then_y()&#123; while(!x.load(std::memory_order_acquire)) ; if(y.load(std::memory_order_acquire)) &#123; ++ z; &#125;&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_seq_cst)) ; if(x.load(std::memory_order_seq_cst)) &#123; ++ z; &#125;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load() != 0); return 0;&#125; 上述代码中的断言仍然可能触发，因为对x的载入和对y的载入都读取false也是有可能的。x与y由不同的线程写入，所以每种情况从释放到获取的顺序对另一个线程的操作是没有影响的。 但是对于同一个线程来说，使用获取-释放操作可以在松散操作之中施加顺序。 12345678910111213141516171819202122232425262728293031323334#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x_then_y()&#123; x.store(true, std::memory_order_relaxed); y.store(true, std::memory_order_release);&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_acquire)); if(x.load(std::memory_order_relaxed)) ++ z;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x_then_y); std::thread b(read_y_then_x); a.join(); b.join(); assert(z.load() != 0); return 0;&#125; 因为存储使用memory_order_release并且载入使用memory_order_acquire，存储与载入同步。对x的存储发生在y的存储之前，因为它们在同一个线程之中。因为对y的存储与对y的载入同步，对x的载入必然读到true，所以断言并不会触发。配合使用release和acquire可以达到跨线程同步的功能，如下代码所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;int&gt; data[5];std::atomic&lt;bool&gt; sync1(false), sync2(false);void thread_1()&#123; data[0].store(42, std::memory_order_relaxed); data[1].store(97, std::memory_order_relaxed); data[2].store(17, std::memory_order_relaxed); data[3].store(1, std::memory_order_relaxed); data[4].store(2, std::memory_order_relaxed); sync1.store(true, std::memory_order_release);&#125;void thread_2()&#123; while(!sync1.load(std::memory_order_acquire)) ; sync2.store(true, std::memory_order_release);&#125;void thread_3()&#123; while(!sync2.load(std::memory_order_acquire)); assert(data[0].load(std::memory_order_relaxed) == 42); assert(data[1].load(std::memory_order_relaxed) == 97); assert(data[2].load(std::memory_order_relaxed) == 17); assert(data[3].load(std::memory_order_relaxed) == 1); assert(data[4].load(std::memory_order_relaxed) == 2);&#125;int main()&#123; std::thread a(thread_1); std::thread b(thread_2); std::thread c(thread_3); a.join(); b.join(); c.join(); return 0;&#125; 获取释放顺序与MEMORY_ORDER_CONSUME的数据依赖通过在载入上使用memory_order_consume以及在之前的存储上使用memory_order_release，你可以确保所指向的数据得到正确的同步，并且无需再其他非依赖的数据上强制任何同步需求。以下代码展示了这种用途: 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;#include &lt;string&gt;#include &lt;unistd.h&gt;struct X&#123; int i; std::string s;&#125;;std::atomic&lt;X*&gt; p;std::atomic&lt;int&gt; a;void create_x()&#123; X* x = new X; x-&gt;i = 42; x-&gt;s = "hello world"; a.store(99, std::memory_order_relaxed); // 因为这里依赖了x，所以这一句代码执行时保证了x已经初始化完毕，并且已经完成赋值。 // 要点，有依赖关系的都已赋值完毕 p.store(x, std::memory_order_release);&#125;void use_x()&#123; X * x; while(!(x=p.load(std::memory_order_consume))) sleep(1); assert(x-&gt;i == 42); assert(x-&gt;s == "hello world"); // 可能断言出错 assert(a.load(std::memory_order_relaxed) == 99);&#125;int main()&#123; std::thread t1(create_x); std::thread t2(use_x); t1.join(); t2.join();&#125; 上述代码中的前两个断言不会出错，因为p的载入带有对那些通过变量x的表达式的依赖。另一方面，在a的值上的断言或许会被触发。此操作并不依赖从p载入的值，因而对读到的值就没有保证。 内存屏障内存屏障分为写内存屏障和读内存屏障。写内存屏障保证所有在屏障之前的写入操作都会在屏障之后的写入操作之前完成，而读内存屏障确保所有屏障之前的读取操作都会在屏障之后的读取操作前执行。内存屏障使得特定的操作无法穿越。以下代码演示了内存屏障的用法。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;#include &lt;string&gt;#include &lt;unistd.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x_then_y()&#123; x.store(true, std::memory_order_relaxed); // 写内存屏障 std::atomic_thread_fence(std::memory_order_release); y.store(true, std::memory_order_release);&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_acquire)); // 读内存屏障 std::atomic_thread_fence(std::memory_order_acquire); if(x.load(std::memory_order_relaxed)) ++ z;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x_then_y); std::thread b(read_y_then_x); a.join(); b.join(); assert(z.load() != 0);&#125; 释放屏障与获取屏障同步，因为线程b中从y载入在线程a中存储的值，这意味着线程a对x的存储发生在线程b从x的load之前，所以读取的值一定为true，断言永远不会触发。 参考: 《 C++并发编程实战 》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo EPollPoller]]></title>
    <url>%2F2017%2F06%2F11%2Fmuduo-EPollPoller%2F</url>
    <content type="text"><![CDATA[默认使用什么io复用模型？在Poller的接口类中定义了一个static函数，如下所示： 1static Poller* newDefaultPoller(EventLoop* loop); 其实现是在DefaultPoller.cc文件之中，如下所示：1234567891011Poller* Poller::newDefaultPoller(EventLoop* loop)&#123; if (::getenv("MUDUO_USE_POLL")) &#123; return new PollPoller(loop); &#125; else &#123; return new EPollPoller(loop); &#125;&#125; 可见除非定义了MUDUO_USE_POLL环境变量，否则muduo会使用epoll作为io复用的方式。 poll因为epoll返回的io事件对应的结构体 epoll_event中，有一个data成员可以记录相关信息，可以方便我们找到对应的Channel，因而epoll的实现较poll比较更为简单。 1234567typedef union epoll_data&#123; void* ptr; int fd; uint32_t u32; uint64_t u64;&#125;epoll_data_t; 12345678910111213141516171819202122232425262728293031323334Timestamp EPollPoller::poll(int timeoutMs, ChannelList* activeChannels)&#123; LOG_TRACE &lt;&lt; "fd total count " &lt;&lt; channels_.size(); int numEvents = ::epoll_wait(epollfd_, &amp;*events_.begin(), static_cast&lt;int&gt;(events_.size()), timeoutMs); int savedErrno = errno; Timestamp now(Timestamp::now()); if (numEvents &gt; 0) &#123; LOG_TRACE &lt;&lt; numEvents &lt;&lt; " events happended"; fillActiveChannels(numEvents, activeChannels); if (implicit_cast&lt;size_t&gt;(numEvents) == events_.size()) &#123; events_.resize(events_.size()*2); &#125; &#125; else if (numEvents == 0) &#123; LOG_TRACE &lt;&lt; "nothing happended"; &#125; else &#123; // error happens, log uncommon ones if (savedErrno != EINTR) &#123; errno = savedErrno; LOG_SYSERR &lt;&lt; "EPollPoller::poll()"; &#125; &#125; return now;&#125; 拿到epoll返回的事件列表之后，就可以调用fillActiveChannels来将当前active的Channel填充进入EventLoop之中的activeChannels之中。 123456789101112131415161718void EPollPoller::fillActiveChannels(int numEvents, ChannelList* activeChannels) const&#123; assert(implicit_cast&lt;size_t&gt;(numEvents) &lt;= events_.size()); for (int i = 0; i &lt; numEvents; ++i) &#123; Channel* channel = static_cast&lt;Channel*&gt;(events_[i].data.ptr);#ifndef NDEBUG int fd = channel-&gt;fd(); ChannelMap::const_iterator it = channels_.find(fd); assert(it != channels_.end()); assert(it-&gt;second == channel);#endif // set revents channel-&gt;set_revents(events_[i].events); activeChannels-&gt;push_back(channel); &#125;&#125; update Channel在Poller中使用std::map&lt;int, Channel*&gt; 来存放fd和对应channel之间的对应关系。需要保证channel和fd的一一对应，不能存在一个fd由两个不同的channel来管理。 12345678910111213141516171819202122232425262728293031323334353637383940414243void EPollPoller::updateChannel(Channel* channel)&#123; Poller::assertInLoopThread(); const int index = channel-&gt;index(); LOG_TRACE &lt;&lt; "fd = " &lt;&lt; channel-&gt;fd() &lt;&lt; " events = " &lt;&lt; channel-&gt;events() &lt;&lt; " index = " &lt;&lt; index; if (index == kNew || index == kDeleted) &#123; // a new one, add with EPOLL_CTL_ADD int fd = channel-&gt;fd(); if (index == kNew) &#123; assert(channels_.find(fd) == channels_.end()); channels_[fd] = channel; &#125; else // index == kDeleted &#123; assert(channels_.find(fd) != channels_.end()); assert(channels_[fd] == channel); &#125; channel-&gt;set_index(kAdded); update(EPOLL_CTL_ADD, channel); &#125; else &#123; // update existing one with EPOLL_CTL_MOD/DEL int fd = channel-&gt;fd(); (void)fd; assert(channels_.find(fd) != channels_.end()); assert(channels_[fd] == channel); assert(index == kAdded); if (channel-&gt;isNoneEvent()) &#123; update(EPOLL_CTL_DEL, channel); channel-&gt;set_index(kDeleted); &#125; else &#123; update(EPOLL_CTL_MOD, channel); &#125; &#125;&#125; Channel默认的index被设为-1，在epoll之中，index被用作标明类别，有以下3种类型，故而新创建的Channel其index代表新增的Channel。 123456namespace&#123;const int kNew = -1;const int kAdded = 1;const int kDeleted = 2;&#125; updateChannel会根据Channel的revent来调用update方法。注意到对于没有关注任何io事件的Channel，EPollPoller采取的方式是将该channel对应的fd直接从epoll之中删除。 123456789101112131415161718192021void EPollPoller::update(int operation, Channel* channel)&#123; struct epoll_event event; bzero(&amp;event, sizeof event); event.events = channel-&gt;events(); event.data.ptr = channel; int fd = channel-&gt;fd(); LOG_TRACE &lt;&lt; "epoll_ctl op = " &lt;&lt; operationToString(operation) &lt;&lt; " fd = " &lt;&lt; fd &lt;&lt; " event = &#123; " &lt;&lt; channel-&gt;eventsToString() &lt;&lt; " &#125;"; if (::epoll_ctl(epollfd_, operation, fd, &amp;event) &lt; 0) &#123; if (operation == EPOLL_CTL_DEL) &#123; LOG_SYSERR &lt;&lt; "epoll_ctl op =" &lt;&lt; operationToString(operation) &lt;&lt; " fd =" &lt;&lt; fd; &#125; else &#123; LOG_SYSFATAL &lt;&lt; "epoll_ctl op =" &lt;&lt; operationToString(operation) &lt;&lt; " fd =" &lt;&lt; fd; &#125; &#125;&#125; 在update中，对于delete操作进行了区分处理，它容忍delete出错，但是对于modify和add出错，程序会fatal。 removeChannelremoveChannel将Channel对应的fd从epoll中删除，并且Channel也从channels_之中删除了。123456789101112131415161718192021void EPollPoller::removeChannel(Channel* channel)&#123; Poller::assertInLoopThread(); int fd = channel-&gt;fd(); LOG_TRACE &lt;&lt; "fd = " &lt;&lt; fd; assert(channels_.find(fd) != channels_.end()); assert(channels_[fd] == channel); assert(channel-&gt;isNoneEvent()); int index = channel-&gt;index(); assert(index == kAdded || index == kDeleted); size_t n = channels_.erase(fd); (void)n; assert(n == 1); if (index == kAdded) &#123; update(EPOLL_CTL_DEL, channel); &#125; channel-&gt;set_index(kNew);&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Connector]]></title>
    <url>%2F2017%2F06%2F11%2Fmuduo-Connector%2F</url>
    <content type="text"><![CDATA[怎么判断连接成功了？12345678910111213141516171819202122232425262728293031323334353637383940void Connector::connect()&#123; int sockfd = sockets::createNonblockingOrDie(serverAddr_.family()); int ret = sockets::connect(sockfd, serverAddr_.getSockAddr()); int savedErrno = (ret == 0) ? 0 : errno; switch (savedErrno) &#123; case 0: case EINPROGRESS: case EINTR: case EISCONN: connecting(sockfd); break; case EAGAIN: case EADDRINUSE: case EADDRNOTAVAIL: case ECONNREFUSED: case ENETUNREACH: retry(sockfd); break; case EACCES: case EPERM: case EAFNOSUPPORT: case EALREADY: case EBADF: case EFAULT: case ENOTSOCK: LOG_SYSERR &lt;&lt; "connect error in Connector::startInLoop " &lt;&lt; savedErrno; sockets::close(sockfd); break; default: LOG_SYSERR &lt;&lt; "Unexpected error in Connector::startInLoop " &lt;&lt; savedErrno; sockets::close(sockfd); // connectErrorCallback_(); break; &#125;&#125; 可见，对于非阻塞io，如果connect之后的返回值为0，或者errno设置为EINTR, EINPROGRESS, EISCONN, 那么代表连接成功或者正在连接的过程之中。 如果errno为EAGIN，EADDRINUSE，EADDRNOTAVAIL，ECONNREFUSED，ENETURNREACH, 那么表示连接失败。在linux tcp编程之中，对于连接失败的情况，可以移植的解决方式是重新创建一个socket fd，再次尝试连接。对于EACCES，EPERM，EAFNOSUPPORT，EALREADY，EBADF，EFAULT，ENOTSOCK的情况，表示不可恢复的连接失败，直接停止连接，对于其他未知的情况也做此处理。 现在，怎么知道连接成功了呢？以connect返回的sockfd创建一个channel，关注其可写事件。若channel可写，并且尝试使用getsockopt(sockfd, SOL_SOCKET, SO_ERROR, &amp;optval, &amp;optlen)返回的errorCode为0，并且不是自连接，那么说明连接成功，可以将这个sockfd通过connectionCallback通知TcpClient。当然，如果调用的是ErrorCallback，那么close返回的fd，并且进行重试。 1234567891011121314151617181920212223242526272829303132333435363738void Connector::handleWrite()&#123; LOG_TRACE &lt;&lt; "Connector::handleWrite " &lt;&lt; state_; if (state_ == kConnecting) &#123; int sockfd = removeAndResetChannel(); int err = sockets::getSocketError(sockfd); if (err) &#123; LOG_WARN &lt;&lt; "Connector::handleWrite - SO_ERROR = " &lt;&lt; err &lt;&lt; " " &lt;&lt; strerror_tl(err); retry(sockfd); &#125; else if (sockets::isSelfConnect(sockfd)) &#123; LOG_WARN &lt;&lt; "Connector::handleWrite - Self connect"; retry(sockfd); &#125; else &#123; setState(kConnected); if (connect_) &#123; newConnectionCallback_(sockfd); &#125; else &#123; sockets::close(sockfd); &#125; &#125; &#125; else &#123; // what happened? assert(state_ == kDisconnected); &#125;&#125; 12345678910111213141516171819202122// check if self connectionbool sockets::isSelfConnect(int sockfd)&#123; struct sockaddr_in6 localaddr = getLocalAddr(sockfd); struct sockaddr_in6 peeraddr = getPeerAddr(sockfd); if (localaddr.sin6_family == AF_INET) &#123; const struct sockaddr_in* laddr4 = reinterpret_cast&lt;struct sockaddr_in*&gt;(&amp;localaddr); const struct sockaddr_in* raddr4 = reinterpret_cast&lt;struct sockaddr_in*&gt;(&amp;peeraddr); return laddr4-&gt;sin_port == raddr4-&gt;sin_port &amp;&amp; laddr4-&gt;sin_addr.s_addr == raddr4-&gt;sin_addr.s_addr; &#125; else if (localaddr.sin6_family == AF_INET6) &#123; return localaddr.sin6_port == peeraddr.sin6_port &amp;&amp; memcmp(&amp;localaddr.sin6_addr, &amp;peeraddr.sin6_addr, sizeof localaddr.sin6_addr) == 0; &#125; else &#123; return false; &#125;&#125; 怎么实现超时重连？对于retry的处理使用了Connector的retry方法，他会设置超时回调，回调的时间间隔设置为从500ms~30s, 每次重新retry会将间隔的时间加倍，当然时间间隔不可超过30s。 1234567891011121314151617void Connector::retry(int sockfd)&#123; sockets::close(sockfd); setState(kDisconnected); if (connect_) &#123; LOG_INFO &lt;&lt; "Connector::retry - Retry connecting to " &lt;&lt; serverAddr_.toIpPort() &lt;&lt; " in " &lt;&lt; retryDelayMs_ &lt;&lt; " milliseconds. "; loop_-&gt;runAfter(retryDelayMs_/1000.0, std::bind(&amp;Connector::startInLoop, shared_from_this())); retryDelayMs_ = std::min(retryDelayMs_ * 2, kMaxRetryDelayMs); &#125; else &#123; LOG_DEBUG &lt;&lt; "do not connect"; &#125;&#125; 对于stop的处理如果要停止连接，那么首先设置connect_为false，表示不需要建立连接了，这样若handleWrite之中返回了正常的sockfd，那么我也不要通过这个sockfd创建一个连接，而是直接将其close。并且因为connect_设置设置为false，后续进行retry的时候也不会尝试重新连接的。 紧接着的是对stopInLoop的调用，这里对正在处于连接状态的channel进行了reset处理，并且将没有确定连接的sockfd关闭。]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的可变长参数模板]]></title>
    <url>%2F2017%2F06%2F10%2FC-%E4%B8%AD%E7%9A%84%E5%8F%AF%E5%8F%98%E9%95%BF%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[C++ 中的可变长参数基本格式在C++中，可变长参数模板可以用来应对未知长度函数参数的问题。其基本格式如下所示： 123456template&lt;typename ...Args&gt;void g(Args ... args)&#123; cout &lt;&lt; sizeof ...(Args) &lt;&lt; endl; // 类型参数的数目 cout &lt;&lt; sizeof ...(args) &lt;&lt; endl; // 函数参数的数目&#125; 基本用法可变参数函数通常是递归的，第一步调用处理包中的第一个实参，然后用剩余的实参来调用自身。如下的print示例程序就演示了这种用法。123456789101112131415161718192021222324#include &lt;vector&gt;#include &lt;cstring&gt;using namespace std;// 递归调用的终点template&lt;typename T&gt;ostream&amp; print(ostream&amp; os, const T&amp; t)&#123; return os &lt;&lt; t;&#125;template&lt;typename T, typename... Args&gt;ostream&amp; print(ostream&amp; os, const T&amp; t, const Args&amp;... rest)&#123; os &lt;&lt; t &lt;&lt; ", "; // 递归用剩余参数进行调用 return print(os, rest...);&#125;int main()&#123; print(cout, 1, 2.0, false);&#125; 递归会执行如下序列： print(cout, 1, 2.0, false) print(cout, 2.0, false) print(cout, false) 当定义可变参数版本的print的时候，非可变参数版本的声明必须在作用域中。否则，可变参数版本会无限递归。 包扩展可以利用包扩展机制，对可变长模板参数中的每一个参数进行相同的调用。如下所示代码演示了对输入的每个参数都调用了函数no_operation。 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;atomic&gt;#include &lt;vector&gt;#include &lt;cstring&gt;using namespace std;// 递归调用的终点template&lt;typename T&gt;ostream&amp; print(ostream&amp; os, const T&amp; t)&#123; return os &lt;&lt; t;&#125;template&lt;typename T&gt;T no_operation(const T&amp; val)&#123; return val;&#125;template&lt;typename T, typename... Args&gt;ostream&amp; print(ostream&amp; os, const T&amp; t, const Args&amp;... rest)&#123; os &lt;&lt; t &lt;&lt; ", "; // 递归用剩余参数进行调用 // 对所有的参数统一调用no_operation return print(os, no_operation(rest)...);&#125;int main()&#123; // 实际调用no_operation的次数为3，和输入的参数的个数一致 print(cout, 1, 2.0, false);&#125; 转发参数包借助std::forward，可以安全的将输入的可变长参数转发给其他函数，这样vector通过emplace_back就在容器内部直接通过输入的参数构造需要插入的对象。 最简单的例子是make_unique，如下所示： 12345template&lt;typename T, typename... Args&gt;std::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp; ...args)&#123; return std::unique_ptr&lt;T&gt;(new T(std::forward&lt;Args&gt;(args)...));&#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb filter_block]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-filter-block%2F</url>
    <content type="text"><![CDATA[leveldb filter_block解析filter meta block 文件格式首先借助leveldb文档leveldb File format可以确定filter meta block内部的格式如下所示： 1234567891011121314[filter 0][filter 1][filter 2][filter 3][filter 4]...[filter N-1][offset of filter 0] : 4 bytes[offset of filter 1] : 4 bytes[offset of filter 2] : 4 bytes...[offset of filter N-1] : 4 bytes[offset of beginning of offset array] : 4 byteslg(base) : 1 byte 借助源码和文档，我对filter meta block的格式有了深刻的理解。每一个filter对应负责一个block offset范围内的key的组织。对于第i个filter，它所管理的key在文件中的偏移范围是[i * base ... (i+1) * base - 1]。在leveldb中，base默认被设置为2KB，也就是说每2KB长度的偏移位置对应一个独立的filter。 每一个key借助hash函数(maybe, 看filter策略具体实现)产生一个滤值，一个filter可能会有多个这样的滤值。所有filter的滤值最后从前到后依次保存在filter meta block之中。然后再存放每一个filter对应滤值的偏移位置。根据当前filter和下一个filter的offset值就可以确定当前filter对应滤值在filter meta block中偏移值的范围。紧接着存放最后一个filter对应滤值offset范围的下界，通过它我们还能知道整个块中filter的数量。filter meta block的最后存放的是log(base)的值，由它我们能知道每个filter所能管理的文件偏移大小限制。 附上一张网上找到的图 FilterBlockBuilder12345678910111213141516171819202122232425262728293031// A FilterBlockBuilder is used to construct all of the filters for a// particular Table. It generates a single string which is stored as// a special block in the Table.//// The sequence of calls to FilterBlockBuilder must match the regexp:// (StartBlock AddKey*)* Finishclass FilterBlockBuilder &#123; public: explicit FilterBlockBuilder(const FilterPolicy*); void StartBlock(uint64_t block_offset); void AddKey(const Slice&amp; key); Slice Finish(); private: void GenerateFilter(); const FilterPolicy* policy_; // 过滤策略 std::string keys_; // 存放所有的key std::vector&lt;size_t&gt; start_; // 存放每一个key在keys_的下标范围 // 存放最终的结果 std::string result_; // Filter data computed so far // 用于记录每个filter产生的滤值的临时容器 std::vector&lt;Slice&gt; tmp_keys_; // policy_-&gt;CreateFilter() argument // 记录每个filter的offset开始位置 std::vector&lt;uint32_t&gt; filter_offsets_; // No copying allowed FilterBlockBuilder(const FilterBlockBuilder&amp;); void operator=(const FilterBlockBuilder&amp;);&#125;; FilterBlockBuilder对象在构造的时候需要指定FilterPolicy，它要用其来生成滤值。在对偏移为block_offset的文件进行操作前，首先需要调用StartBlock。此方法确定输入的偏移值对应哪一个filter，并且将filter_index更小的filter的滤值写入result_。 123456789void FilterBlockBuilder::StartBlock(uint64_t block_offset) &#123; // kFilterBase的大小为2048 uint64_t filter_index = (block_offset / kFilterBase); assert(filter_index &gt;= filter_offsets_.size()); while (filter_index &gt; filter_offsets_.size()) &#123; // 若filter_index 的值更大，将之前的filter对应的滤值加入result_ GenerateFilter(); &#125;&#125; 请注意，要按照偏移的先后顺序调用StartBlock和AddKey方法，这样才能保证filter meta block内部顺序和实际偏移一致。 GenerateFilter方法将当前filter所管理的key按照输入的Filter策略转换为滤值，并且记录当前filter对应的滤值在block中偏移的开始位置。123456789101112131415161718192021222324252627282930313233// 产生新的filtervoid FilterBlockBuilder::GenerateFilter() &#123; // 对应key的数目 const size_t num_keys = start_.size(); if (num_keys == 0) &#123; // Fast path if there are no keys for this filter // 记录此filter的偏移位置 filter_offsets_.push_back(result_.size()); return; &#125; // Make list of keys from flattened key structure start_.push_back(keys_.size()); // Simplify length computation tmp_keys_.resize(num_keys); for (size_t i = 0; i &lt; num_keys; i++) &#123; // 每个key的开头位置 const char* base = keys_.data() + start_[i]; // 每个key的长度 size_t length = start_[i+1] - start_[i]; tmp_keys_[i] = Slice(base, length); &#125; // Generate filter for current set of keys and append to result_. // 记录此filter的偏移起始位置 filter_offsets_.push_back(result_.size()); // 创建filter，输入key对应的数组，数组大小，存放结果的result // result存放key对应的hash值 policy_-&gt;CreateFilter(&amp;tmp_keys_[0], static_cast&lt;int&gt;(num_keys), &amp;result_); tmp_keys_.clear(); keys_.clear(); start_.clear();&#125; 在加入新的key时，会在start_中记录新的key在keys_中的开始位置，然后将其append到keys_之中，这样之后借助keys_和start_t就能重构所有输入的key。12345void FilterBlockBuilder::AddKey(const Slice&amp; key) &#123; Slice k = key; start_.push_back(keys_.size()); keys_.append(k.data(), k.size());&#125; Finish函数的操作很容易理解，他首先记录所有filter对应滤值的offset范围，注意要补充记录最后一个filter的滤值offset下界。当然也要按照文件格式记录log(base)值。 12345678910111213141516171819Slice FilterBlockBuilder::Finish() &#123; if (!start_.empty()) &#123; GenerateFilter(); &#125; // Append array of per-filter offsets // 这是滤值数组的结束位置offset，将这个值记住 const uint32_t array_offset = result_.size(); // 存放filter对应的offset开头位置 for (size_t i = 0; i &lt; filter_offsets_.size(); i++) &#123; PutFixed32(&amp;result_, filter_offsets_[i]); &#125; // 存放最后一个filter offset的下界 PutFixed32(&amp;result_, array_offset); // 存放kFilterBaseLg的大小 // kFilterBaseLg = log(base) result_.push_back(kFilterBaseLg); // Save encoding parameter in result return Slice(result_);&#125; FilterBlockReader相比FilterBlockBuilder，FilterBLockReader可以理解为它的逆过程。 123456789101112131415class FilterBlockReader &#123; public: // REQUIRES: "contents" and *policy must stay live while *this is live. FilterBlockReader(const FilterPolicy* policy, const Slice&amp; contents); bool KeyMayMatch(uint64_t block_offset, const Slice&amp; key); private: const FilterPolicy* policy_; const char* data_; // Pointer to filter data (at block-start) // 指向offset数组靠近block尾部的开始处 const char* offset_; // Pointer to beginning of offset array (at block-end) // filter的数目 size_t num_; // Number of entries in offset array size_t base_lg_; // Encoding parameter (see kFilterBaseLg in .cc file)&#125;; 在构造函数中，Reader根据文件格式获取base的log值，filter的数目，第一个filter的偏移的开始位置。 123456789101112131415161718192021FilterBlockReader::FilterBlockReader(const FilterPolicy* policy, const Slice&amp; contents) : policy_(policy), data_(NULL), offset_(NULL), num_(0), base_lg_(0) &#123; size_t n = contents.size(); // size not enough to hold start and offset array if (n &lt; 5) return; // 1 byte for base_lg_ and 4 for start of offset array // 取出base_lg_的值 base_lg_ = contents[n-1]; uint32_t last_word = DecodeFixed32(contents.data() + n - 5); // 滤值数组的最后元素的末尾位置不可能超出n-5，否则无法容纳 if (last_word &gt; n - 5) return; data_ = contents.data(); // 指向最后一个filter滤值的offset下界位置 offset_ = data_ + last_word; // filter的数量 num_ = (n - 5 - last_word) / 4;&#125; 至于对key的匹配判断，对于输入的block_offset，计算出它属于哪一个filter。然后取出此filter的所有滤值，和key按照filter策略计算得到的滤纸进行匹配，相同说明可能匹配，否则不能匹配。对于计算得到的filter的index值大于block中filter的数量的情况，也被认为是匹配，即错误被当做潜在的匹配。 123456789101112131415161718bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice&amp; key) &#123; uint64_t index = block_offset &gt;&gt; base_lg_; if (index &lt; num_) &#123; // 滤值开始位置对应的偏移 uint32_t start = DecodeFixed32(offset_ + index*4); // 滤值结束位置对应的偏移 // 实质上是下一个filter的offset开始位置 uint32_t limit = DecodeFixed32(offset_ + index*4 + 4); if (start &lt;= limit &amp;&amp; limit &lt;= static_cast&lt;size_t&gt;(offset_ - data_)) &#123; Slice filter = Slice(data_ + start, limit - start); return policy_-&gt;KeyMayMatch(key, filter); &#125; else if (start == limit) &#123; // Empty filters do not match any keys return false; &#125; &#125; return true; // Errors are treated as potential matches&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb File format]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-File-format%2F</url>
    <content type="text"><![CDATA[leveldb File format123456789101112&lt;beginning_of_file&gt;[data block 1][data block 2]...[data block N][meta block 1]...[meta block K][metaindex block][index block][Footer] (fixed size; starts at file_size - sizeof(Footer))&lt;end_of_file&gt; 文件之中包含内部指针。每一个这样的指针被称为BlockHandle，包含下述信息。 12offset: varint64size: varint64 varint的解释可以查看varints。 文件中的键值对按照顺序进行存储，并被分割成为数据块序列。这些数据块在文件中从前到后依次排列。每一个数据块按照block_builder.cc中的代码进行格式化，然后进行可选的压缩。 在数据块之后，我们存储了一串元数据块。支持的meta块类型会在下文描述。未来可能会增加新的meta块类型。每一个meta块也是使用block_builder.cc中的代码进行格式化，然后进行可选的压缩。 一个命名为”metaindex”的块。对于其他的meta块每个块记录一个entry，key是meta块的名称，value是指向对应meta块的BlockHandle。 一个名为”index”的块。这个块对于每个数据块记录一个entry，key是大于对应数据块最后一个key，并且小于紧接着的下一个数据块的第一个key的字符串。value是数据块的BlockHandle。 每个文件的末尾是一个固定长度的footer，包含metaindex和index块的BlockHandle，以及一个魔数。 12345metaindex_handle: char[p]; // Block handle for metaindexindex_handle: char[q]; // Block handle for indexpadding: char[40-p-q];// zeroed bytes to make fixed length // (40==2*BlockHandle::kMaxEncodedLength)magic: fixed64; // == 0xdb4775248b80fb57 (little-endian) “filter” Meta Block若数据库打开时指定了FilterPolicy，每个table会存储一个filter块。”metaindex”块包含一条entry，记录从filter.&lt;N&gt;到filter块的BlockHandle的映射。其中&lt;N&gt;是filter policy的Name()方法返回的字符串。 filter块存储了filters序列，其中filter i包含FilterPolicy::CreateFilter()所有key的输出，这些key在文件中偏移的范围在范围： 1[ i*base ... (i+1)*base-1 ] 当前，”base”是2KB，举例来说，若块x和y在文件中的偏移范围是[0KB .. 2KB-1]，所有x和y的将会调用FilterPolicy::CreateFilter()转换成filter，生成的filter是第一个filter block。 filter块的格式如下所示： 1234567891011121314[filter 0][filter 1][filter 2]...[filter N-1][offset of filter 0] : 4 bytes[offset of filter 1] : 4 bytes[offset of filter 2] : 4 bytes...[offset of filter N-1] : 4 bytes[offset of beginning of offset array] : 4 byteslg(base) : 1 byte filter块末尾的offset array 允许从data block偏移到对应filter的有效映射。 “Stats” Meta Block这一meta块包含一串统计信息。key是统计名称，value是统计值。 TODO(postrelease): record following stats. 123456data sizeindex sizekey size (uncompressed)value size (uncompressed)number of entriesnumber of data blocks]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb Log format]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-Log-format%2F</url>
    <content type="text"><![CDATA[leveldb Log format日志文件内容是一系列32KB大小的block序列。唯一的例外是文件的末尾可能包含一个不完整的block。 每一个block包含一个记录序列： 123456block := record* trailer? record := checksum: uint32 // crc32c of type and data[] ; little-endian length: uint16 // little-endian type: uint8 // One of FULL, FIRST, MIDDLE, LAST data: uint8[length] 一条记录不会在一个block的最后6 byte处开始（因为放不下）。所有剩余的bytes组成trailer，需要包含全0的bytes，并且必须被读者跳过。 例外：若当前block恰好剩余7bytes，增加一个新的非0长度的record，写者必须将第一条记录（包含长度为0的用户数据）填充之前block剩余的7bytes，将用户数据写入之后的block之中。 在未来可能会增加新的类型。 一些读者可能会跳过不理解的记录类型，其他的可能会报告他跳过了一些值。 1234FULL == 1FIRST == 2MIDDLE == 3LAST == 4 FULL record包含完整的用户记录。 FIRST, MIDDLE, LAST 用于标志分片的用户记录（一般由于block边界）。FIRST是用户记录第一个分片的类型，LAST是用户记录最后一个分片的类型，MIDDLE是所有的用户记录中间分片的类型。 例子： 一个用户记录序列： 123A: length 1000B: length 97270C: length 8000 A 会是第一个block的FULL记录。 B 会被分为3个分段：第一段占据第一块剩余部分，第二段占据第二个block的全部，第三段占据第三个block的前面的绝大部分。第三个block会剩余6bytes空间，会被空余当做trailer。 C 会在第4个block中存放一条FULL记录。 Some benefits over the recordio format: 重新同步时不需要任何启发式查找 - 只需要到下一个block边界并进行扫描。 如果有错误，跳过去处理下一个block。附加的好处是，当一个log文件的部分内容被嵌入另一个log文件作为record时，我们不会陷入疑惑。 在大致的边界上进行分割（例如，mapreduce）非常简单：找到下一个块的边界，跳过record直到我们找到一条FULL或者FIRST类型的记录。 对于大的records，我们不需要额外的缓存。 Some downside compared to recordio format: 不会对小的record进行打包。可以通过增加新的记录类型来解决。所以这是当前实现的缺陷，不是这一format的缺点。 没有压缩。 这个也可以通过增加新的记录类型来解决。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb 实现文档]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-%E5%AE%9E%E7%8E%B0%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[leveldb 实现文档Filesleveldb的实现和一个单点的Bigtable tablet(section 5.2)相似。但是内部文件的组成有所不同，下面会进行解释。 每一个数据库都是存储在目录下一系列的文件集合构成。有以下几种不同的文件类型： Log files一个log文件存储了最近更新的序列。每一个更新记录都被追加到当前的log文件中。当log文件达到预先设置的大小（可能是默认值4MB），它会被转换为一个sorted table，并且会创建一个新的log文件记录未来的更新。 当前log文件的副本被保存在内存中(memtable)。每次读都会检索这一副本，所以读操作能反映所有已经记录日志的更新。 Sorted tables一个sorted table（*.ldb）保存了按照key排序的entry序列。每一个entry可能是key和对应的value，或者key和对应的删除标记。（在旧版本的sorted tables中，删除标记用于覆盖过期的value）。 sorted tables组成的集合被组织成为level序列。从一个log文件中生成的sorted table被放置在一个特殊的 young level之中（也被称为level-0）。当 young files 的数目超出阈值（当前设置为4），所有的 young files 和key区间重叠的level-1文件合并生成一系列新的level-1文件（我们创建的新的level-1文件的大小是2MB）。 young level 文件可能包含重叠区间的key。但是其他level的文件都有唯一的没有重叠的key区间范围。对于 &gt;= 1的level值L，当level-L级别的文件大小超过（10^L）MB时（例如，level-1达到10MB, level-2达到100MB，···），一个level-L文件和所有key区间重叠的level-(L+1)文件合并为level-(L+1)的一系列新文件。这些合并操作使用块读取和写入操作，将新的更新从young level 逐步迁移到最大的level，减少了昂贵的寻道操作。 Manifset一个MANIFEST文件列出了组成每个level的sorted tables文件集合，对应key的范围，其他重要的元数据。一个新的MANIFEST文件（会在文件名中植入新的number）会在数据库重新打开时创建。MANIFEST是日志文件，服务状态的更新（新增或者移除文件）会追加到这一log文件。 CurrentCURRENT是一个简单的文本文件，其中包含了最新的MANIFEST文件的名字。 Info logs日志信息被写入命名为LOG或者Log.old的文件。 Others其他文件各种用途的文件，用途如名称所述，例如LOCK， *.dbtmp。 level0当log文件增长到某个值（默认是1MB）时： 创建新的memtable和log文件，将未来的更新写入新的文件。 在后台： 将之前memtable的内容写入到sstable 丢弃memtable 删除旧的log和memtable文件，将新的sstable文件加入young level。 Compactions当level L的文件大小超出限制之后，我们会在后台线程之中进行压缩合并。合并操作选取level-L中的一个文件和下一个level-(L+1)中key区间重叠的所有文件进行。注意到，如果level-L文件key区间只和level-(L+1)文件部分重叠，那么level-(L+1)文件会作为合并操作的输入，并且在合并操作完成之后被丢弃。例外：因为level-0文件比较特殊（level-0文件可能彼此之间互相重叠），我们对于从level-0到level-1的合并操作特殊对待：一个level-0级别的合并操作会选取所有key区间重叠的level-0文件进行，因而选取的level-0文件数量可能超过1。 一个合并压缩操作合并选取的文件内容，产生一个level-(L+1)序列的文件。在当前输出文件大小到达目标大小（2MB），我们会创建新的level-(L+1)文件。我们在当前输出文件的大小增长到和超过10个level-(L+2)级别的文件重叠时，也会产生新的输出文件。最后一条规则确保之后对于level-(L+1)文件的合并操作不会涉及到level-(L+2)中的过多的文件。 旧的文件会被丢弃，新的文件会被记录以更新当前服务状态。 对于一个特定level来说，合并操作会在key区间轮转进行。更详细地说，对于每一个level L，我们记录上一次level-L合并操作最后的key，下次level L的合并操作将会选取第一个大于这个key的文件开始（如果没有这样的文件，就从key区间的开头位置开始）。 合并操作会丢弃覆盖的值。若更高level的文件key的区间没有包含标记为删除的key，也会将其删除。 TimingLevel-0的合并操作会读取至多4个1MB大小的level-0文件，在最坏的情况下会读取所有的level-1文件（10MB）。因此，我们会读14MB，写14MB。 除了特殊的level-0合并操作，我们会从level-L选取一个2MB的文件。在最坏的情况下，这一文件会和level-(L+1)的中12个level-L文件大小的，level-(L+1)文件key区间重合（10因为level-(L+1) 比level-L的文件大小大10倍，剩余2因为level-L的文件大小和level-L+1的文件大小通常不对齐而增加的界限)。所以合并操作会读取26MB，写入26MB。假设硬盘的IO速度为100MB/s(现代设备的速度)，最坏的合并操作需要大约0.5秒。 若我们限制后台写入的速度，比如说全速100MB/s的10%，一个合并操作可能花费5秒。如果用户写入的速度是10MB/s，我们需要创建很多level-0文件（~50个，用于存放5*10MB）。由于每次读操作会合并过多的文件，这会显著增加读的开销。 解决方式： 为了减小这一问题，当level-0文件数量很大时，我们可能需要增加生成新的log文件的阈值。然而，缺点是这个阈值越大，我们需要更多的内存来存放对应的memtable。 当level-0文件数量上涨时，我们可能需要人为减小写入速度。 减小大幅度merge的开销。可能大多数level-0文件都是未经压缩存放在cache中，我们只需要O(N)复杂度的合并操作。 Number of files不再总是创建2MB的文件，更大level的文件有更大的大小能减小文件总数，虽然以合并操作更加突发为代价。另外，我们能将文件集合存放在不同的路径下。 2001年2月4日，一个在ext3文件系统下的实验演示了对于目录下不同数量，相同大小（100K）文件的打开操作的时间开销： Files in directory Microseconds to open a file 1000 9 10000 10 100000 16 所以对于现代文件系统，分片没有必要？ Recovery 读取CURRENT找到最新提交的MANIFEST文件的名称 读取MANIFEST文件 清除无效文件 我们可以打开所有的sstables文件，但是可能晚点打开会更好… 将log文件转换为新的level-0 sstable文件 将更新新写入新的log文件（以恢复后的序列） Garbage collection of fileDeleteObsoleteFiles()在每次合并和恢复操作的最后会被调用。他会查找database中用到的所有文件，删除不是当前log文件的所有log文件，删除没被任何层引用并且不是有效合并操作输出的所有table文件。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Channel]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Channel%2F</url>
    <content type="text"><![CDATA[实现简介channel一般用于抽象一个fd，包含fd当前关注的事件，出现事件更新需要在poller之中做出更新。poller获取到当前io复用返回的io事件之后，会更新channel之中的revent。在eventloop中会为当前活跃的channel进行事件处理，调用对应revent，io事件的回调函数。整个Channel类的实现非常简单明了。 重点:tie可能出现这种情况，我们设置的回调函数是某个类的成员函数，此类对象使用shared_ptr进行管理。如果在回调函数之中对此shared_ptr进行了reset或者release处理，那么此回调函数就会立即失效，因为类对象被回收了。对于这种特殊情况，可以使用std::weak_ptr&lt;void&gt; tie来存放该shared_ptr的弱引用（使用弱引用是为了避免增加shared_ptr的引用计数，导致对象一直无法得以析构。每次进行事件处理的时候，若之前设置了tie，那么首先tie进行提升，保证回调函数处理期间此shared_ptr管理的对象不会被析构。 tie这一措施是为了TcpConnectionPtr而设计了，如果在某个回调函数之中，reset了此TcpConnectionPtr, 那么TcpConnection的其他回调函数就会失效。所以在处理这些事件期间，需要提升此TcpConnectionPtr的引用计数，阻止TcpConnectionPtr被析构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455void Channel::tie(const std::shared_ptr&lt;void&gt;&amp; obj)&#123; tie_ = obj; tied_ = true;&#125;void Channel::handleEvent(Timestamp receiveTime)&#123; std::shared_ptr&lt;void&gt; guard; if (tied_) &#123; guard = tie_.lock(); if (guard) &#123; handleEventWithGuard(receiveTime); &#125; &#125; else &#123; handleEventWithGuard(receiveTime); &#125;&#125;void Channel::handleEventWithGuard(Timestamp receiveTime)&#123; eventHandling_ = true; LOG_TRACE &lt;&lt; reventsToString(); if ((revents_ &amp; POLLHUP) &amp;&amp; !(revents_ &amp; POLLIN)) &#123; if (logHup_) &#123; LOG_WARN &lt;&lt; "fd = " &lt;&lt; fd_ &lt;&lt; " Channel::handle_event() POLLHUP"; &#125; if (closeCallback_) closeCallback_(); &#125; if (revents_ &amp; POLLNVAL) &#123; LOG_WARN &lt;&lt; "fd = " &lt;&lt; fd_ &lt;&lt; " Channel::handle_event() POLLNVAL"; &#125; if (revents_ &amp; (POLLERR | POLLNVAL)) &#123; if (errorCallback_) errorCallback_(); &#125; if (revents_ &amp; (POLLIN | POLLPRI | POLLRDHUP)) &#123; if (readCallback_) readCallback_(receiveTime); &#125; if (revents_ &amp; POLLOUT) &#123; if (writeCallback_) writeCallback_(); &#125; eventHandling_ = false;&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Buffer]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Buffer%2F</url>
    <content type="text"><![CDATA[实现原理在muduo之中，使用std::vector来存放网络中传输的数据，包括从要发送给对方的数据以及从对方接收的数据。在Buffer之中，预留了 prependable 的缓存，可以在buffer之中加入前缀而无需移动整个buffer。整个buffer分为prependable, readable, writable bytes. Buffer 的布局可以参考下图。 12345678910/// A buffer class modeled after org.jboss.netty.buffer.ChannelBuffer////// @code/// +-------------------+------------------+------------------+/// | prependable bytes | readable bytes | writable bytes |/// | | (CONTENT) | |/// +-------------------+------------------+------------------+/// | | | |/// 0 &lt;= readerIndex &lt;= writerIndex &lt;= size/// @endcode&gt;&gt;&gt; Buffer的作用非常之大，将用户程序从繁琐的Buffer相关读写操作之中解放了出来。 重点在muduo的Buffer之中，对read进行了特殊处理。因为从socket读，会调用read，涉及到一次上下文切换，为了减少系统调用的开销，read的调用次数是越少越好，因而需要尽可能预先分配更大的用户空间缓存。另一方面，如果对于每个连接都分配过多的缓存，那么会造成因为内存容量有限而造成支持的并发连接数目有限的问题。这二者之间存在矛盾。 在muduo之中，使用分配在堆栈上的缓存区域以及readv系统调用，将读取的数据优先存入buffer之中，超过限制才存放在堆栈上分配的缓存之中，最后再统一汇总到buffer之中。离开readFd函数之后，堆栈上分配的读取缓存会被自动回收。具体可以参考以下代码: 123456789101112131415161718192021222324252627282930313233ssize_t Buffer::readFd(int fd, int* savedErrno)&#123; // saved an ioctl()/FIONREAD call to tell how much to read char extrabuf[65536]; struct iovec vec[2]; const size_t writable = writableBytes(); vec[0].iov_base = begin()+writerIndex_; vec[0].iov_len = writable; vec[1].iov_base = extrabuf; vec[1].iov_len = sizeof extrabuf; // when there is enough space in this buffer, don't read into extrabuf. // when extrabuf is used, we read 128k-1 bytes at most. const int iovcnt = (writable &lt; sizeof extrabuf) ? 2 : 1; const ssize_t n = sockets::readv(fd, vec, iovcnt); if (n &lt; 0) &#123; *savedErrno = errno; &#125; else if (implicit_cast&lt;size_t&gt;(n) &lt;= writable) &#123; writerIndex_ += n; &#125; else &#123; writerIndex_ = buffer_.size(); append(extrabuf, n - writable); &#125; // if (n == writable + sizeof extrabuf) // &#123; // goto line_30; // &#125; return n;&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[auto关键字]]></title>
    <url>%2F2017%2F06%2F08%2Fauto%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[5. 优先使用auto而非显示类型声明在C++之中，使用auto关键字声明类型可以将程序员从输入繁琐的类型中解放出来，编译器会自动推导出变量的实际类型。 123456789template&lt;typename It&gt;void dwim(It b, It e)&#123; while(b != e)&#123; typename std::iterator_traits&lt;It&gt;::value_type currValue = *b; ... &#125;&#125; 使用auto关键字 12345678template&lt;typename It&gt;void dwim(It b, It e)&#123; while(b != e)&#123; auto currValue = *b; ... &#125;&#125; 在C++14中，lambda函数的参数都可以使用auto来定义。1234auto derefLess = // C++14 comparison [](const auto&amp; p1, // function for const auto&amp; p2) // values pointed &#123; return *p1 &lt; *p2; &#125;; 使用auto生命类型还可以将我们从类型截断的问题中解放出来：12std::vector&lt;int&gt; arrs;auto size = arrs.size(); 在C++中，unordered_map的key的类型是const类型的，所以即便采取如下方式遍历unordered_map容器，仍然会产生临时对象：1234567std::unordered_map&lt;std::string, int&gt; m; ...for (const std::pair&lt;std::string, int&gt;&amp; p : m)&#123; ... // do something with p&#125; 但是借助auto，我们不仅使声明更加简洁，还避开了此问题：1234567std::unordered_map&lt;std::string, int&gt; m; ...for (const auto&amp; p : m)&#123; ... // do something with p&#125; 6. 当auto推导出非预期类型时应当使用显示的类型初始化在C++中，因为标准不允许返回对bit的引用，所以对于vector&lt;bool&gt;标准库进行了特化处理，其[]运算符返回的是std::vector&lt;bool&gt;::reference类型的临时对象。对临时对象的修改会被其同步到vector中，因而这样使用auto关键字是不合规的。12345Widget w;…auto highPriority = features(w)[5]; // w是不是个高优先级的？…processWidget(w, highPriority); // 配合优先级处理w 在这种情况下，我们只需显示指出highPriority的类型为bool即可规避此问题。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>modern effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++类型推导]]></title>
    <url>%2F2017%2F06%2F08%2FC%2B%2B%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[1. 理解模板类型推导1. expr是T&amp;123456template&lt;typename T&gt;void f(T &amp; param);// 我们声明如下变量int x = 27;const int cx = x;const int&amp; rx = x; 函数调用时，推导出的Param和T的类型如下： 123f(x); // T is int, param's type is int&amp;f(cx); // T is const int, param's type is const int&amp;f(rx); // T is const int, param's type is const int&amp; 需要特别注明的是，通过T&amp;的方式传入数组，数组的大小信息不会丢失。 1234template&lt;typename T&gt;void f(T&amp; param);const int arr[10];f(arr); // T is const int[10], param type is const int(&amp;)[10] 在类型推导期间，数组和函数将退化为指针类型，除非他们是被初始化为引用。 2. expr是const T&amp;123456template&lt;typename T&gt;void f(const T&amp; param);int x = 27;const int cx = x;const int&amp; rx = x; 在进行类型推导的时候，rx的引用性被忽略了。 123f(x); // T is int, param's type is const int&amp;f(cx); // T is int, param's type is const int&amp;f(rx); // T is int, param's type is const int&amp; 3. param是一个指针类型1234567template&lt;typename T&gt;void f(T* param); // param is now a pointerint x = 27;const int* px = &amp;x;f(&amp;x); // T is int, param's type is int *f(px); // T is const int, param's type is const int * 4. param是universial reference1234567891011template&lt;typename T&gt;void f(T&amp;&amp; param); // param is now a universal referenceint x = 27;const int cx = x;const int&amp; rx = x;f(x); // x is lvalue, so T is int&amp;, param's type is also int&amp;f(cx); // cx is lvalue, so T is const int&amp;, param's type is also const int&amp;f(rx); // rx is lvalue, so T is const int&amp;, param's type is also const int&amp;f(27); // 27 is rvalue, so T is int, param's typs is int&amp;&amp; 5. param 既不是指针也不是引用12template&lt;typename T&gt;void f(T param); 当ParamType既不是指针也不是引用的时候，我们按照值传递的方式进行处理。需要举出一个有用的例子：1234template&lt;typename T&gt;void f(T param);const char* const ptr = "hello world\n";f(ptr); // param's type is const char* 2. 理解auto自动类型推导auto 类型对象推导通常和模板类型推导是相同的。例子：123456const char name[] = "zhouyang";auto arr1 = name; // arr1's type is const char*auto&amp; arr2 = name; // arr2's type is const char(&amp;)[9]void someFunc(int, double); // someFunc is a functionauto func1 = someFunc; // func1's type is void(*)(int, double)auto&amp; func2 = someFunc; // func2's type is void(&amp;)(int, double) 唯一的例外是：使用auto和大括号进行初始化时，自动推导为std::initializer_list。并且，对于使用括号进行的初始化，模板类型推导会失败。 3. 理解decltypedecltype 一般情况下总是返回变量名或者表达式的类型而不做任何的修改。123const int i = 0; // decltype(i) is const intbool f(const Widget&amp; w) // decltype(w) is const Widget&amp;Widget W; // decltype(w) is Widget 在C++14中，提供了decltype(auto)的支持，它从初始化式子中推导类型，使用的是decltype的推导规则。123456Widget w;cosnt Widget&amp; cw = w;auto myWidget1 = cw; // myWidget1's type is Widgetdecltype(auto) myWidget2 = cw; // decltype type deduction: // myWidget2's type is const Widget&amp;// 注：可以在模板中使用 特例:12345678910111213#include &lt;iostream&gt;using namespace std;int main()&#123; int temp = 10; decltype((temp)) temp1 = temp; // temp1's type is int&amp; temp1 = 1; cout&lt;&lt; temp &lt;&lt; endl; return 0;&#125;//输出 : 1 4. 了解如何查看推导出的类型可以利用编译器诊断来完成。我们想要知道被推导出的类型，可以首先声明一个类模板，但是不定义它。那么编译器的出错信息会包含推导的类型信息。12template&lt;typename T&gt;class TD; 通过编译器内置的宏定义，可以输出函数类型1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void test_func(int)&#123;#if defined(__GNUC__) cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; endl;#elif defined(_MSC_VER) cout &lt;&lt; __FUNCSIG__ &lt;&lt; endl;#endif&#125;int main()&#123; test_func(10); return 0;&#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>modern effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Acceptor]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Acceptor%2F</url>
    <content type="text"><![CDATA[运行流程Acceptr是muduo之中TcpServer用于接受连接的wrapper类。其中有一个成员acceptChannel_用于接受连接。其句柄是用于接受连接的socket fd。 上述acceptChannel_关注的是可读事件，可读代表有新的连接可以accept了。在关注可读事件之前需要首先开始监听。监听的backlog的限制采用的是Linux所支持的最大值: SOMAXCONN. 特殊处理在接受连接的时候，可能会出现这种问题：描述符用完了，这会导致accpet失败，并且返回ENFILE错误。但是并没有拒绝这一连接，连接仍然会在连接队列之中，这导致了下一次eventLoop中仍然会触发监听描述符的可读事件，这会导致busy loop。 一种比较简单的解决方式是程序遇到这个问题，直接忽略，直到这种情况消失，但是这种解决方式会导致busy waiting。 另一种解决思路是记录除了EAGAIN或者EWOULDBLOCK其他任何错误，告诉用户出现了某种错误，并且停止监听描述符的可读事件，减少CPU的使用。 在libevent中，采用的是如下解决方式。首先打开/dev/null, 保留一个文件描述符，当accept出现ENFILE或者EMFILE错误的时候，关闭/dev/null，然后再次accept，并且close掉accept产生的fd，再次打开/dev/null，这是一种比较优雅的方式来拒绝客户端的连接。 最后一种比较sb的方式是遇到accept的这种错误，直接拒绝并且退出。这种方式比较容易受到Dos攻击。 12345678910111213141516171819202122232425262728293031323334void Acceptor::handleRead()&#123; loop_-&gt;assertInLoopThread(); InetAddress peerAddr; //FIXME loop until no more int connfd = acceptSocket_.accept(&amp;peerAddr); if (connfd &gt;= 0) &#123; // string hostport = peerAddr.toIpPort(); // LOG_TRACE &lt;&lt; "Accepts of " &lt;&lt; hostport; if (newConnectionCallback_) &#123; newConnectionCallback_(connfd, peerAddr); &#125; else &#123; sockets::close(connfd); &#125; &#125; else &#123; LOG_SYSERR &lt;&lt; "in Acceptor::handleRead"; // Read the section named "The special problem of // accept()ing when you can't" in libev's doc. // By Marc Lehmann, author of libev. if (errno == EMFILE) &#123; ::close(idleFd_); idleFd_ = ::accept(acceptSocket_.fd(), NULL, NULL); ::close(idleFd_); idleFd_ = ::open("/dev/null", O_RDONLY | O_CLOEXEC); &#125; &#125;&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>