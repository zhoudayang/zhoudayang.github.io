<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[leveldb File format]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-File-format%2F</url>
    <content type="text"><![CDATA[leveldb File format&lt;beginning_of_file&gt; [data block 1] [data block 2] ... [data block N] [meta block 1] ... [meta block K] [metaindex block] [index block] [Footer] (fixed size; starts at file_size - sizeof(Footer)) &lt;end_of_file&gt; The file contains internal pointers. Each such pointer is calleda BlockHandle and contains the following information: offset: varint64 size: varint64 See varintsfor an explanation of varint64 format. The sequence of key/value pairs in the file are stored in sortedorder and partitioned into a sequence of data blocks. These blockscome one after at the beginning of the file. Each data blockis formatted according to the code in block_builder.cc, and thenoptionally compressed. After the data blocks we store a bunch of meta blocks. Thesupported meta block types are described below. More meta block typesmay be added in the future. Each meta block is again formatted usingblock_builder.cc and then optionally compressed. A “metaindex” block. It contains one entry for every other metablock where the key is the name of the meta block and the value is aBlockHandle pointing to that meta block. An “index” block. This block contains one entry per data block,where the key is a string &gt;= last key in that data block and beforethe first key in the successive data block. The value is theBlockHandle for the data block. At the very end of the file is a fixed length footer that containsthe BlockHandle of the metaindex and index blocks as well as a magic number. metaindex_handle: char[p]; // Block handle for metaindex index_handle: char[q]; // Block handle for index padding: char[40-p-q];// zeroed bytes to make fixed length // (40==2*BlockHandle::kMaxEncodedLength) magic: fixed64; // == 0xdb4775248b80fb57 (little-endian) “filter” Meta BlockIf a FilterPolicy was specified when the database was opened, afilter block is stored in each table. The “metaindex” block containsan entry that maps from filter.&lt;N&gt; to the BlockHandle for the filterblock where &lt;N&gt; is the string returned by the filter policy’sName() method. The filter block stores a sequence of filters, where filter i containsthe output of FilterPolicy::CreateFilter() on all keys that are storedin a block whose file offset falls within the range [ i*base ... (i+1)*base-1 ] Currently, “base” is 2KB. So for example, if blocks X and Y start inthe range [ 0KB .. 2KB-1 ], all of the keys in X and Y will beconverted to a filter by calling FilterPolicy::CreateFilter(), and theresulting filter will be stored as the first filter in the filterblock. The filter block is formatted as follows: [filter 0] [filter 1] [filter 2] ... [filter N-1] [offset of filter 0] : 4 bytes [offset of filter 1] : 4 bytes [offset of filter 2] : 4 bytes ... [offset of filter N-1] : 4 bytes [offset of beginning of offset array] : 4 bytes lg(base) : 1 byte The offset array at the end of the filter block allows efficientmapping from a data block offset to the corresponding filter. “stats” Meta BlockThis meta block contains a bunch of stats. The key is the nameof the statistic. The value contains the statistic. TODO(postrelease): record following stats. data size index size key size (uncompressed) value size (uncompressed) number of entries number of data blocks]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb Log format]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-Log-format%2F</url>
    <content type="text"><![CDATA[leveldb Log format日志文件内容是一系列32KB大小的block序列。唯一的例外是文件的末尾可能包含一个不完整的block。 每一个block包含一个记录序列： 123456block := record* trailer? record := checksum: uint32 // crc32c of type and data[] ; little-endian length: uint16 // little-endian type: uint8 // One of FULL, FIRST, MIDDLE, LAST data: uint8[length] 一条记录不会在一个block的最后6 byte处开始（因为放不下）。所有剩余的bytes组成trailer，需要包含全0的bytes，并且必须被读者跳过。 例外：若当前block恰好剩余7bytes，增加一个新的非0长度的record，写者必须将第一条记录（包含长度为0的用户数据）填充之前block剩余的7bytes，将用户数据写入之后的block之中。 在未来可能会增加新的类型。 一些读者可能会跳过不理解的记录类型，其他的可能会报告他跳过了一些值。 1234FULL == 1FIRST == 2MIDDLE == 3LAST == 4 FULL record包含完整的用户记录。 FIRST, MIDDLE, LAST 用于标志分片的用户记录（一般由于block边界）。FIRST是用户记录第一个分片的类型，LAST是用户记录最后一个分片的类型，MIDDLE是所有的用户记录中间分片的类型。 例子： 一个用户记录序列： 123A: length 1000B: length 97270C: length 8000 A 会是第一个block的FULL记录。 B 会被分为3个分段：第一段占据第一块剩余部分，第二段占据第二个block的全部，第三段占据第三个block的前面的绝大部分。第三个block会剩余6bytes空间，会被空余当做trailer。 C 会在第4个block中存放一条FULL记录。 Some benefits over the recordio format: 重新同步时不需要任何启发式查找 - 只需要到下一个block边界并进行扫描。 如果有错误，跳过去处理下一个block。附加的好处是，当一个log文件的部分内容被嵌入另一个log文件作为record时，我们不会陷入疑惑。 在大致的边界上进行分割（例如，mapreduce）非常简单：找到下一个块的边界，跳过record直到我们找到一条FULL或者FIRST类型的记录。 对于大的records，我们不需要额外的缓存。 Some downside compared to recordio format: 不会对小的record进行打包。可以通过增加新的记录类型来解决。所以这是当前实现的缺陷，不是这一format的缺点。 没有压缩。 这个也可以通过增加新的记录类型来解决。]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb 实现文档]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-%E5%AE%9E%E7%8E%B0%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[leveldb 实现文档Filesleveldb的实现和一个单点的Bigtable tablet(section 5.2)相似。但是内部文件的组成有所不同，下面会进行解释。 每一个数据库都是存储在目录下一系列的文件集合构成。有以下几种不同的文件类型： Log files一个log文件存储了最近更新的序列。每一个更新记录都被追加到当前的log文件中。当log文件达到预先设置的大小（可能是默认值4MB），它会被转换为一个sorted table，并且会创建一个新的log文件记录未来的更新。 当前log文件的副本被保存在内存中(memtable)。每次读都会检索这一副本，所以读操作能反映所有已经记录日志的更新。 Sorted tables一个sorted table（*.ldb）保存了按照key排序的entry序列。每一个entry可能是key和对应的value，或者key和对应的删除标记。（在旧版本的sorted tables中，删除标记用于覆盖过期的value）。 sorted tables组成的集合被组织成为level序列。从一个log文件中生成的sorted table被放置在一个特殊的 young level之中（也被称为level-0）。当 young files 的数目超出阈值（当前设置为4），所有的 young files 和key区间重叠的level-1文件合并生成一系列新的level-1文件（我们创建的新的level-1文件的大小是2MB）。 young level 文件可能包含重叠区间的key。但是其他level的文件都有唯一的没有重叠的key区间范围。对于 &gt;= 1的level值L，当level-L级别的文件大小超过（10^L）MB时（例如，level-1达到10MB, level-2达到100MB，···），一个level-L文件和所有key区间重叠的level-(L+1)文件合并为level-(L+1)的一系列新文件。这些合并操作使用块读取和写入操作，将新的更新从young level 逐步迁移到最大的level，减少了昂贵的寻道操作。 Manifset一个MANIFEST文件列出了组成每个level的sorted tables文件集合，对应key的范围，其他重要的元数据。一个新的MANIFEST文件（会在文件名中植入新的number）会在数据库重新打开时创建。MANIFEST是日志文件，服务状态的更新（新增或者移除文件）会追加到这一log文件。 CurrentCURRENT是一个简单的文本文件，其中包含了最新的MANIFEST文件的名字。 Info logs日志信息被写入命名为LOG或者Log.old的文件。 Others其他文件各种用途的文件，用途如名称所述，例如LOCK， *.dbtmp。 level0当log文件增长到某个值（默认是1MB）时： 创建新的memtable和log文件，将未来的更新写入新的文件。 在后台： 将之前memtable的内容写入到sstable 丢弃memtable 删除旧的log和memtable文件，将新的sstable文件加入young level。 Compactions当level L的文件大小超出限制之后，我们会在后台线程之中进行压缩合并。合并操作选取level-L中的一个文件和下一个level-(L+1)中key区间重叠的所有文件进行。注意到，如果level-L文件key区间只和level-(L+1)文件部分重叠，那么level-(L+1)文件会作为合并操作的输入，并且在合并操作完成之后被丢弃。例外：因为level-0文件比较特殊（level-0文件可能彼此之间互相重叠），我们对于从level-0到level-1的合并操作特殊对待：一个level-0级别的合并操作会选取所有key区间重叠的level-0文件进行，因而选取的level-0文件数量可能超过1。 一个合并压缩操作合并选取的文件内容，产生一个level-(L+1)序列的文件。在当前输出文件大小到达目标大小（2MB），我们会创建新的level-(L+1)文件。我们在当前输出文件的大小增长到和超过10个level-(L+2)级别的文件重叠时，也会产生新的输出文件。最后一条规则确保之后对于level-(L+1)文件的合并操作不会涉及到level-(L+2)中的过多的文件。 旧的文件会被丢弃，新的文件会被记录以更新当前服务状态。 对于一个特定level来说，合并操作会在key区间轮转进行。更详细地说，对于每一个level L，我们记录上一次level-L合并操作最后的key，下次level L的合并操作将会选取第一个大于这个key的文件开始（如果没有这样的文件，就从key区间的开头位置开始）。 合并操作会丢弃覆盖的值。若更高level的文件key的区间没有包含标记为删除的key，也会将其删除。 TimingLevel-0的合并操作会读取至多4个1MB大小的level-0文件，在最坏的情况下会读取所有的level-1文件（10MB）。因此，我们会读14MB，写14MB。 除了特殊的level-0合并操作，我们会从level-L选取一个2MB的文件。在最坏的情况下，这一文件会和level-(L+1)的中12个level-L文件大小的，level-(L+1)文件key区间重合（10因为level-(L+1) 比level-L的文件大小大10倍，剩余2因为level-L的文件大小和level-L+1的文件大小通常不对齐而增加的界限)。所以合并操作会读取26MB，写入26MB。假设硬盘的IO速度为100MB/s(现代设备的速度)，最坏的合并操作需要大约0.5秒。 若我们限制后台写入的速度，比如说全速100MB/s的10%，一个合并操作可能花费5秒。如果用户写入的速度是10MB/s，我们需要创建很多level-0文件（~50个，用于存放5*10MB）。由于每次读操作会合并过多的文件，这会显著增加读的开销。 解决方式： 为了减小这一问题，当level-0文件数量很大时，我们可能需要增加生成新的log文件的阈值。然而，缺点是这个阈值越大，我们需要更多的内存来存放对应的memtable。 当level-0文件数量上涨时，我们可能需要人为减小写入速度。 减小大幅度merge的开销。可能大多数level-0文件都是未经压缩存放在cache中，我们只需要O(N)复杂度的合并操作。 Number of files不再总是创建2MB的文件，更大level的文件有更大的大小能减小文件总数，虽然以合并操作更加突发为代价。另外，我们能将文件集合存放在不同的路径下。 2001年2月4日，一个在ext3文件系统下的实验演示了对于目录下不同数量，相同大小（100K）文件的打开操作的时间开销： Files in directory Microseconds to open a file 1000 9 10000 10 100000 16 所以对于现代文件系统，分片没有必要？ Recovery 读取CURRENT找到最新提交的MANIFEST文件的名称 读取MANIFEST文件 清除无效文件 我们可以打开所有的sstables文件，但是可能晚点打开会更好… 将log文件转换为新的level-0 sstable文件 将更新新写入新的log文件（以恢复后的序列） Garbage collection of fileDeleteObsoleteFiles()在每次合并和恢复操作的最后会被调用。他会查找database中用到的所有文件，删除不是当前log文件的所有log文件，删除没被任何层引用并且不是有效合并操作输出的所有table文件。]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Channel]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Channel%2F</url>
    <content type="text"><![CDATA[实现简介channel一般用于抽象一个fd，包含fd当前关注的事件，出现事件更新需要在poller之中做出更新。poller获取到当前io复用返回的io事件之后，会更新channel之中的revent。在eventloop中会为当前活跃的channel进行事件处理，调用对应revent，io事件的回调函数。整个Channel类的实现非常简单明了。 重点:tie可能出现这种情况，我们设置的回调函数是某个类的成员函数，此类对象使用shared_ptr进行管理。如果在回调函数之中对此shared_ptr进行了reset或者release处理，那么此回调函数就会立即失效，因为类对象被回收了。对于这种特殊情况，可以使用std::weak_ptr&lt;void&gt; tie来存放该shared_ptr的弱引用（使用弱引用是为了避免增加shared_ptr的引用计数，导致对象一直无法得以析构。每次进行事件处理的时候，若之前设置了tie，那么首先tie进行提升，保证回调函数处理期间此shared_ptr管理的对象不会被析构。 tie这一措施是为了TcpConnectionPtr而设计了，如果在某个回调函数之中，reset了此TcpConnectionPtr, 那么TcpConnection的其他回调函数就会失效。所以在处理这些事件期间，需要提升此TcpConnectionPtr的引用计数，阻止TcpConnectionPtr被析构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455void Channel::tie(const std::shared_ptr&lt;void&gt;&amp; obj)&#123; tie_ = obj; tied_ = true;&#125;void Channel::handleEvent(Timestamp receiveTime)&#123; std::shared_ptr&lt;void&gt; guard; if (tied_) &#123; guard = tie_.lock(); if (guard) &#123; handleEventWithGuard(receiveTime); &#125; &#125; else &#123; handleEventWithGuard(receiveTime); &#125;&#125;void Channel::handleEventWithGuard(Timestamp receiveTime)&#123; eventHandling_ = true; LOG_TRACE &lt;&lt; reventsToString(); if ((revents_ &amp; POLLHUP) &amp;&amp; !(revents_ &amp; POLLIN)) &#123; if (logHup_) &#123; LOG_WARN &lt;&lt; "fd = " &lt;&lt; fd_ &lt;&lt; " Channel::handle_event() POLLHUP"; &#125; if (closeCallback_) closeCallback_(); &#125; if (revents_ &amp; POLLNVAL) &#123; LOG_WARN &lt;&lt; "fd = " &lt;&lt; fd_ &lt;&lt; " Channel::handle_event() POLLNVAL"; &#125; if (revents_ &amp; (POLLERR | POLLNVAL)) &#123; if (errorCallback_) errorCallback_(); &#125; if (revents_ &amp; (POLLIN | POLLPRI | POLLRDHUP)) &#123; if (readCallback_) readCallback_(receiveTime); &#125; if (revents_ &amp; POLLOUT) &#123; if (writeCallback_) writeCallback_(); &#125; eventHandling_ = false;&#125;]]></content>
      <tags>
        <tag>muduo</tag>
        <tag>C++</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Buffer]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Buffer%2F</url>
    <content type="text"><![CDATA[实现原理在muduo之中，使用std::vector来存放网络中传输的数据，包括从要发送给对方的数据以及从对方接收的数据。在Buffer之中，预留了 prependable 的缓存，可以在buffer之中加入前缀而无需移动整个buffer。整个buffer分为prependable, readable, writable bytes. Buffer 的布局可以参考下图。 12345678910/// A buffer class modeled after org.jboss.netty.buffer.ChannelBuffer////// @code/// +-------------------+------------------+------------------+/// | prependable bytes | readable bytes | writable bytes |/// | | (CONTENT) | |/// +-------------------+------------------+------------------+/// | | | |/// 0 &lt;= readerIndex &lt;= writerIndex &lt;= size/// @endcode&gt;&gt;&gt; Buffer的作用非常之大，将用户程序从繁琐的Buffer相关读写操作之中解放了出来。 重点在muduo的Buffer之中，对read进行了特殊处理。因为从socket读，会调用read，涉及到一次上下文切换，为了减少系统调用的开销，read的调用次数是越少越好，因而需要尽可能预先分配更大的用户空间缓存。另一方面，如果对于每个连接都分配过多的缓存，那么会造成因为内存容量有限而造成支持的并发连接数目有限的问题。这二者之间存在矛盾。 在muduo之中，使用分配在堆栈上的缓存区域以及readv系统调用，将读取的数据优先存入buffer之中，超过限制才存放在堆栈上分配的缓存之中，最后再统一汇总到buffer之中。离开readFd函数之后，堆栈上分配的读取缓存会被自动回收。具体可以参考以下代码: 123456789101112131415161718192021222324252627282930313233ssize_t Buffer::readFd(int fd, int* savedErrno)&#123; // saved an ioctl()/FIONREAD call to tell how much to read char extrabuf[65536]; struct iovec vec[2]; const size_t writable = writableBytes(); vec[0].iov_base = begin()+writerIndex_; vec[0].iov_len = writable; vec[1].iov_base = extrabuf; vec[1].iov_len = sizeof extrabuf; // when there is enough space in this buffer, don't read into extrabuf. // when extrabuf is used, we read 128k-1 bytes at most. const int iovcnt = (writable &lt; sizeof extrabuf) ? 2 : 1; const ssize_t n = sockets::readv(fd, vec, iovcnt); if (n &lt; 0) &#123; *savedErrno = errno; &#125; else if (implicit_cast&lt;size_t&gt;(n) &lt;= writable) &#123; writerIndex_ += n; &#125; else &#123; writerIndex_ = buffer_.size(); append(extrabuf, n - writable); &#125; // if (n == writable + sizeof extrabuf) // &#123; // goto line_30; // &#125; return n;&#125;]]></content>
      <tags>
        <tag>muduo</tag>
        <tag>C++</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[auto关键字]]></title>
    <url>%2F2017%2F06%2F08%2Fauto%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[5. 优先使用auto而非显示类型声明在C++之中，使用auto关键字声明类型可以将程序员从输入繁琐的类型中解放出来，编译器会自动推导出变量的实际类型。 123456789template&lt;typename It&gt;void dwim(It b, It e)&#123; while(b != e)&#123; typename std::iterator_traits&lt;It&gt;::value_type currValue = *b; ... &#125;&#125; 使用auto关键字 12345678template&lt;typename It&gt;void dwim(It b, It e)&#123; while(b != e)&#123; auto currValue = *b; ... &#125;&#125; 在C++14中，lambda函数的参数都可以使用auto来定义。1234auto derefLess = // C++14 comparison [](const auto&amp; p1, // function for const auto&amp; p2) // values pointed &#123; return *p1 &lt; *p2; &#125;; 使用auto生命类型还可以将我们从类型截断的问题中解放出来：12std::vector&lt;int&gt; arrs;auto size = arrs.size(); 在C++中，unordered_map的key的类型是const类型的，所以即便采取如下方式遍历unordered_map容器，仍然会产生临时对象：1234567std::unordered_map&lt;std::string, int&gt; m; ...for (const std::pair&lt;std::string, int&gt;&amp; p : m)&#123; ... // do something with p&#125; 但是借助auto，我们不仅使声明更加简洁，还避开了此问题：1234567std::unordered_map&lt;std::string, int&gt; m; ...for (const auto&amp; p : m)&#123; ... // do something with p&#125; 6. 当auto推导出非预期类型时应当使用显示的类型初始化在C++中，因为标准不允许返回对bit的引用，所以对于vector&lt;bool&gt;标准库进行了特化处理，其[]运算符返回的是std::vector&lt;bool&gt;::reference类型的临时对象。对临时对象的修改会被其同步到vector中，因而这样使用auto关键字是不合规的。12345Widget w;…auto highPriority = features(w)[5]; // w是不是个高优先级的？…processWidget(w, highPriority); // 配合优先级处理w 在这种情况下，我们只需显示指出highPriority的类型为bool即可规避此问题。]]></content>
      <tags>
        <tag>modern effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++类型推导]]></title>
    <url>%2F2017%2F06%2F08%2FC%2B%2B%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[1. 理解模板类型推导1. expr是T&amp;123456template&lt;typename T&gt;void f(T &amp; param);// 我们声明如下变量int x = 27;const int cx = x;const int&amp; rx = x; 函数调用时，推导出的Param和T的类型如下： 123f(x); // T is int, param's type is int&amp;f(cx); // T is const int, param's type is const int&amp;f(rx); // T is const int, param's type is const int&amp; 需要特别注明的是，通过T&amp;的方式传入数组，数组的大小信息不会丢失。 1234template&lt;typename T&gt;void f(T&amp; param);const int arr[10];f(arr); // T is const int[10], param type is const int(&amp;)[10] 在类型推导期间，数组和函数将退化为指针类型，除非他们是被初始化为引用。 2. expr是const T&amp;123456template&lt;typename T&gt;void f(const T&amp; param);int x = 27;const int cx = x;const int&amp; rx = x; 在进行类型推导的时候，rx的引用性被忽略了。 123f(x); // T is int, param's type is const int&amp;f(cx); // T is int, param's type is const int&amp;f(rx); // T is int, param's type is const int&amp; 3. param是一个指针类型1234567template&lt;typename T&gt;void f(T* param); // param is now a pointerint x = 27;const int* px = &amp;x;f(&amp;x); // T is int, param's type is int *f(px); // T is const int, param's type is const int * 4. param是universial reference1234567891011template&lt;typename T&gt;void f(T&amp;&amp; param); // param is now a universal referenceint x = 27;const int cx = x;const int&amp; rx = x;f(x); // x is lvalue, so T is int&amp;, param's type is also int&amp;f(cx); // cx is lvalue, so T is const int&amp;, param's type is also const int&amp;f(rx); // rx is lvalue, so T is const int&amp;, param's type is also const int&amp;f(27); // 27 is rvalue, so T is int, param's typs is int&amp;&amp; 5. param 既不是指针也不是引用12template&lt;typename T&gt;void f(T param); 当ParamType既不是指针也不是引用的时候，我们按照值传递的方式进行处理。需要举出一个有用的例子：1234template&lt;typename T&gt;void f(T param);const char* const ptr = "hello world\n";f(ptr); // param's type is const char* 2. 理解auto自动类型推导auto 类型对象推导通常和模板类型推导是相同的。例子：123456const char name[] = "zhouyang";auto arr1 = name; // arr1's type is const char*auto&amp; arr2 = name; // arr2's type is const char(&amp;)[9]void someFunc(int, double); // someFunc is a functionauto func1 = someFunc; // func1's type is void(*)(int, double)auto&amp; func2 = someFunc; // func2's type is void(&amp;)(int, double) 唯一的例外是：使用auto和大括号进行初始化时，自动推导为std::initializer_list。并且，对于使用括号进行的初始化，模板类型推导会失败。 3. 理解decltypedecltype 一般情况下总是返回变量名或者表达式的类型而不做任何的修改。123const int i = 0; // decltype(i) is const intbool f(const Widget&amp; w) // decltype(w) is const Widget&amp;Widget W; // decltype(w) is Widget 在C++14中，提供了decltype(auto)的支持，它从初始化式子中推导类型，使用的是decltype的推导规则。123456Widget w;cosnt Widget&amp; cw = w;auto myWidget1 = cw; // myWidget1's type is Widgetdecltype(auto) myWidget2 = cw; // decltype type deduction: // myWidget2's type is const Widget&amp;// 注：可以在模板中使用 特例:12345678910111213#include &lt;iostream&gt;using namespace std;int main()&#123; int temp = 10; decltype((temp)) temp1 = temp; // temp1's type is int&amp; temp1 = 1; cout&lt;&lt; temp &lt;&lt; endl; return 0;&#125;//输出 : 1 4. 了解如何查看推导出的类型可以利用编译器诊断来完成。我们想要知道被推导出的类型，可以首先声明一个类模板，但是不定义它。那么编译器的出错信息会包含推导的类型信息。12template&lt;typename T&gt;class TD; 通过编译器内置的宏定义，可以输出函数类型1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void test_func(int)&#123;#if defined(__GNUC__) cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; endl;#elif defined(_MSC_VER) cout &lt;&lt; __FUNCSIG__ &lt;&lt; endl;#endif&#125;int main()&#123; test_func(10); return 0;&#125;]]></content>
      <tags>
        <tag>modern effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Acceptor]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Acceptor%2F</url>
    <content type="text"><![CDATA[运行流程Acceptr是muduo之中TcpServer用于接受连接的wrapper类。其中有一个成员acceptChannel_用于接受连接。其句柄是用于接受连接的socket fd。 上述acceptChannel_关注的是可读事件，可读代表有新的连接可以accept了。在关注可读事件之前需要首先开始监听。监听的backlog的限制采用的是Linux所支持的最大值: SOMAXCONN. 特殊处理在接受连接的时候，可能会出现这种问题：描述符用完了，这会导致accpet失败，并且返回ENFILE错误。但是并没有拒绝这一连接，连接仍然会在连接队列之中，这导致了下一次eventLoop中仍然会触发监听描述符的可读事件，这会导致busy loop。 一种比较简单的解决方式是程序遇到这个问题，直接忽略，直到这种情况消失，但是这种解决方式会导致busy waiting。 另一种解决思路是记录除了EAGAIN或者EWOULDBLOCK其他任何错误，告诉用户出现了某种错误，并且停止监听描述符的可读事件，减少CPU的使用。 在libevent中，采用的是如下解决方式。首先打开/dev/null, 保留一个文件描述符，当accept出现ENFILE或者EMFILE错误的时候，关闭/dev/null，然后再次accept，并且close掉accept产生的fd，再次打开/dev/null，这是一种比较优雅的方式来拒绝客户端的连接。 最后一种比较sb的方式是遇到accept的这种错误，直接拒绝并且退出。这种方式比较容易受到Dos攻击。 12345678910111213141516171819202122232425262728293031323334void Acceptor::handleRead()&#123; loop_-&gt;assertInLoopThread(); InetAddress peerAddr; //FIXME loop until no more int connfd = acceptSocket_.accept(&amp;peerAddr); if (connfd &gt;= 0) &#123; // string hostport = peerAddr.toIpPort(); // LOG_TRACE &lt;&lt; "Accepts of " &lt;&lt; hostport; if (newConnectionCallback_) &#123; newConnectionCallback_(connfd, peerAddr); &#125; else &#123; sockets::close(connfd); &#125; &#125; else &#123; LOG_SYSERR &lt;&lt; "in Acceptor::handleRead"; // Read the section named "The special problem of // accept()ing when you can't" in libev's doc. // By Marc Lehmann, author of libev. if (errno == EMFILE) &#123; ::close(idleFd_); idleFd_ = ::accept(acceptSocket_.fd(), NULL, NULL); ::close(idleFd_); idleFd_ = ::open("/dev/null", O_RDONLY | O_CLOEXEC); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>muduo</tag>
        <tag>C++</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>