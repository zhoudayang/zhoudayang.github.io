<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[muduo Connector]]></title>
    <url>%2F2017%2F06%2F11%2Fmuduo-Connector%2F</url>
    <content type="text"><![CDATA[怎么判断连接成功了？12345678910111213141516171819202122232425262728293031323334353637383940void Connector::connect()&#123; int sockfd = sockets::createNonblockingOrDie(serverAddr_.family()); int ret = sockets::connect(sockfd, serverAddr_.getSockAddr()); int savedErrno = (ret == 0) ? 0 : errno; switch (savedErrno) &#123; case 0: case EINPROGRESS: case EINTR: case EISCONN: connecting(sockfd); break; case EAGAIN: case EADDRINUSE: case EADDRNOTAVAIL: case ECONNREFUSED: case ENETUNREACH: retry(sockfd); break; case EACCES: case EPERM: case EAFNOSUPPORT: case EALREADY: case EBADF: case EFAULT: case ENOTSOCK: LOG_SYSERR &lt;&lt; "connect error in Connector::startInLoop " &lt;&lt; savedErrno; sockets::close(sockfd); break; default: LOG_SYSERR &lt;&lt; "Unexpected error in Connector::startInLoop " &lt;&lt; savedErrno; sockets::close(sockfd); // connectErrorCallback_(); break; &#125;&#125; 可见，对于非阻塞io，如果connect之后的返回值为0，或者errno设置为EINTR, EINPROGRESS, EISCONN, 那么代表连接成功或者正在连接的过程之中。 如果errno为EAGIN，EADDRINUSE，EADDRNOTAVAIL，ECONNREFUSED，ENETURNREACH, 那么表示连接失败。在linux tcp编程之中，对于连接失败的情况，可以移植的解决方式是重新创建一个socket fd，再次尝试连接。对于EACCES，EPERM，EAFNOSUPPORT，EALREADY，EBADF，EFAULT，ENOTSOCK的情况，表示不可恢复的连接失败，直接停止连接，对于其他未知的情况也做此处理。 现在，怎么知道连接成功了呢？以connect返回的sockfd创建一个channel，关注其可写事件。若channel可写，并且尝试使用getsockopt(sockfd, SOL_SOCKET, SO_ERROR, &amp;optval, &amp;optlen)返回的errorCode为0，并且不是自连接，那么说明连接成功，可以将这个sockfd通过connectionCallback通知TcpClient。当然，如果调用的是ErrorCallback，那么close返回的fd，并且进行重试。 1234567891011121314151617181920212223242526272829303132333435363738void Connector::handleWrite()&#123; LOG_TRACE &lt;&lt; "Connector::handleWrite " &lt;&lt; state_; if (state_ == kConnecting) &#123; int sockfd = removeAndResetChannel(); int err = sockets::getSocketError(sockfd); if (err) &#123; LOG_WARN &lt;&lt; "Connector::handleWrite - SO_ERROR = " &lt;&lt; err &lt;&lt; " " &lt;&lt; strerror_tl(err); retry(sockfd); &#125; else if (sockets::isSelfConnect(sockfd)) &#123; LOG_WARN &lt;&lt; "Connector::handleWrite - Self connect"; retry(sockfd); &#125; else &#123; setState(kConnected); if (connect_) &#123; newConnectionCallback_(sockfd); &#125; else &#123; sockets::close(sockfd); &#125; &#125; &#125; else &#123; // what happened? assert(state_ == kDisconnected); &#125;&#125; 12345678910111213141516171819202122// check if self connectionbool sockets::isSelfConnect(int sockfd)&#123; struct sockaddr_in6 localaddr = getLocalAddr(sockfd); struct sockaddr_in6 peeraddr = getPeerAddr(sockfd); if (localaddr.sin6_family == AF_INET) &#123; const struct sockaddr_in* laddr4 = reinterpret_cast&lt;struct sockaddr_in*&gt;(&amp;localaddr); const struct sockaddr_in* raddr4 = reinterpret_cast&lt;struct sockaddr_in*&gt;(&amp;peeraddr); return laddr4-&gt;sin_port == raddr4-&gt;sin_port &amp;&amp; laddr4-&gt;sin_addr.s_addr == raddr4-&gt;sin_addr.s_addr; &#125; else if (localaddr.sin6_family == AF_INET6) &#123; return localaddr.sin6_port == peeraddr.sin6_port &amp;&amp; memcmp(&amp;localaddr.sin6_addr, &amp;peeraddr.sin6_addr, sizeof localaddr.sin6_addr) == 0; &#125; else &#123; return false; &#125;&#125; 怎么实现超时重连？对于retry的处理使用了Connector的retry方法，他会设置超时回调，回调的时间间隔设置为从500ms~30s, 每次重新retry会将间隔的时间加倍，当然时间间隔不可超过30s。 1234567891011121314151617void Connector::retry(int sockfd)&#123; sockets::close(sockfd); setState(kDisconnected); if (connect_) &#123; LOG_INFO &lt;&lt; "Connector::retry - Retry connecting to " &lt;&lt; serverAddr_.toIpPort() &lt;&lt; " in " &lt;&lt; retryDelayMs_ &lt;&lt; " milliseconds. "; loop_-&gt;runAfter(retryDelayMs_/1000.0, std::bind(&amp;Connector::startInLoop, shared_from_this())); retryDelayMs_ = std::min(retryDelayMs_ * 2, kMaxRetryDelayMs); &#125; else &#123; LOG_DEBUG &lt;&lt; "do not connect"; &#125;&#125; 对于stop的处理如果要停止连接，那么首先设置connect_为false，表示不需要建立连接了，这样若handleWrite之中返回了正常的sockfd，那么我也不要通过这个sockfd创建一个连接，而是直接将其close。并且因为connect_设置设置为false，后续进行retry的时候也不会尝试重新连接的。 紧接着的是对stopInLoop的调用，这里对正在处于连接状态的channel进行了reset处理，并且将没有确定连接的sockfd关闭。]]></content>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的可变长参数]]></title>
    <url>%2F2017%2F06%2F10%2FC-%E4%B8%AD%E7%9A%84%E5%8F%AF%E5%8F%98%E9%95%BF%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[C++ 中的可变长参数基本格式在C++中，可变长参数模板可以用来应对未知长度函数参数的问题。其基本格式如下所示： 123456template&lt;typename ...Args&gt;void g(Args ... args)&#123; cout &lt;&lt; sizeof ...(Args) &lt;&lt; endl; // 类型参数的数目 cout &lt;&lt; sizeof ...(args) &lt;&lt; endl; // 函数参数的数目&#125; 基本用法可变参数函数通常是递归的，第一步调用处理包中的第一个实参，然后用剩余的实参来调用自身。如下的print示例程序就演示了这种用法。123456789101112131415161718192021222324#include &lt;vector&gt;#include &lt;cstring&gt;using namespace std;// 递归调用的终点template&lt;typename T&gt;ostream&amp; print(ostream&amp; os, const T&amp; t)&#123; return os &lt;&lt; t;&#125;template&lt;typename T, typename... Args&gt;ostream&amp; print(ostream&amp; os, const T&amp; t, const Args&amp;... rest)&#123; os &lt;&lt; t &lt;&lt; ", "; // 递归用剩余参数进行调用 return print(os, rest...);&#125;int main()&#123; print(cout, 1, 2.0, false);&#125; 递归会执行如下序列： print(cout, 1, 2.0, false) print(cout, 2.0, false) print(cout, false) 当定义可变参数版本的print的时候，非可变参数版本的声明必须在作用域中。否则，可变参数版本会无限递归。 包扩展可以利用包扩展机制，对可变长模板参数中的每一个参数进行相同的调用。如下所示代码演示了对输入的每个参数都调用了函数no_operation。 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;atomic&gt;#include &lt;vector&gt;#include &lt;cstring&gt;using namespace std;// 递归调用的终点template&lt;typename T&gt;ostream&amp; print(ostream&amp; os, const T&amp; t)&#123; return os &lt;&lt; t;&#125;template&lt;typename T&gt;T no_operation(const T&amp; val)&#123; return val;&#125;template&lt;typename T, typename... Args&gt;ostream&amp; print(ostream&amp; os, const T&amp; t, const Args&amp;... rest)&#123; os &lt;&lt; t &lt;&lt; ", "; // 递归用剩余参数进行调用 // 对所有的参数统一调用no_operation return print(os, no_operation(rest)...);&#125;int main()&#123; // 实际调用no_operation的次数为3，和输入的参数的个数一致 print(cout, 1, 2.0, false);&#125; 转发参数包借助std::forward，可以安全的将输入的可变长参数转发给其他函数，这样vector通过emplace_back就在容器内部直接通过输入的参数构造需要插入的对象。 最简单的例子是make_unique，如下所示： 12345template&lt;typename T, typename... Args&gt;std::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp; ...args)&#123; return std::unique_ptr&lt;T&gt;(new T(std::forward&lt;Args&gt;(args)...));&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb filter_block]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-filter-block%2F</url>
    <content type="text"><![CDATA[leveldb filter_block解析filter meta block 文件格式首先借助leveldb文档leveldb File format可以确定filter meta block内部的格式如下所示： 1234567891011121314[filter 0][filter 1][filter 2][filter 3][filter 4]...[filter N-1][offset of filter 0] : 4 bytes[offset of filter 1] : 4 bytes[offset of filter 2] : 4 bytes...[offset of filter N-1] : 4 bytes[offset of beginning of offset array] : 4 byteslg(base) : 1 byte 借助源码和文档，我对filter meta block的格式有了深刻的理解。每一个filter对应负责一个block offset范围内的key的组织。对于第i个filter，它所管理的key在文件中的偏移范围是[i * base ... (i+1) * base - 1]。在leveldb中，base默认被设置为2KB，也就是说每2KB长度的偏移位置对应一个独立的filter。 每一个key借助hash函数(maybe, 看filter策略具体实现)产生一个滤值，一个filter可能会有多个这样的滤值。所有filter的滤值最后从前到后依次保存在filter meta block之中。然后再存放每一个filter对应滤值的偏移位置。根据当前filter和下一个filter的offset值就可以确定当前filter对应滤值在filter meta block中偏移值的范围。紧接着存放最后一个filter对应滤值offset范围的下界，通过它我们还能知道整个块中filter的数量。filter meta block的最后存放的是log(base)的值，由它我们能知道每个filter所能管理的文件偏移大小限制。 附上一张网上找到的图 FilterBlockBuilder12345678910111213141516171819202122232425262728293031// A FilterBlockBuilder is used to construct all of the filters for a// particular Table. It generates a single string which is stored as// a special block in the Table.//// The sequence of calls to FilterBlockBuilder must match the regexp:// (StartBlock AddKey*)* Finishclass FilterBlockBuilder &#123; public: explicit FilterBlockBuilder(const FilterPolicy*); void StartBlock(uint64_t block_offset); void AddKey(const Slice&amp; key); Slice Finish(); private: void GenerateFilter(); const FilterPolicy* policy_; // 过滤策略 std::string keys_; // 存放所有的key std::vector&lt;size_t&gt; start_; // 存放每一个key在keys_的下标范围 // 存放最终的结果 std::string result_; // Filter data computed so far // 用于记录每个filter产生的滤值的临时容器 std::vector&lt;Slice&gt; tmp_keys_; // policy_-&gt;CreateFilter() argument // 记录每个filter的offset开始位置 std::vector&lt;uint32_t&gt; filter_offsets_; // No copying allowed FilterBlockBuilder(const FilterBlockBuilder&amp;); void operator=(const FilterBlockBuilder&amp;);&#125;; FilterBlockBuilder对象在构造的时候需要指定FilterPolicy，它要用其来生成滤值。在对偏移为block_offset的文件进行操作前，首先需要调用StartBlock。此方法确定输入的偏移值对应哪一个filter，并且将filter_index更小的filter的滤值写入result_。 123456789void FilterBlockBuilder::StartBlock(uint64_t block_offset) &#123; // kFilterBase的大小为2048 uint64_t filter_index = (block_offset / kFilterBase); assert(filter_index &gt;= filter_offsets_.size()); while (filter_index &gt; filter_offsets_.size()) &#123; // 若filter_index 的值更大，将之前的filter对应的滤值加入result_ GenerateFilter(); &#125;&#125; 请注意，要按照偏移的先后顺序调用StartBlock和AddKey方法，这样才能保证filter meta block内部顺序和实际偏移一致。 GenerateFilter方法将当前filter所管理的key按照输入的Filter策略转换为滤值，并且记录当前filter对应的滤值在block中偏移的开始位置。123456789101112131415161718192021222324252627282930313233// 产生新的filtervoid FilterBlockBuilder::GenerateFilter() &#123; // 对应key的数目 const size_t num_keys = start_.size(); if (num_keys == 0) &#123; // Fast path if there are no keys for this filter // 记录此filter的偏移位置 filter_offsets_.push_back(result_.size()); return; &#125; // Make list of keys from flattened key structure start_.push_back(keys_.size()); // Simplify length computation tmp_keys_.resize(num_keys); for (size_t i = 0; i &lt; num_keys; i++) &#123; // 每个key的开头位置 const char* base = keys_.data() + start_[i]; // 每个key的长度 size_t length = start_[i+1] - start_[i]; tmp_keys_[i] = Slice(base, length); &#125; // Generate filter for current set of keys and append to result_. // 记录此filter的偏移起始位置 filter_offsets_.push_back(result_.size()); // 创建filter，输入key对应的数组，数组大小，存放结果的result // result存放key对应的hash值 policy_-&gt;CreateFilter(&amp;tmp_keys_[0], static_cast&lt;int&gt;(num_keys), &amp;result_); tmp_keys_.clear(); keys_.clear(); start_.clear();&#125; 在加入新的key时，会在start_中记录新的key在keys_中的开始位置，然后将其append到keys_之中，这样之后借助keys_和start_t就能重构所有输入的key。12345void FilterBlockBuilder::AddKey(const Slice&amp; key) &#123; Slice k = key; start_.push_back(keys_.size()); keys_.append(k.data(), k.size());&#125; Finish函数的操作很容易理解，他首先记录所有filter对应滤值的offset范围，注意要补充记录最后一个filter的滤值offset下界。当然也要按照文件格式记录log(base)值。 12345678910111213141516171819Slice FilterBlockBuilder::Finish() &#123; if (!start_.empty()) &#123; GenerateFilter(); &#125; // Append array of per-filter offsets // 这是滤值数组的结束位置offset，将这个值记住 const uint32_t array_offset = result_.size(); // 存放filter对应的offset开头位置 for (size_t i = 0; i &lt; filter_offsets_.size(); i++) &#123; PutFixed32(&amp;result_, filter_offsets_[i]); &#125; // 存放最后一个filter offset的下界 PutFixed32(&amp;result_, array_offset); // 存放kFilterBaseLg的大小 // kFilterBaseLg = log(base) result_.push_back(kFilterBaseLg); // Save encoding parameter in result return Slice(result_);&#125; FilterBlockReader相比FilterBlockBuilder，FilterBLockReader可以理解为它的逆过程。 123456789101112131415class FilterBlockReader &#123; public: // REQUIRES: "contents" and *policy must stay live while *this is live. FilterBlockReader(const FilterPolicy* policy, const Slice&amp; contents); bool KeyMayMatch(uint64_t block_offset, const Slice&amp; key); private: const FilterPolicy* policy_; const char* data_; // Pointer to filter data (at block-start) // 指向offset数组靠近block尾部的开始处 const char* offset_; // Pointer to beginning of offset array (at block-end) // filter的数目 size_t num_; // Number of entries in offset array size_t base_lg_; // Encoding parameter (see kFilterBaseLg in .cc file)&#125;; 在构造函数中，Reader根据文件格式获取base的log值，filter的数目，第一个filter的偏移的开始位置。 123456789101112131415161718192021FilterBlockReader::FilterBlockReader(const FilterPolicy* policy, const Slice&amp; contents) : policy_(policy), data_(NULL), offset_(NULL), num_(0), base_lg_(0) &#123; size_t n = contents.size(); // size not enough to hold start and offset array if (n &lt; 5) return; // 1 byte for base_lg_ and 4 for start of offset array // 取出base_lg_的值 base_lg_ = contents[n-1]; uint32_t last_word = DecodeFixed32(contents.data() + n - 5); // 滤值数组的最后元素的末尾位置不可能超出n-5，否则无法容纳 if (last_word &gt; n - 5) return; data_ = contents.data(); // 指向最后一个filter滤值的offset下界位置 offset_ = data_ + last_word; // filter的数量 num_ = (n - 5 - last_word) / 4;&#125; 至于对key的匹配判断，对于输入的block_offset，计算出它属于哪一个filter。然后取出此filter的所有滤值，和key按照filter策略计算得到的滤纸进行匹配，相同说明可能匹配，否则不能匹配。对于计算得到的filter的index值大于block中filter的数量的情况，也被认为是匹配，即错误被当做潜在的匹配。 123456789101112131415161718bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice&amp; key) &#123; uint64_t index = block_offset &gt;&gt; base_lg_; if (index &lt; num_) &#123; // 滤值开始位置对应的偏移 uint32_t start = DecodeFixed32(offset_ + index*4); // 滤值结束位置对应的偏移 // 实质上是下一个filter的offset开始位置 uint32_t limit = DecodeFixed32(offset_ + index*4 + 4); if (start &lt;= limit &amp;&amp; limit &lt;= static_cast&lt;size_t&gt;(offset_ - data_)) &#123; Slice filter = Slice(data_ + start, limit - start); return policy_-&gt;KeyMayMatch(key, filter); &#125; else if (start == limit) &#123; // Empty filters do not match any keys return false; &#125; &#125; return true; // Errors are treated as potential matches&#125;]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb File format]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-File-format%2F</url>
    <content type="text"><![CDATA[leveldb File format123456789101112&lt;beginning_of_file&gt;[data block 1][data block 2]...[data block N][meta block 1]...[meta block K][metaindex block][index block][Footer] (fixed size; starts at file_size - sizeof(Footer))&lt;end_of_file&gt; 文件之中包含内部指针。每一个这样的指针被称为BlockHandle，包含下述信息。 12offset: varint64size: varint64 varint的解释可以查看varints。 文件中的键值对按照顺序进行存储，并被分割成为数据块序列。这些数据块在文件中从前到后依次排列。每一个数据块按照block_builder.cc中的代码进行格式化，然后进行可选的压缩。 在数据块之后，我们存储了一串元数据块。支持的meta块类型会在下文描述。未来可能会增加新的meta块类型。每一个meta块也是使用block_builder.cc中的代码进行格式化，然后进行可选的压缩。 一个命名为”metaindex”的块。对于其他的meta块每个块记录一个entry，key是meta块的名称，value是指向对应meta块的BlockHandle。 一个名为”index”的块。这个块对于每个数据块记录一个entry，key是大于对应数据块最后一个key，并且小于紧接着的下一个数据块的第一个key的字符串。value是数据块的BlockHandle。 每个文件的末尾是一个固定长度的footer，包含metaindex和index块的BlockHandle，以及一个魔数。 12345metaindex_handle: char[p]; // Block handle for metaindexindex_handle: char[q]; // Block handle for indexpadding: char[40-p-q];// zeroed bytes to make fixed length // (40==2*BlockHandle::kMaxEncodedLength)magic: fixed64; // == 0xdb4775248b80fb57 (little-endian) “filter” Meta Block若数据库打开时指定了FilterPolicy，每个table会存储一个filter块。”metaindex”块包含一条entry，记录从filter.&lt;N&gt;到filter块的BlockHandle的映射。其中&lt;N&gt;是filter policy的Name()方法返回的字符串。 filter块存储了filters序列，其中filter i包含FilterPolicy::CreateFilter()所有key的输出，这些key在文件中偏移的范围在范围： 1[ i*base ... (i+1)*base-1 ] 当前，”base”是2KB，举例来说，若块x和y在文件中的偏移范围是[0KB .. 2KB-1]，所有x和y的将会调用FilterPolicy::CreateFilter()转换成filter，生成的filter是第一个filter block。 filter块的格式如下所示： 1234567891011121314[filter 0][filter 1][filter 2]...[filter N-1][offset of filter 0] : 4 bytes[offset of filter 1] : 4 bytes[offset of filter 2] : 4 bytes...[offset of filter N-1] : 4 bytes[offset of beginning of offset array] : 4 byteslg(base) : 1 byte filter块末尾的offset array 允许从data block偏移到对应filter的有效映射。 “Stats” Meta Block这一meta块包含一串统计信息。key是统计名称，value是统计值。 TODO(postrelease): record following stats. 123456data sizeindex sizekey size (uncompressed)value size (uncompressed)number of entriesnumber of data blocks]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb Log format]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-Log-format%2F</url>
    <content type="text"><![CDATA[leveldb Log format日志文件内容是一系列32KB大小的block序列。唯一的例外是文件的末尾可能包含一个不完整的block。 每一个block包含一个记录序列： 123456block := record* trailer? record := checksum: uint32 // crc32c of type and data[] ; little-endian length: uint16 // little-endian type: uint8 // One of FULL, FIRST, MIDDLE, LAST data: uint8[length] 一条记录不会在一个block的最后6 byte处开始（因为放不下）。所有剩余的bytes组成trailer，需要包含全0的bytes，并且必须被读者跳过。 例外：若当前block恰好剩余7bytes，增加一个新的非0长度的record，写者必须将第一条记录（包含长度为0的用户数据）填充之前block剩余的7bytes，将用户数据写入之后的block之中。 在未来可能会增加新的类型。 一些读者可能会跳过不理解的记录类型，其他的可能会报告他跳过了一些值。 1234FULL == 1FIRST == 2MIDDLE == 3LAST == 4 FULL record包含完整的用户记录。 FIRST, MIDDLE, LAST 用于标志分片的用户记录（一般由于block边界）。FIRST是用户记录第一个分片的类型，LAST是用户记录最后一个分片的类型，MIDDLE是所有的用户记录中间分片的类型。 例子： 一个用户记录序列： 123A: length 1000B: length 97270C: length 8000 A 会是第一个block的FULL记录。 B 会被分为3个分段：第一段占据第一块剩余部分，第二段占据第二个block的全部，第三段占据第三个block的前面的绝大部分。第三个block会剩余6bytes空间，会被空余当做trailer。 C 会在第4个block中存放一条FULL记录。 Some benefits over the recordio format: 重新同步时不需要任何启发式查找 - 只需要到下一个block边界并进行扫描。 如果有错误，跳过去处理下一个block。附加的好处是，当一个log文件的部分内容被嵌入另一个log文件作为record时，我们不会陷入疑惑。 在大致的边界上进行分割（例如，mapreduce）非常简单：找到下一个块的边界，跳过record直到我们找到一条FULL或者FIRST类型的记录。 对于大的records，我们不需要额外的缓存。 Some downside compared to recordio format: 不会对小的record进行打包。可以通过增加新的记录类型来解决。所以这是当前实现的缺陷，不是这一format的缺点。 没有压缩。 这个也可以通过增加新的记录类型来解决。]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb 实现文档]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-%E5%AE%9E%E7%8E%B0%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[leveldb 实现文档Filesleveldb的实现和一个单点的Bigtable tablet(section 5.2)相似。但是内部文件的组成有所不同，下面会进行解释。 每一个数据库都是存储在目录下一系列的文件集合构成。有以下几种不同的文件类型： Log files一个log文件存储了最近更新的序列。每一个更新记录都被追加到当前的log文件中。当log文件达到预先设置的大小（可能是默认值4MB），它会被转换为一个sorted table，并且会创建一个新的log文件记录未来的更新。 当前log文件的副本被保存在内存中(memtable)。每次读都会检索这一副本，所以读操作能反映所有已经记录日志的更新。 Sorted tables一个sorted table（*.ldb）保存了按照key排序的entry序列。每一个entry可能是key和对应的value，或者key和对应的删除标记。（在旧版本的sorted tables中，删除标记用于覆盖过期的value）。 sorted tables组成的集合被组织成为level序列。从一个log文件中生成的sorted table被放置在一个特殊的 young level之中（也被称为level-0）。当 young files 的数目超出阈值（当前设置为4），所有的 young files 和key区间重叠的level-1文件合并生成一系列新的level-1文件（我们创建的新的level-1文件的大小是2MB）。 young level 文件可能包含重叠区间的key。但是其他level的文件都有唯一的没有重叠的key区间范围。对于 &gt;= 1的level值L，当level-L级别的文件大小超过（10^L）MB时（例如，level-1达到10MB, level-2达到100MB，···），一个level-L文件和所有key区间重叠的level-(L+1)文件合并为level-(L+1)的一系列新文件。这些合并操作使用块读取和写入操作，将新的更新从young level 逐步迁移到最大的level，减少了昂贵的寻道操作。 Manifset一个MANIFEST文件列出了组成每个level的sorted tables文件集合，对应key的范围，其他重要的元数据。一个新的MANIFEST文件（会在文件名中植入新的number）会在数据库重新打开时创建。MANIFEST是日志文件，服务状态的更新（新增或者移除文件）会追加到这一log文件。 CurrentCURRENT是一个简单的文本文件，其中包含了最新的MANIFEST文件的名字。 Info logs日志信息被写入命名为LOG或者Log.old的文件。 Others其他文件各种用途的文件，用途如名称所述，例如LOCK， *.dbtmp。 level0当log文件增长到某个值（默认是1MB）时： 创建新的memtable和log文件，将未来的更新写入新的文件。 在后台： 将之前memtable的内容写入到sstable 丢弃memtable 删除旧的log和memtable文件，将新的sstable文件加入young level。 Compactions当level L的文件大小超出限制之后，我们会在后台线程之中进行压缩合并。合并操作选取level-L中的一个文件和下一个level-(L+1)中key区间重叠的所有文件进行。注意到，如果level-L文件key区间只和level-(L+1)文件部分重叠，那么level-(L+1)文件会作为合并操作的输入，并且在合并操作完成之后被丢弃。例外：因为level-0文件比较特殊（level-0文件可能彼此之间互相重叠），我们对于从level-0到level-1的合并操作特殊对待：一个level-0级别的合并操作会选取所有key区间重叠的level-0文件进行，因而选取的level-0文件数量可能超过1。 一个合并压缩操作合并选取的文件内容，产生一个level-(L+1)序列的文件。在当前输出文件大小到达目标大小（2MB），我们会创建新的level-(L+1)文件。我们在当前输出文件的大小增长到和超过10个level-(L+2)级别的文件重叠时，也会产生新的输出文件。最后一条规则确保之后对于level-(L+1)文件的合并操作不会涉及到level-(L+2)中的过多的文件。 旧的文件会被丢弃，新的文件会被记录以更新当前服务状态。 对于一个特定level来说，合并操作会在key区间轮转进行。更详细地说，对于每一个level L，我们记录上一次level-L合并操作最后的key，下次level L的合并操作将会选取第一个大于这个key的文件开始（如果没有这样的文件，就从key区间的开头位置开始）。 合并操作会丢弃覆盖的值。若更高level的文件key的区间没有包含标记为删除的key，也会将其删除。 TimingLevel-0的合并操作会读取至多4个1MB大小的level-0文件，在最坏的情况下会读取所有的level-1文件（10MB）。因此，我们会读14MB，写14MB。 除了特殊的level-0合并操作，我们会从level-L选取一个2MB的文件。在最坏的情况下，这一文件会和level-(L+1)的中12个level-L文件大小的，level-(L+1)文件key区间重合（10因为level-(L+1) 比level-L的文件大小大10倍，剩余2因为level-L的文件大小和level-L+1的文件大小通常不对齐而增加的界限)。所以合并操作会读取26MB，写入26MB。假设硬盘的IO速度为100MB/s(现代设备的速度)，最坏的合并操作需要大约0.5秒。 若我们限制后台写入的速度，比如说全速100MB/s的10%，一个合并操作可能花费5秒。如果用户写入的速度是10MB/s，我们需要创建很多level-0文件（~50个，用于存放5*10MB）。由于每次读操作会合并过多的文件，这会显著增加读的开销。 解决方式： 为了减小这一问题，当level-0文件数量很大时，我们可能需要增加生成新的log文件的阈值。然而，缺点是这个阈值越大，我们需要更多的内存来存放对应的memtable。 当level-0文件数量上涨时，我们可能需要人为减小写入速度。 减小大幅度merge的开销。可能大多数level-0文件都是未经压缩存放在cache中，我们只需要O(N)复杂度的合并操作。 Number of files不再总是创建2MB的文件，更大level的文件有更大的大小能减小文件总数，虽然以合并操作更加突发为代价。另外，我们能将文件集合存放在不同的路径下。 2001年2月4日，一个在ext3文件系统下的实验演示了对于目录下不同数量，相同大小（100K）文件的打开操作的时间开销： Files in directory Microseconds to open a file 1000 9 10000 10 100000 16 所以对于现代文件系统，分片没有必要？ Recovery 读取CURRENT找到最新提交的MANIFEST文件的名称 读取MANIFEST文件 清除无效文件 我们可以打开所有的sstables文件，但是可能晚点打开会更好… 将log文件转换为新的level-0 sstable文件 将更新新写入新的log文件（以恢复后的序列） Garbage collection of fileDeleteObsoleteFiles()在每次合并和恢复操作的最后会被调用。他会查找database中用到的所有文件，删除不是当前log文件的所有log文件，删除没被任何层引用并且不是有效合并操作输出的所有table文件。]]></content>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Channel]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Channel%2F</url>
    <content type="text"><![CDATA[实现简介channel一般用于抽象一个fd，包含fd当前关注的事件，出现事件更新需要在poller之中做出更新。poller获取到当前io复用返回的io事件之后，会更新channel之中的revent。在eventloop中会为当前活跃的channel进行事件处理，调用对应revent，io事件的回调函数。整个Channel类的实现非常简单明了。 重点:tie可能出现这种情况，我们设置的回调函数是某个类的成员函数，此类对象使用shared_ptr进行管理。如果在回调函数之中对此shared_ptr进行了reset或者release处理，那么此回调函数就会立即失效，因为类对象被回收了。对于这种特殊情况，可以使用std::weak_ptr&lt;void&gt; tie来存放该shared_ptr的弱引用（使用弱引用是为了避免增加shared_ptr的引用计数，导致对象一直无法得以析构。每次进行事件处理的时候，若之前设置了tie，那么首先tie进行提升，保证回调函数处理期间此shared_ptr管理的对象不会被析构。 tie这一措施是为了TcpConnectionPtr而设计了，如果在某个回调函数之中，reset了此TcpConnectionPtr, 那么TcpConnection的其他回调函数就会失效。所以在处理这些事件期间，需要提升此TcpConnectionPtr的引用计数，阻止TcpConnectionPtr被析构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455void Channel::tie(const std::shared_ptr&lt;void&gt;&amp; obj)&#123; tie_ = obj; tied_ = true;&#125;void Channel::handleEvent(Timestamp receiveTime)&#123; std::shared_ptr&lt;void&gt; guard; if (tied_) &#123; guard = tie_.lock(); if (guard) &#123; handleEventWithGuard(receiveTime); &#125; &#125; else &#123; handleEventWithGuard(receiveTime); &#125;&#125;void Channel::handleEventWithGuard(Timestamp receiveTime)&#123; eventHandling_ = true; LOG_TRACE &lt;&lt; reventsToString(); if ((revents_ &amp; POLLHUP) &amp;&amp; !(revents_ &amp; POLLIN)) &#123; if (logHup_) &#123; LOG_WARN &lt;&lt; "fd = " &lt;&lt; fd_ &lt;&lt; " Channel::handle_event() POLLHUP"; &#125; if (closeCallback_) closeCallback_(); &#125; if (revents_ &amp; POLLNVAL) &#123; LOG_WARN &lt;&lt; "fd = " &lt;&lt; fd_ &lt;&lt; " Channel::handle_event() POLLNVAL"; &#125; if (revents_ &amp; (POLLERR | POLLNVAL)) &#123; if (errorCallback_) errorCallback_(); &#125; if (revents_ &amp; (POLLIN | POLLPRI | POLLRDHUP)) &#123; if (readCallback_) readCallback_(receiveTime); &#125; if (revents_ &amp; POLLOUT) &#123; if (writeCallback_) writeCallback_(); &#125; eventHandling_ = false;&#125;]]></content>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Buffer]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Buffer%2F</url>
    <content type="text"><![CDATA[实现原理在muduo之中，使用std::vector来存放网络中传输的数据，包括从要发送给对方的数据以及从对方接收的数据。在Buffer之中，预留了 prependable 的缓存，可以在buffer之中加入前缀而无需移动整个buffer。整个buffer分为prependable, readable, writable bytes. Buffer 的布局可以参考下图。 12345678910/// A buffer class modeled after org.jboss.netty.buffer.ChannelBuffer////// @code/// +-------------------+------------------+------------------+/// | prependable bytes | readable bytes | writable bytes |/// | | (CONTENT) | |/// +-------------------+------------------+------------------+/// | | | |/// 0 &lt;= readerIndex &lt;= writerIndex &lt;= size/// @endcode&gt;&gt;&gt; Buffer的作用非常之大，将用户程序从繁琐的Buffer相关读写操作之中解放了出来。 重点在muduo的Buffer之中，对read进行了特殊处理。因为从socket读，会调用read，涉及到一次上下文切换，为了减少系统调用的开销，read的调用次数是越少越好，因而需要尽可能预先分配更大的用户空间缓存。另一方面，如果对于每个连接都分配过多的缓存，那么会造成因为内存容量有限而造成支持的并发连接数目有限的问题。这二者之间存在矛盾。 在muduo之中，使用分配在堆栈上的缓存区域以及readv系统调用，将读取的数据优先存入buffer之中，超过限制才存放在堆栈上分配的缓存之中，最后再统一汇总到buffer之中。离开readFd函数之后，堆栈上分配的读取缓存会被自动回收。具体可以参考以下代码: 123456789101112131415161718192021222324252627282930313233ssize_t Buffer::readFd(int fd, int* savedErrno)&#123; // saved an ioctl()/FIONREAD call to tell how much to read char extrabuf[65536]; struct iovec vec[2]; const size_t writable = writableBytes(); vec[0].iov_base = begin()+writerIndex_; vec[0].iov_len = writable; vec[1].iov_base = extrabuf; vec[1].iov_len = sizeof extrabuf; // when there is enough space in this buffer, don't read into extrabuf. // when extrabuf is used, we read 128k-1 bytes at most. const int iovcnt = (writable &lt; sizeof extrabuf) ? 2 : 1; const ssize_t n = sockets::readv(fd, vec, iovcnt); if (n &lt; 0) &#123; *savedErrno = errno; &#125; else if (implicit_cast&lt;size_t&gt;(n) &lt;= writable) &#123; writerIndex_ += n; &#125; else &#123; writerIndex_ = buffer_.size(); append(extrabuf, n - writable); &#125; // if (n == writable + sizeof extrabuf) // &#123; // goto line_30; // &#125; return n;&#125;]]></content>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[auto关键字]]></title>
    <url>%2F2017%2F06%2F08%2Fauto%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[5. 优先使用auto而非显示类型声明在C++之中，使用auto关键字声明类型可以将程序员从输入繁琐的类型中解放出来，编译器会自动推导出变量的实际类型。 123456789template&lt;typename It&gt;void dwim(It b, It e)&#123; while(b != e)&#123; typename std::iterator_traits&lt;It&gt;::value_type currValue = *b; ... &#125;&#125; 使用auto关键字 12345678template&lt;typename It&gt;void dwim(It b, It e)&#123; while(b != e)&#123; auto currValue = *b; ... &#125;&#125; 在C++14中，lambda函数的参数都可以使用auto来定义。1234auto derefLess = // C++14 comparison [](const auto&amp; p1, // function for const auto&amp; p2) // values pointed &#123; return *p1 &lt; *p2; &#125;; 使用auto生命类型还可以将我们从类型截断的问题中解放出来：12std::vector&lt;int&gt; arrs;auto size = arrs.size(); 在C++中，unordered_map的key的类型是const类型的，所以即便采取如下方式遍历unordered_map容器，仍然会产生临时对象：1234567std::unordered_map&lt;std::string, int&gt; m; ...for (const std::pair&lt;std::string, int&gt;&amp; p : m)&#123; ... // do something with p&#125; 但是借助auto，我们不仅使声明更加简洁，还避开了此问题：1234567std::unordered_map&lt;std::string, int&gt; m; ...for (const auto&amp; p : m)&#123; ... // do something with p&#125; 6. 当auto推导出非预期类型时应当使用显示的类型初始化在C++中，因为标准不允许返回对bit的引用，所以对于vector&lt;bool&gt;标准库进行了特化处理，其[]运算符返回的是std::vector&lt;bool&gt;::reference类型的临时对象。对临时对象的修改会被其同步到vector中，因而这样使用auto关键字是不合规的。12345Widget w;…auto highPriority = features(w)[5]; // w是不是个高优先级的？…processWidget(w, highPriority); // 配合优先级处理w 在这种情况下，我们只需显示指出highPriority的类型为bool即可规避此问题。]]></content>
      <tags>
        <tag>modern effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++类型推导]]></title>
    <url>%2F2017%2F06%2F08%2FC%2B%2B%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[1. 理解模板类型推导1. expr是T&amp;123456template&lt;typename T&gt;void f(T &amp; param);// 我们声明如下变量int x = 27;const int cx = x;const int&amp; rx = x; 函数调用时，推导出的Param和T的类型如下： 123f(x); // T is int, param's type is int&amp;f(cx); // T is const int, param's type is const int&amp;f(rx); // T is const int, param's type is const int&amp; 需要特别注明的是，通过T&amp;的方式传入数组，数组的大小信息不会丢失。 1234template&lt;typename T&gt;void f(T&amp; param);const int arr[10];f(arr); // T is const int[10], param type is const int(&amp;)[10] 在类型推导期间，数组和函数将退化为指针类型，除非他们是被初始化为引用。 2. expr是const T&amp;123456template&lt;typename T&gt;void f(const T&amp; param);int x = 27;const int cx = x;const int&amp; rx = x; 在进行类型推导的时候，rx的引用性被忽略了。 123f(x); // T is int, param's type is const int&amp;f(cx); // T is int, param's type is const int&amp;f(rx); // T is int, param's type is const int&amp; 3. param是一个指针类型1234567template&lt;typename T&gt;void f(T* param); // param is now a pointerint x = 27;const int* px = &amp;x;f(&amp;x); // T is int, param's type is int *f(px); // T is const int, param's type is const int * 4. param是universial reference1234567891011template&lt;typename T&gt;void f(T&amp;&amp; param); // param is now a universal referenceint x = 27;const int cx = x;const int&amp; rx = x;f(x); // x is lvalue, so T is int&amp;, param's type is also int&amp;f(cx); // cx is lvalue, so T is const int&amp;, param's type is also const int&amp;f(rx); // rx is lvalue, so T is const int&amp;, param's type is also const int&amp;f(27); // 27 is rvalue, so T is int, param's typs is int&amp;&amp; 5. param 既不是指针也不是引用12template&lt;typename T&gt;void f(T param); 当ParamType既不是指针也不是引用的时候，我们按照值传递的方式进行处理。需要举出一个有用的例子：1234template&lt;typename T&gt;void f(T param);const char* const ptr = "hello world\n";f(ptr); // param's type is const char* 2. 理解auto自动类型推导auto 类型对象推导通常和模板类型推导是相同的。例子：123456const char name[] = "zhouyang";auto arr1 = name; // arr1's type is const char*auto&amp; arr2 = name; // arr2's type is const char(&amp;)[9]void someFunc(int, double); // someFunc is a functionauto func1 = someFunc; // func1's type is void(*)(int, double)auto&amp; func2 = someFunc; // func2's type is void(&amp;)(int, double) 唯一的例外是：使用auto和大括号进行初始化时，自动推导为std::initializer_list。并且，对于使用括号进行的初始化，模板类型推导会失败。 3. 理解decltypedecltype 一般情况下总是返回变量名或者表达式的类型而不做任何的修改。123const int i = 0; // decltype(i) is const intbool f(const Widget&amp; w) // decltype(w) is const Widget&amp;Widget W; // decltype(w) is Widget 在C++14中，提供了decltype(auto)的支持，它从初始化式子中推导类型，使用的是decltype的推导规则。123456Widget w;cosnt Widget&amp; cw = w;auto myWidget1 = cw; // myWidget1's type is Widgetdecltype(auto) myWidget2 = cw; // decltype type deduction: // myWidget2's type is const Widget&amp;// 注：可以在模板中使用 特例:12345678910111213#include &lt;iostream&gt;using namespace std;int main()&#123; int temp = 10; decltype((temp)) temp1 = temp; // temp1's type is int&amp; temp1 = 1; cout&lt;&lt; temp &lt;&lt; endl; return 0;&#125;//输出 : 1 4. 了解如何查看推导出的类型可以利用编译器诊断来完成。我们想要知道被推导出的类型，可以首先声明一个类模板，但是不定义它。那么编译器的出错信息会包含推导的类型信息。12template&lt;typename T&gt;class TD; 通过编译器内置的宏定义，可以输出函数类型1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void test_func(int)&#123;#if defined(__GNUC__) cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; endl;#elif defined(_MSC_VER) cout &lt;&lt; __FUNCSIG__ &lt;&lt; endl;#endif&#125;int main()&#123; test_func(10); return 0;&#125;]]></content>
      <tags>
        <tag>modern effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Acceptor]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Acceptor%2F</url>
    <content type="text"><![CDATA[运行流程Acceptr是muduo之中TcpServer用于接受连接的wrapper类。其中有一个成员acceptChannel_用于接受连接。其句柄是用于接受连接的socket fd。 上述acceptChannel_关注的是可读事件，可读代表有新的连接可以accept了。在关注可读事件之前需要首先开始监听。监听的backlog的限制采用的是Linux所支持的最大值: SOMAXCONN. 特殊处理在接受连接的时候，可能会出现这种问题：描述符用完了，这会导致accpet失败，并且返回ENFILE错误。但是并没有拒绝这一连接，连接仍然会在连接队列之中，这导致了下一次eventLoop中仍然会触发监听描述符的可读事件，这会导致busy loop。 一种比较简单的解决方式是程序遇到这个问题，直接忽略，直到这种情况消失，但是这种解决方式会导致busy waiting。 另一种解决思路是记录除了EAGAIN或者EWOULDBLOCK其他任何错误，告诉用户出现了某种错误，并且停止监听描述符的可读事件，减少CPU的使用。 在libevent中，采用的是如下解决方式。首先打开/dev/null, 保留一个文件描述符，当accept出现ENFILE或者EMFILE错误的时候，关闭/dev/null，然后再次accept，并且close掉accept产生的fd，再次打开/dev/null，这是一种比较优雅的方式来拒绝客户端的连接。 最后一种比较sb的方式是遇到accept的这种错误，直接拒绝并且退出。这种方式比较容易受到Dos攻击。 12345678910111213141516171819202122232425262728293031323334void Acceptor::handleRead()&#123; loop_-&gt;assertInLoopThread(); InetAddress peerAddr; //FIXME loop until no more int connfd = acceptSocket_.accept(&amp;peerAddr); if (connfd &gt;= 0) &#123; // string hostport = peerAddr.toIpPort(); // LOG_TRACE &lt;&lt; "Accepts of " &lt;&lt; hostport; if (newConnectionCallback_) &#123; newConnectionCallback_(connfd, peerAddr); &#125; else &#123; sockets::close(connfd); &#125; &#125; else &#123; LOG_SYSERR &lt;&lt; "in Acceptor::handleRead"; // Read the section named "The special problem of // accept()ing when you can't" in libev's doc. // By Marc Lehmann, author of libev. if (errno == EMFILE) &#123; ::close(idleFd_); idleFd_ = ::accept(acceptSocket_.fd(), NULL, NULL); ::close(idleFd_); idleFd_ = ::open("/dev/null", O_RDONLY | O_CLOEXEC); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>