<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[leveldb bloom filter]]></title>
    <url>%2F2017%2F06%2F13%2Fleveldb-bloom-filter%2F</url>
    <content type="text"><![CDATA[bloom过滤器在1970年由布隆提出。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于快速检索一个元素是否在一个集合中。使用布隆过滤器能够确定某个元素不在集合之中，但是布隆过滤器可能会误报，将本来不在集合中的元素归类为在集合之中的元素。 在leveldb的布隆过滤器，需要指定每个key需要的向量位数，如下所示： 12345678910explicit BloomFilterPolicy(int bits_per_key) : bits_per_key_(bits_per_key)&#123; // we intentionally round down to reduce probing cost a little bit k_ = static_cast&lt;size_t&gt;(bits_per_key * 0.69); // 0.69 =~ ln(2) if (k_ &lt; 1) k_ = 1; if (k_ &gt; 30) k_ = 30;&#125; leveldb 会在向量的最后记录k_的值,k_代表每个key需要设置hash位的次数。 对于创建filter，leveldb会根据key的个数和bits_per_key_设置计算总共需要的二进制位数，将其向上取整到byte为单位，并且最小为8byte。对于每个key，重复设置k_次对应bit位，每次hash值加上delta const uint32_t delta = (h &gt;&gt; 17) | (h &lt;&lt; 15); 123456789101112131415161718192021222324252627282930313233343536virtual void CreateFilter(const Slice *keys, int n, std::string *dst) const&#123; // compute bloom filter size (in both bits and bytes) size_t bits = n * bits_per_key_; // for small n, we can see a very high false positive rate. Fix it by enforcing // a minimum bloom filter length. if (bits &lt; 64) bits = 64; size_t bytes = (bits + 7) / 8; bits = bytes * 8; const size_t init_size = dst-&gt;size(); dst-&gt;resize(init_size + bytes, 0); dst-&gt;push_back(static_cast&lt;char&gt;(k_)); // remember # of probes in filter // 因为采用的是push_back, 所以现在dst的实际大小为 init_size + 1 + bytes // 最后一个byte用于存放k_ char *array = &amp;(*dst)[init_size]; for (int i = 0; i &lt; n; ++i) &#123; // use double-hashing to generate a sequence of hash values. // se analysis in [Kirsch,Mitzenmacher 2006]. uint32_t h = BloomHash(keys[i]); const uint32_t delta = (h &gt;&gt; 17) | (h &lt;&lt; 15); // rotate right 17 bits for (size_t j = 0; j &lt; k_; j++) &#123; const uint32_t bitpos = h % bits; // 设置对应位 array[bitpos/8] |= (1 &lt;&lt; (bitpos % 8)); // h+= delta h += delta; &#125; &#125;&#125; 至于KeyMayMatch操作，就是对于给定key，首先拿到k_的值，然后进行k_次比较，比较每次计算得出的hash值对应的向量位是否设置为1，若k_次比较完毕之后，对应bit都设置为1，那么有理由相信这个key符合要求，否则，此key一定不在bloom集合之中。这里对k_做了特殊处理，对于k_大于30的情况，统一认定为符合filter，这是保留用途。 1234567891011121314151617181920212223242526virtual bool KeyMayMatch(const Slice&amp; key, const Slice&amp; bloom_filter) const &#123; const size_t len = bloom_filter.size(); if (len &lt; 2) return false; const char* array = bloom_filter.data(); const size_t bits = (len - 1) * 8; // use the encoded k so that we can read filters generated by bloom filters created using different parameters. const size_t k = array[len - 1]; if (k &gt; 30) &#123; // reserved for potentially new encodings for short bloom filters. // consider it a match return true; &#125; uint32_t h = BloomHash(key); const uint32_t delta = (h &gt;&gt; 17) | (h &lt;&lt; 15); for(size_t j = 0; j &lt; k; j++) &#123; const uint32_t bitpos = h % bits; if((array[bitpos/8] &amp; (1 &lt;&lt; (bitpos %8))) == 0) return false; h += delta; &#125; return true; &#125; 求hash值的操作实际上是对hash操作的简单封装，指定seed为0xbc9f1d34。 1234static uint32_t BloomHash(const Slice &amp;key)&#123; return Hash(key.data(), key.size(), 0xbc9f1d34);&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb Arena内存分配器]]></title>
    <url>%2F2017%2F06%2F13%2Fleveldb-Arena%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%2F</url>
    <content type="text"><![CDATA[leveldb使用vector存放使用malloc分配的内存。在析构的时候，对这些分配的内存统一进行释放。 在分配内存时，首先判断上一个剩余块空间是否足够，足够就直接从剩余空间之中分配内存，否则调用AllocateFallback, 分配一块的新的内存。 123456789101112inline char* Arena::Allocate(size_t bytes)&#123; assert(bytes &gt; 0); if(bytes &lt;= alloc_bytes_remaining_) &#123; char* result = alloc_ptr_; alloc_ptr_ += bytes; alloc_bytes_remaining_ -= bytes; return result; &#125; return AllocateFallback(bytes);&#125; 在分配新的内存时，判断要分配的内存是否大于分配内存块大小kBlockSize的1/4，若大于，直接分配此大小的内存。否则分配一块kBlockSize大小的内存，从此内存块之中分配需要的内存，记录当前块剩余空间，以便下次内存分配能够利用剩余的空间。 123456789101112131415161718char* Arena::AllocateFallback(size_t bytes)&#123; if(bytes &gt; kBlockSize / 4) &#123; // object is more than a quarter of our block size. Allocate it separately to // avoid wasting too much space in leftover bytes. char* result = AllocateNewBlock(bytes); return result; &#125; // we waste the remaining space in the current block alloc_ptr_ = AllocateNewBlock(kBlockSize); alloc_bytes_remaining_ = kBlockSize; char* result = alloc_ptr_; alloc_ptr_ += bytes; alloc_bytes_remaining_ -= bytes; return result;&#125; 还有一种需求是分配的内存需要对齐，这需要保证分配的内存地址能够整除8（64位cpu），所以可能需要跳过一段内存区域，返回对齐的地址空间。 1234567891011121314151617181920212223char* Arena::AllocateAligned(size_t bytes)&#123; const int align = (sizeof(void*) &gt; 8) ? sizeof(void*) : 8; assert((align &amp; (align - 1)) == 0); // pointer size should be a power of 2 size_t current_mod = reinterpret_cast&lt;uintptr_t&gt;(alloc_ptr_) &amp; (align - 1); size_t slop = (current_mod == 0 ? 0 : align - current_mod); size_t needed = bytes + slop; char* result; if(needed &lt;= alloc_bytes_remaining_) &#123; result = alloc_ptr_ + slop; alloc_ptr_ += needed; alloc_bytes_remaining_ -= needed; &#125; else &#123; // AllocateFallback always returned aligned memory result = AllocateFallback(bytes); &#125; assert((reinterpret_cast&lt;uintptr_t&gt;(result) &amp; (align - 1)) == 0); return result;&#125; 至于分配块内存，是直接调用new运算符来分配，其实质是利用malloc。在此过程中还记录了内存空间的总用量，注意要包括vector中记录内存地址占用的内存大小。 12345678char* Arena::AllocateNewBlock(size_t block_bytes)&#123; char* result = new char[block_bytes]; blocks_.push_back(result); // also add pointer size at blocks_ memory_usage_.NoBarrier_Store(reinterpret_cast&lt;void*&gt;(MemoryUsage() + block_bytes + sizeof(char*))); return result;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb测试夹具]]></title>
    <url>%2F2017%2F06%2F13%2Fleveldb%E6%B5%8B%E8%AF%95%E5%A4%B9%E5%85%B7%2F</url>
    <content type="text"><![CDATA[一直以来，都想实现一个简单的单元测试工具，从根本上理解单元测试框架的实现原理。今天看了leveldb中的源码testharness.cc，感觉已经彻底理解了。 核心技术和log实现一样，实现单元测试框架的核心是要用好宏。如果对宏没有清晰的认知，恐怕连相关的代码都无法理解。 以下主要补充说明#和##在宏中的作用：1#define WARN_IF(EXP) do &#123; if(EXP) fprintf(stderr, "Warning! "#EXP"\n"); &#125; while(0) #对他后面的变量左右添加双引号，所以上述宏定义之中可以将表达式转换为字符串输出。 1#define CONCAT(X, Y) X##Y ##则用于连接两个变量。上述宏定义是一个简单的连接操作。 断言的实现断言的实现是基于类Tester完成的，类成员中由std::stringstream ss_ 来记录输出的错误信息。如果Tester中的用于测试的成员函数出错了，会记录状态为出错，这样在析构的时候就会将ss_的错误信息输出到stderr之中, 并且调用exit退出。 为了避免重复输入内容完全一样，仅仅名称和比较运算符不同的测试函数，在这里使用了宏定义进行简化。1234567891011121314151617#define BINARY_OP(name,op) \ template &lt;class X, class Y&gt; \ Tester&amp; name(const X&amp; x, const Y&amp; y) &#123; \ if (! (x op y)) &#123; \ ss_ &lt;&lt; " failed: " &lt;&lt; x &lt;&lt; (" " #op " ") &lt;&lt; y; \ ok_ = false; \ &#125; \ return *this; \ &#125; BINARY_OP(IsEq, ==) BINARY_OP(IsNe, !=) BINARY_OP(IsGe, &gt;=) BINARY_OP(IsGt, &gt;) BINARY_OP(IsLe, &lt;=) BINARY_OP(IsLt, &lt;)#undef BINARY_OP 对于后续不再使用的宏定义要及时将其undef，这里符合了google的编程规范。 通过代码可以发现，对于ASSERT_TRUE, ASSERT_OK, ASSERT_EQ, ASSERT_NE的调用原理实际上是创建一个Tester临时成员，并且立即调用对应的比较函数。这样若检查失败，那么临时对象在析构的时候会输出错误信息，并且程序终止运行。 增加测试案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// testharness.h#define TCONCAT(a,b) TCONCAT1(a,b)#define TCONCAT1(a,b) a##b#define TEST(base,name) \class TCONCAT(_Test_,name) : public base &#123; \ public: \ void _Run(); \ static void _RunIt() &#123; \ TCONCAT(_Test_,name) t; \ t._Run(); \ &#125; \&#125;; \bool TCONCAT(_Test_ignored_,name) = \ ::leveldb::test::RegisterTest(#base, #name, &amp;TCONCAT(_Test_,name)::_RunIt); \void TCONCAT(_Test_,name)::_Run()// Register the specified test. Typically not used directly, but// invoked via the macro expansion of TEST.extern bool RegisterTest(const char* base, const char* name, void (*func)());//testharness.ccstruct Test &#123; const char* base; const char* name; void (*func)();&#125;;std::vector&lt;Test&gt;* tests;&#125;bool RegisterTest(const char* base, const char* name, void (*func)()) &#123; if (tests == NULL) &#123; tests = new std::vector&lt;Test&gt;; &#125; Test t; t.base = base; t.name = name; t.func = func; tests-&gt;push_back(t); return true;&#125;int RunAllTests() &#123; const char* matcher = getenv("LEVELDB_TESTS"); int num = 0; if (tests != NULL) &#123; for (size_t i = 0; i &lt; tests-&gt;size(); i++) &#123; const Test&amp; t = (*tests)[i]; if (matcher != NULL) &#123; std::string name = t.base; name.push_back('.'); name.append(t.name); if (strstr(name.c_str(), matcher) == NULL) &#123; continue; &#125; &#125; fprintf(stderr, "==== Test %s.%s\n", t.base, t.name); (*t.func)(); ++num; &#125; &#125; fprintf(stderr, "==== PASSED %d tests\n", num); return 0;&#125; 在leveldb中，每个测试案例对应一个struct test实例，其成员包括base(基础名称), name, 以及一个无参的void类型函数。测试所有案例就是依次调用所有案例的测试函数。 以下代码演示了测试的具体使用方法： 1234567891011121314151617181920// 有删减#include "util/crc32c.h"#include "util/testharness.h"namespace leveldb &#123;namespace crc32c &#123;class CRC &#123; &#125;;TEST(CRC, StandardResults) &#123; // From rfc3720 section B.4. char buf[32]; memset(buf, 0, sizeof(buf));&#125;&#125;&#125;int main(int argc, char** argv) &#123; return leveldb::test::RunAllTests();&#125; 拆解前述代码的宏定义，可以发现，每次调用依次test就是定义一个与之相关的class，宏定义将具体的Run_实现交给用户进行。宏定义TEST中已经将此类的static成员函数定义好了，此成员函数是创建一个此类的对象，并且调用其Run_方法。这样只需将此类的static函数作为struct Test中的函数指针指向的函数，在进行测试的时候，调用此静态函数就会调用用户定义的测试方法。虽然过程比较百转千折，但是实现非常精妙！]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MergingIterator和TwoLevelIterator]]></title>
    <url>%2F2017%2F06%2F13%2FMergingIterator%E5%92%8CTwoLevelIterator%2F</url>
    <content type="text"><![CDATA[MergingIterator概述MergingIterator的存在能够将多个iterator对应的数据结合起来，统一成一个iterator对外提供服务。迭代器的先后顺序仍然表示数据的大小关系，但是MegingIterator并不会对输入的迭代器进行去重处理。 通过构造函数可以发现，若没有输入任何迭代器，则返回一个empty iterator；若只输入了一个迭代器，则返回这个迭代器；在其他情况下才会创建MergingIterator对象。 1234567891011// 输入0，返回空的iterator，1，返回本身，n返回合并iteratorIterator* NewMergingIterator(const Comparator* cmp, Iterator** list, int n) &#123; assert(n &gt;= 0); if (n == 0) &#123; return NewEmptyIterator(); &#125; else if (n == 1) &#123; return list[0]; &#125; else &#123; return new MergingIterator(cmp, list, n); &#125;&#125; 实现解析SeekToFirst，SeekToLast 和 Seek先从简单的讲起，SeekToFirst操作对所有输入的迭代器执行SeekToFirst操作，然后找到其中最小的一个就是第一个迭代器，并且记录迭代器前进方向为kForward。SeekToLast实现同理。 12345678910111213141516171819virtual void SeekToFirst() &#123; for (int i = 0; i &lt; n_; i++) &#123; children_[i].SeekToFirst(); &#125; // 找到最小的 FindSmallest(); // 方向是前进 direction_ = kForward; &#125; virtual void SeekToLast() &#123; for (int i = 0; i &lt; n_; i++) &#123; children_[i].SeekToLast(); &#125; // 找到最大的 FindLargest(); // 方向是后退 direction_ = kReverse; &#125; Seek操作是对所有输入的迭代器统一执行Seek操作，找到其中最小的迭代器返回。 123456789virtual void Seek(const Slice&amp; target) &#123; for (int i = 0; i &lt; n_; i++) &#123; children_[i].Seek(target); &#125; // 找到最小的 FindSmallest(); // 方向是前进 direction_ = kForward; &#125; FindSmallest函数遍历所有输入的迭代器，记录key最小的迭代器为current_;FindLargest遍历所有输入的迭代器，记录key最大的迭代器为current_。 123456789101112131415161718192021222324252627282930// 简单的O(n)遍历查找void MergingIterator::FindSmallest() &#123; IteratorWrapper* smallest = NULL; for (int i = 0; i &lt; n_; i++) &#123; IteratorWrapper* child = &amp;children_[i]; if (child-&gt;Valid()) &#123; if (smallest == NULL) &#123; smallest = child; &#125; else if (comparator_-&gt;Compare(child-&gt;key(), smallest-&gt;key()) &lt; 0) &#123; smallest = child; &#125; &#125; &#125; current_ = smallest;&#125;void MergingIterator::FindLargest() &#123; IteratorWrapper* largest = NULL; for (int i = n_-1; i &gt;= 0; i--) &#123; IteratorWrapper* child = &amp;children_[i]; if (child-&gt;Valid()) &#123; if (largest == NULL) &#123; largest = child; &#125; else if (comparator_-&gt;Compare(child-&gt;key(), largest-&gt;key()) &gt; 0) &#123; largest = child; &#125; &#125; &#125; current_ = largest;&#125; Prev 和 NextPrev操作是找到从左边最接近当前key的迭代器位置。若当前迭代器的遍历方向是kReverse，那么children_记录的除了current_之外的迭代器都current_小。因而其他迭代器都不用移动，只需current_向前移动一位，这样所有迭代器都比当前位置的key小，其中最大的就是最接近当前位置的迭代器。 在其他情况下，就要对其他迭代器先执行Seek(key())操作，再执行Prev操作，移动到刚好小于当前key的位置。对于当前迭代器仍然只执行Prev操作。这样所有迭代器都是刚好比key小的位置，其中最大的就是最接近当前位置的迭代器。 123456789101112131415161718192021222324252627282930virtual void Prev() &#123; assert(Valid()); /// Ensure that all children are positioned before key(). /// reverse 情况下，其他child的key都比current小 // If we are moving in the reverse direction, it is already // true for all of the non-current_ children since current_ is // the largest child and key() == current_-&gt;key(). Otherwise, // we explicitly position the non-current_ children. if (direction_ != kReverse) &#123; for (int i = 0; i &lt; n_; i++) &#123; IteratorWrapper* child = &amp;children_[i]; if (child != current_) &#123; child-&gt;Seek(key()); if (child-&gt;Valid()) &#123; // Child is at first entry &gt;= key(). Step back one to be &lt; key() child-&gt;Prev(); &#125; else &#123; // Child has no entries &gt;= key(). Position at last entry. child-&gt;SeekToLast(); &#125; &#125; &#125; direction_ = kReverse; &#125; current_-&gt;Prev(); // 找其中最大的 FindLargest(); &#125; Next的实现方式同理，下面仅列出代码： 12345678910111213141516171819202122232425262728virtual void Next() &#123; assert(Valid()); /// Ensure that all children are positioned after key(). /// forward 情况下，其他child的key都比current大 // If we are moving in the forward direction, it is already // true for all of the non-current_ children since current_ is // the smallest child and key() == current_-&gt;key(). Otherwise, // we explicitly position the non-current_ children. if (direction_ != kForward) &#123; for (int i = 0; i &lt; n_; i++) &#123; IteratorWrapper* child = &amp;children_[i]; if (child != current_) &#123; child-&gt;Seek(key()); if (child-&gt;Valid() &amp;&amp; comparator_-&gt;Compare(key(), child-&gt;key()) == 0) &#123; // child指向比key()大的位置 child-&gt;Next(); &#125; &#125; &#125; direction_ = kForward; &#125; // current指向下一位 current_-&gt;Next(); // 找其中最小的 FindSmallest(); &#125; TwoLevelIterator概述TwoLevelIterator输入Index block 对应的iterator，以及输入的BlockReader函数，将index iterator所管理的数据块整合成为一个iterator，对外提供数据服务。 初始化data iterator初始化data iterator的操作很简单，获取index_iter_当前位置的值作为block handle来初始化data iterator。在此过程中会记录此handle的值。若data_iter_不为空，且handle与记录的值不变，则不会重新初始化data_iter_。 12345678910111213141516171819202122232425// initialize data iteratorvoid TwoLevelIterator::InitDataBlock() &#123; if (!index_iter_.Valid()) &#123; SetDataIterator(NULL); &#125; else &#123; Slice handle = index_iter_.value(); if (data_iter_.iter() != NULL &amp;&amp; handle.compare(data_block_handle_) == 0) &#123; // data_iter_ is already constructed with this iterator, so // no need to change anything &#125; else &#123; // 获取data iter Iterator* iter = (*block_function_)(arg_, options_, handle); // 保存创建data_iter的handle信息 data_block_handle_.assign(handle.data(), handle.size()); // 设置data iterator SetDataIterator(iter); &#125; &#125;&#125;// 设置data itervoid TwoLevelIterator::SetDataIterator(Iterator* data_iter) &#123; if (data_iter_.iter() != NULL) SaveError(data_iter_.status()); data_iter_.Set(data_iter);&#125; iterator的Seek相关操作iterator的Seek相关操作也非常简单，首先根据不同的Seek操作对index_iter_进行相应的移动，根据当前index_iter_的值初始化data_iter_，再移动到正确的位置上。 1234567891011121314151617181920void TwoLevelIterator::Seek(const Slice&amp; target) &#123; index_iter_.Seek(target); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.Seek(target); SkipEmptyDataBlocksForward();&#125;void TwoLevelIterator::SeekToFirst() &#123; index_iter_.SeekToFirst(); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.SeekToFirst(); SkipEmptyDataBlocksForward();&#125;void TwoLevelIterator::SeekToLast() &#123; index_iter_.SeekToLast(); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.SeekToLast(); SkipEmptyDataBlocksBackward();&#125; 向前后移动以及Skip操作data_iter_在移动过程中，有可能因为已经遍历过数据块的最后一条record，data_iter_需要继续移动，指向下一个数据块，而且index_iter_也可能指向空的数据块。对于这些情况，都需要跳过一些数据块，即如下代码所示： 123456789101112131415161718192021222324252627// 向前跳过空的data_iter_void TwoLevelIterator::SkipEmptyDataBlocksForward() &#123; while (data_iter_.iter() == NULL || !data_iter_.Valid()) &#123; // Move to next block if (!index_iter_.Valid()) &#123; SetDataIterator(NULL); return; &#125; index_iter_.Next(); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.SeekToFirst(); &#125;&#125;// 向后跳过空的data_iter_void TwoLevelIterator::SkipEmptyDataBlocksBackward() &#123; while (data_iter_.iter() == NULL || !data_iter_.Valid()) &#123; // Move to next block if (!index_iter_.Valid()) &#123; SetDataIterator(NULL); return; &#125; index_iter_.Prev(); InitDataBlock(); if (data_iter_.iter() != NULL) data_iter_.SeekToLast(); &#125;&#125; 在上述基础上，Prev和Next操作只需要在移动data_iter_移动之后，进行相应的跳空处理即可。 1234567891011void TwoLevelIterator::Next() &#123; assert(Valid()); data_iter_.Next(); SkipEmptyDataBlocksForward();&#125;void TwoLevelIterator::Prev() &#123; assert(Valid()); data_iter_.Prev(); SkipEmptyDataBlocksBackward();&#125; 至此，leveldb table路径下所有代码分析完毕，下面转入db路径，深入到leveldb的实际建构之中。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb sstable 读取解析]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-sstable-%E8%AF%BB%E5%8F%96%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[leveldb sstable 读取解析结构化数据的读取比写入实现起来更为复杂，levledb中的sstable读取又一次说明了这一点。sstable的读取操作定义在table.h和table.cc之中。在这一节代码中主要实现了sstable的打开操作，以及如何从index handle得到对应block 的interator。 Opensstable的打开先从footer开始，校验是否是sstable文件。读取meta_block index 和 index block handle。若无误，则根据footer中的信息来创建Rep对象。请注意，这里生成了cache_id，cache_id是采用全局递增的算法产生的，在整个系统中独一无二，后续会在cache之中使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758Status Table::Open(const Options&amp; options, RandomAccessFile* file, uint64_t size, Table** table) &#123; *table = NULL; // sstable的文件大小需要大于Footer if (size &lt; Footer::kEncodedLength) &#123; return Status::Corruption("file is too short to be an sstable"); &#125; char footer_space[Footer::kEncodedLength]; Slice footer_input; // 读取footer Status s = file-&gt;Read(size - Footer::kEncodedLength, Footer::kEncodedLength, &amp;footer_input, footer_space); if (!s.ok()) return s; Footer footer; // decode from footer Slice s = footer.DecodeFrom(&amp;footer_input); if (!s.ok()) return s; // Read the index block BlockContents contents; Block* index_block = NULL; if (s.ok()) &#123; ReadOptions opt; // 如果设置了paranoid_checks, 那么需要检查校验码 if (options.paranoid_checks) &#123; opt.verify_checksums = true; &#125; // 读取index block s = ReadBlock(file, opt, footer.index_handle(), &amp;contents); if (s.ok()) &#123; index_block = new Block(contents); &#125; &#125; if (s.ok()) &#123; // We've successfully read the footer and the index block: we're // ready to serve requests. Rep* rep = new Table::Rep; rep-&gt;options = options; rep-&gt;file = file; rep-&gt;metaindex_handle = footer.metaindex_handle(); rep-&gt;index_block = index_block; rep-&gt;cache_id = (options.block_cache ? options.block_cache-&gt;NewId() : 0); rep-&gt;filter_data = NULL; rep-&gt;filter = NULL; *table = new Table(rep); // 读取meta 元数据 (*table)-&gt;ReadMeta(footer); &#125; else &#123; delete index_block; &#125; return s;&#125; 读取meta block会首先查找有没有filter block handle，若有的话读取filter block，创建FilterBlockReader成员。 123456789101112131415161718192021222324252627282930void Table::ReadMeta(const Footer&amp; footer) &#123; // 没有设置filter_policy, return if (rep_-&gt;options.filter_policy == NULL || footer.metaindex_handle().size() == 0) &#123; return; // Do not need any metadata &#125; ReadOptions opt; if (rep_-&gt;options.paranoid_checks) &#123; opt.verify_checksums = true; &#125; BlockContents contents; if (!ReadBlock(rep_-&gt;file, opt, footer.metaindex_handle(), &amp;contents).ok()) &#123; // Do not propagate errors since meta info is not needed for operation return; &#125; // meta index block Block* meta = new Block(contents); Iterator* iter = meta-&gt;NewIterator(BytewiseComparator()); std::string key = "filter."; key.append(rep_-&gt;options.filter_policy-&gt;Name()); // 查找filter 策略对应的filter index block iter-&gt;Seek(key); if (iter-&gt;Valid() &amp;&amp; iter-&gt;key() == Slice(key)) &#123; ReadFilter(iter-&gt;value()); &#125; delete iter; delete meta;&#125; 1234567891011121314151617181920212223void Table::ReadFilter(const Slice&amp; filter_handle_value) &#123; Slice v = filter_handle_value; BlockHandle filter_handle; if (!filter_handle.DecodeFrom(&amp;v).ok()) &#123; return; &#125; // We might want to unify with ReadBlock() if we start // requiring checksum verification in Table::Open. ReadOptions opt; if (rep_-&gt;options.paranoid_checks) &#123; opt.verify_checksums = true; &#125; BlockContents block; if (!ReadBlock(rep_-&gt;file, opt, filter_handle, &amp;block).ok()) &#123; return; &#125; if (block.heap_allocated) &#123; rep_-&gt;filter_data = block.data.data(); // Will need to delete later &#125; // 创建filter rep_-&gt;filter = new FilterBlockReader(rep_-&gt;options.filter_policy, block.data);&#125; BlockReaderBlockReader函数根据index_value指定的handle信息，首先尝试从cache中查找block。查找的key是cache_id以及块偏移的组合键。找不到就直接从文件之中读取。根据读取的块创建这个数据块上的iterator。如果是从文件中读取的数据块，在iterator析构的时候，需要将数据块释放给内存；如果是从cache中读取的数据块，在iterator被析构时，需要进行release。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Convert an index iterator value (i.e., an encoded BlockHandle)// into an iterator over the contents of the corresponding block.Iterator* Table::BlockReader(void* arg, const ReadOptions&amp; options, const Slice&amp; index_value) &#123; Table* table = reinterpret_cast&lt;Table*&gt;(arg); Cache* block_cache = table-&gt;rep_-&gt;options.block_cache; Block* block = NULL; Cache::Handle* cache_handle = NULL; BlockHandle handle; Slice input = index_value; // decode block handle from input Status s = handle.DecodeFrom(&amp;input); // We intentionally allow extra stuff in index_value so that we // can add more features in the future. if (s.ok()) &#123; BlockContents contents; if (block_cache != NULL) &#123; char cache_key_buffer[16]; // cache_id + handle.offset -&gt; key EncodeFixed64(cache_key_buffer, table-&gt;rep_-&gt;cache_id); EncodeFixed64(cache_key_buffer+8, handle.offset()); Slice key(cache_key_buffer, sizeof(cache_key_buffer)); cache_handle = block_cache-&gt;Lookup(key); if (cache_handle != NULL) &#123; // 尝试从缓存之中获取handle对应的block block = reinterpret_cast&lt;Block*&gt;(block_cache-&gt;Value(cache_handle)); &#125; else &#123; // 直接从文件之中读取 s = ReadBlock(table-&gt;rep_-&gt;file, options, handle, &amp;contents); if (s.ok()) &#123; block = new Block(contents); // 缓存it if (contents.cachable &amp;&amp; options.fill_cache) &#123; cache_handle = block_cache-&gt;Insert( key, block, block-&gt;size(), &amp;DeleteCachedBlock); &#125; &#125; &#125; &#125; else &#123; s = ReadBlock(table-&gt;rep_-&gt;file, options, handle, &amp;contents); if (s.ok()) &#123; block = new Block(contents); &#125; &#125; &#125; Iterator* iter; if (block != NULL) &#123; iter = block-&gt;NewIterator(table-&gt;rep_-&gt;options.comparator); if (cache_handle == NULL) &#123; // 注册cleanup function 为 DeleteBlock iter-&gt;RegisterCleanup(&amp;DeleteBlock, block, NULL); &#125; else &#123; // 注册cleanup function 为ReleaseBlock iter-&gt;RegisterCleanup(&amp;ReleaseBlock, block_cache, cache_handle); &#125; &#125; else &#123; // 否则创建非法的空的iterator iter = NewErrorIterator(s); &#125; return iter;&#125; NewIterator由Table对象返回的Iterator实际上是一个TwoLevelIterator，其具体实现会在后面进行讲解，这个iterator实际上涉及到从index handle到对应data block之间的转换，转换函数就是前面的BlockReader函数。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb table builder 解析]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-table-builder-%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[leveldb table_builder解析在leveldb之中，为了维持接口的简单，不暴露太多的实现细节，大量使用了impl机制，将具体实现定义在内部类之中，table_builder又是一例。 table_builder实际上对应的是sstable的建立过程，包括相关block的存储处理。首先，有必要重温一下sstable文件的具体格式。 成员和构造函数table_builder数据成员如下所示： 12345678910111213141516171819202122232425262728293031Options options;Options index_block_options;WritableFile* file;uint64_t offset;Status status;BlockBuilder data_block;BlockBuilder index_block;std::string last_key;int64_t num_entries;bool closed; // Either Finish() or Abandon() has been called.// FilterBlockFilterBlockBuilder* filter_block;// We do not emit the index entry for a block until we have seen the// first key for the next data block. This allows us to use shorter// keys in the index block. For example, consider a block boundary// between the keys "the quick brown fox" and "the who". We can use// "the r" as the key for the index block entry since it is &gt;= all// entries in the first block and &lt; all entries in subsequent// blocks.//// Invariant: r-&gt;pending_index_entry is true only if data_block is empty.// 是否需要更新index block ?// 若data_block为空，那么pending_index_entry为truebool pending_index_entry;// add 进入 index block 的handleBlockHandle pending_handle; // Handle to add to index block// compressed output// snappy压缩的输出存放地std::string compressed_output; 可见，相关数据成员和sstable文件中的各类型block基本一一对应，其他项用途由注释可知。 在构造函数中，根据输入的参数初始化各成员变量。注意，对于index block，restart间隔被设置为1，也就是每一个record都存储完整的record值。 上面说到的数据成员和构造函数都是内部类Rep的，实际上，TableBuilder通过建立Rep对象，将相关的操作转发给此对象，实现都是在Rep之中。 1234567TableBuilder::TableBuilder(const Options&amp; options, WritableFile* file) : rep_(new Rep(options, file)) &#123; if (rep_-&gt;filter_block != NULL) &#123; // 初始化filter block rep_-&gt;filter_block-&gt;StartBlock(0); &#125;&#125; AddAdd操作是TableBuilder中的重点，占据了大部分篇幅。Add操作也需要保证添加key的顺序是升序。若当前data block为空，将新的data block的handle信息保存在index block之中。请注意，这里对handle的key采用的是比last_key_大，比当前key小的字符串。 若制定了filter_policy，就将这个key加入filter_block，同时记录last_key，更新添加的key的总数，向data block插入这条键值对。若data block的大小超出option限定的值（默认为4K），就调用Flush，将这一数据块写入文件。 123456789101112131415161718192021222324252627282930313233343536373839void TableBuilder::Add(const Slice&amp; key, const Slice&amp; value) &#123; Rep* r = rep_; assert(!r-&gt;closed); if (!ok()) return; // 断言Add的key比之前的更大 if (r-&gt;num_entries &gt; 0) &#123; assert(r-&gt;options.comparator-&gt;Compare(key, Slice(r-&gt;last_key)) &gt; 0); &#125; if (r-&gt;pending_index_entry) &#123; assert(r-&gt;data_block.empty()); // 找到比last_key大，比key小的key，存放在last_key之中 r-&gt;options.comparator-&gt;FindShortestSeparator(&amp;r-&gt;last_key, key); std::string handle_encoding; // 记录第一个data block，保存进入index_block之中 r-&gt;pending_handle.EncodeTo(&amp;handle_encoding); // 在index block之中添加这个block的handle信息 r-&gt;index_block.Add(r-&gt;last_key, Slice(handle_encoding)); r-&gt;pending_index_entry = false; &#125; // 向filter_block之中add key if (r-&gt;filter_block != NULL) &#123; r-&gt;filter_block-&gt;AddKey(key); &#125; // 记录last key r-&gt;last_key.assign(key.data(), key.size()); // 记录add key的总数 r-&gt;num_entries++; // 向data block之中添加这一条记录 r-&gt;data_block.Add(key, value); const size_t estimated_block_size = r-&gt;data_block.CurrentSizeEstimate(); // 若data block的大小超出设定值，Flush 4K if (estimated_block_size &gt;= r-&gt;options.block_size) &#123; Flush(); &#125;&#125; Flush操作如下： 12345678910111213141516171819void TableBuilder::Flush() &#123; Rep* r = rep_; assert(!r-&gt;closed); if (!ok()) return; if (r-&gt;data_block.empty()) return; // data block 不为空 assert(!r-&gt;pending_index_entry); WriteBlock(&amp;r-&gt;data_block, &amp;r-&gt;pending_handle); if (ok()) &#123; // 需要写入新的数据块 r-&gt;pending_index_entry = true; // flush r-&gt;status = r-&gt;file-&gt;Flush(); &#125; // 若filter_block不为空，那么开始对r-&gt;offset段写入滤值 if (r-&gt;filter_block != NULL) &#123; r-&gt;filter_block-&gt;StartBlock(r-&gt;offset); &#125;&#125; Flush首先写入数据块，更新新的数据块对应的handle位置，并且通知filter policy开始对新的offset生成filter。 在WriteBlock中，根据option设定，对data block进行可选的压缩处理。只有当压缩选项被设置，而且压缩可用，压缩减小的空间大小高于12.5%，才会进行压缩。 123456789101112131415161718192021222324252627282930313233343536void TableBuilder::WriteBlock(BlockBuilder* block, BlockHandle* handle) &#123; // File format contains a sequence of blocks where each block has: // block_data: uint8[n] // type: uint8 // crc: uint32 assert(ok()); Rep* r = rep_; Slice raw = block-&gt;Finish(); Slice block_contents; CompressionType type = r-&gt;options.compression; // TODO(postrelease): Support more compression options: zlib? switch (type) &#123; case kNoCompression: block_contents = raw; break; case kSnappyCompression: &#123; std::string* compressed = &amp;r-&gt;compressed_output; // 使用snappy压缩成功，并且压缩的空间大于12.5% if (port::Snappy_Compress(raw.data(), raw.size(), compressed) &amp;&amp; compressed-&gt;size() &lt; raw.size() - (raw.size() / 8u)) &#123; block_contents = *compressed; &#125; else &#123; // Snappy not supported, or compressed less than 12.5%, so just // store uncompressed form block_contents = raw; type = kNoCompression; &#125; break; &#125; &#125; WriteRawBlock(block_contents, type, handle); r-&gt;compressed_output.clear(); block-&gt;Reset();&#125; WriteRawBlock中，还为写入的data block添加了crc校验码以及type信息。 12345678910111213141516171819202122void TableBuilder::WriteRawBlock(const Slice&amp; block_contents, CompressionType type, BlockHandle* handle) &#123; Rep* r = rep_; // 设置offset和size, 其实设置在r-&gt;pending_handle之中 handle-&gt;set_offset(r-&gt;offset); handle-&gt;set_size(block_contents.size()); // 向file中写入block r-&gt;status = r-&gt;file-&gt;Append(block_contents); if (r-&gt;status.ok()) &#123; char trailer[kBlockTrailerSize]; trailer[0] = type; uint32_t crc = crc32c::Value(block_contents.data(), block_contents.size()); crc = crc32c::Extend(crc, trailer, 1); // Extend crc to cover block type EncodeFixed32(trailer+1, crc32c::Mask(crc)); // 写入trailer r-&gt;status = r-&gt;file-&gt;Append(Slice(trailer, kBlockTrailerSize)); if (r-&gt;status.ok()) &#123; r-&gt;offset += block_contents.size() + kBlockTrailerSize; &#125; &#125;&#125; Finish finish操作会将数据块都写入到文件，并且依照sstable文件格式，依次写入filter block，filter index block，index block，footer，完成收尾工作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Status TableBuilder::Finish() &#123; Rep* r = rep_; Flush(); assert(!r-&gt;closed); r-&gt;closed = true; BlockHandle filter_block_handle, metaindex_block_handle, index_block_handle; // Write filter block // 记录filter block 的handle if (ok() &amp;&amp; r-&gt;filter_block != NULL) &#123; WriteRawBlock(r-&gt;filter_block-&gt;Finish(), kNoCompression, &amp;filter_block_handle); &#125; // Write metaindex block if (ok()) &#123; BlockBuilder meta_index_block(&amp;r-&gt;options); if (r-&gt;filter_block != NULL) &#123; // Add mapping from "filter.Name" to location of filter data std::string key = "filter."; key.append(r-&gt;options.filter_policy-&gt;Name()); std::string handle_encoding; filter_block_handle.EncodeTo(&amp;handle_encoding); // 将filter block的信息加入mata_index_block meta_index_block.Add(key, handle_encoding); &#125; // TODO(postrelease): Add stats and other meta blocks WriteBlock(&amp;meta_index_block, &amp;metaindex_block_handle); &#125; // Write index block if (ok()) &#123; if (r-&gt;pending_index_entry) &#123; r-&gt;options.comparator-&gt;FindShortSuccessor(&amp;r-&gt;last_key); std::string handle_encoding; r-&gt;pending_handle.EncodeTo(&amp;handle_encoding); // 添加最后一个data block的handle信息 r-&gt;index_block.Add(r-&gt;last_key, Slice(handle_encoding)); r-&gt;pending_index_entry = false; &#125; // 写入index block WriteBlock(&amp;r-&gt;index_block, &amp;index_block_handle); &#125; // Write footer if (ok()) &#123; Footer footer; footer.set_metaindex_handle(metaindex_block_handle); footer.set_index_handle(index_block_handle); std::string footer_encoding; footer.EncodeTo(&amp;footer_encoding); r-&gt;status = r-&gt;file-&gt;Append(footer_encoding); if (r-&gt;status.ok()) &#123; r-&gt;offset += footer_encoding.size(); &#125; &#125; return r-&gt;status;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb format解析]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-format%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[leveldb format 解析下面解析的是leveldb中的源文件format.h和format.cc，这一节代码主要围绕handle的存储和解析，footer的存储和解析，以及block的读取。 handlehandle 是对block文件之中位移和大小封装的数据结构，有了它，就能迅速对block进行定位。因为采取varint64存储这两个值，所以占据的大小最大为10bytes。 12345678910111213141516171819202122232425class BlockHandle &#123; public: BlockHandle(); // The offset of the block in the file. uint64_t offset() const &#123; return offset_; &#125; void set_offset(uint64_t offset) &#123; offset_ = offset; &#125; // The size of the stored block uint64_t size() const &#123; return size_; &#125; void set_size(uint64_t size) &#123; size_ = size; &#125; // 向dst指定的地址位置存入offset和size void EncodeTo(std::string* dst) const; // 从input指定的地址位置获取offset和size Status DecodeFrom(Slice* input); // Maximum encoding length of a BlockHandle // 两个varint64数占用的空间最大为20bytes enum &#123; kMaxEncodedLength = 10 + 10 &#125;; private: uint64_t offset_; uint64_t size_;&#125;; FooterFooter位于整个sstable文件的底部，由footer可以快速获取sstable中的metaindex block，index block的位置信息，通过比较魔数，能够快速判断是否是leveldb之中使用的sstable文件。 在Footer之中，前面40bytes存储Metaindex_handle和Index_handle，若空间不足40bytes就用0补齐。之后存放leveldb中定义的魔数0xdb4775248b80fb57ull。 1234567891011121314151617181920// footer// metaindex_handle// index_handle// padding// magic numbervoid Footer::EncodeTo(std::string* dst) const &#123; const size_t original_size = dst-&gt;size(); // 此处存放的是varint64 metaindex_handle_.EncodeTo(dst); index_handle_.EncodeTo(dst); dst-&gt;resize(2 * BlockHandle::kMaxEncodedLength); // Padding // 加上padding，为 40 bytes // 再加上8bytes对应的魔数 // 先存低 4bytes PutFixed32(dst, static_cast&lt;uint32_t&gt;(kTableMagicNumber &amp; 0xffffffffu)); // 再存高 4 bytes PutFixed32(dst, static_cast&lt;uint32_t&gt;(kTableMagicNumber &gt;&gt; 32)); assert(dst-&gt;size() == original_size + kEncodedLength); (void)original_size; // Disable unused variable warning.&#125; 在读取footer时，首先读取魔数，没有问题才继续读取meta index handle和index handle。 1234567891011121314151617181920212223// input输入的是整个footerStatus Footer::DecodeFrom(Slice* input) &#123; const char* magic_ptr = input-&gt;data() + kEncodedLength - 8; const uint32_t magic_lo = DecodeFixed32(magic_ptr); const uint32_t magic_hi = DecodeFixed32(magic_ptr + 4); const uint64_t magic = ((static_cast&lt;uint64_t&gt;(magic_hi) &lt;&lt; 32) | (static_cast&lt;uint64_t&gt;(magic_lo))); // 魔数不匹配 if (magic != kTableMagicNumber) &#123; return Status::Corruption("not an sstable (bad magic number)"); &#125; Status result = metaindex_handle_.DecodeFrom(input); if (result.ok()) &#123; result = index_handle_.DecodeFrom(input); &#125; if (result.ok()) &#123; // We skip over any leftover data (just padding for now) in "input" const char* end = magic_ptr + 8; *input = Slice(end, input-&gt;data() + input-&gt;size() - end); &#125; return result;&#125; blockleveldb在存储block的时候，实际上还要记录block的类型和当前block的CRC校验值在后面进行校验。block格式如下所示： 读取block时，首先根据option要求进行可选的crc校验，再根据type查看是压缩数据块还是raw block，对压缩数据块进行解压缩。若成功读取将读取处理之后的block记录在result之中，失败了就返回相应的状态码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// block - type - crcStatus ReadBlock(RandomAccessFile* file, const ReadOptions&amp; options, const BlockHandle&amp; handle, BlockContents* result) &#123; result-&gt;data = Slice(); result-&gt;cachable = false; result-&gt;heap_allocated = false; // Read the block contents as well as the type/crc footer. // See table_builder.cc for the code that built this structure. size_t n = static_cast&lt;size_t&gt;(handle.size()); char* buf = new char[n + kBlockTrailerSize]; Slice contents; Status s = file-&gt;Read(handle.offset(), n + kBlockTrailerSize, &amp;contents, buf); // 读取失败 if (!s.ok()) &#123; delete[] buf; return s; &#125; // 读取的block大小和handle不一致 if (contents.size() != n + kBlockTrailerSize) &#123; delete[] buf; return Status::Corruption("truncated block read"); &#125; // 检查block+type计算得到的crc值是否和记录的所一致 // Check the crc of the type and the block contents const char* data = contents.data(); // Pointer to where Read put the data if (options.verify_checksums) &#123; const uint32_t crc = crc32c::Unmask(DecodeFixed32(data + n + 1)); const uint32_t actual = crc32c::Value(data, n + 1); if (actual != crc) &#123; delete[] buf; s = Status::Corruption("block checksum mismatch"); return s; &#125; &#125; // 针对block的不同类型，采取不同的操作 switch (data[n]) &#123; case kNoCompression: if (data != buf) &#123; // File implementation gave us pointer to some other data. // Use it directly under the assumption that it will be live // while the file is open. // 内部文件操作返回的buf不是之前分配的 delete[] buf; result-&gt;data = Slice(data, n); result-&gt;heap_allocated = false; result-&gt;cachable = false; // Do not double-cache &#125; else &#123; result-&gt;data = Slice(buf, n); result-&gt;heap_allocated = true; result-&gt;cachable = true; &#125; // Ok break; // 是压缩的类型，获取解压的长度，解压block case kSnappyCompression: &#123; size_t ulength = 0; if (!port::Snappy_GetUncompressedLength(data, n, &amp;ulength)) &#123; delete[] buf; return Status::Corruption("corrupted compressed block contents"); &#125; char* ubuf = new char[ulength]; if (!port::Snappy_Uncompress(data, n, ubuf)) &#123; delete[] buf; delete[] ubuf; return Status::Corruption("corrupted compressed block contents"); &#125; delete[] buf; result-&gt;data = Slice(ubuf, ulength); result-&gt;heap_allocated = true; result-&gt;cachable = true; break; &#125; default: delete[] buf; return Status::Corruption("bad block type"); &#125; return Status::OK();&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb data block 建立]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-data-block-%E5%BB%BA%E7%AB%8B%2F</url>
    <content type="text"><![CDATA[leveldb data block 建立总览相比data block的读取来说，data block的建立比较简单，因为不涉及到查找的操作。下面的所有操作都是根据data block 内部的组织格式进行的，如下图所示。 data block record leveldb data block 建立相关的代码是data_block.h和data_block.c。 实现类成员类成员如下所示，buffers存放最终生成的data block，restarts\对应restarts数组，counter是自从上一次restart以来添加的key的计数，last_key_记录了上一次add的key。Options对应传入的参数，其中定义了restart的间隔大小限制。 12345678const Options* options_;std::string buffer_; // Destination buffer// 所有的restart数组的元素std::vector&lt;uint32_t&gt; restarts_; // Restart points// restart之后已经加入的entry的数目int counter_; // Number of entries emitted since restartbool finished_; // Has Finish() been called?std::string last_key_; 辅助类成员函数CurrentSizeEstimate() 返回当前估计的data block的大小，empty判断当前数据块是否为空，Reset重置所有状态，丢弃所有添加的key。 1234567891011// Reset the contents as if the BlockBuilder was just constructed.void Reset();// Returns an estimate of the current (uncompressed) size of the block// we are building.size_t CurrentSizeEstimate() const;// Return true iff no entries have been added since the last Reset()bool empty() const &#123; return buffer_.empty();&#125; Add和Finish操作data block在BlockBuilder类对象初始化之后，通过Add方法向block中添加键值对记录，数据块建立完成之后，调用Finish返回完整的数据块数据。 Add操作要求添加的key的顺序应该是升序的。在Add中，首先检查是否达到restart间隔。若达到了，那么shared key的长度为0，否则和last key比较得到shared key的长度。之后则将共享key，非共享key，value的长度值写入buffer之中，同时也将非共享key和value的值写入buffer，更新last key。 123456789101112131415161718192021222324252627282930313233343536373839void BlockBuilder::Add(const Slice&amp; key, const Slice&amp; value) &#123; Slice last_key_piece(last_key_); assert(!finished_); assert(counter_ &lt;= options_-&gt;block_restart_interval); // 要求key比last_key要大 assert(buffer_.empty() // No values yet? || options_-&gt;comparator-&gt;Compare(key, last_key_piece) &gt; 0); size_t shared = 0; if (counter_ &lt; options_-&gt;block_restart_interval) &#123; // See how much sharing to do with previous string const size_t min_length = std::min(last_key_piece.size(), key.size()); // 计算shared 的key的长度 while ((shared &lt; min_length) &amp;&amp; (last_key_piece[shared] == key[shared])) &#123; shared++; &#125; &#125; else &#123; // Restart compression restarts_.push_back(buffer_.size()); counter_ = 0; &#125; // 不共享的key的长度 const size_t non_shared = key.size() - shared; // Add "&lt;shared&gt;&lt;non_shared&gt;&lt;value_size&gt;" to buffer_ PutVarint32(&amp;buffer_, shared); PutVarint32(&amp;buffer_, non_shared); PutVarint32(&amp;buffer_, value.size()); // Add string delta to buffer_ followed by value buffer_.append(key.data() + shared, non_shared); buffer_.append(value.data(), value.size()); // Update state // 设置last key last_key_.resize(shared); last_key_.append(key.data() + shared, non_shared); assert(Slice(last_key_) == key); counter_++;&#125; Finish操作则是将所有的restarts数组元素写入到block之中，同时在block之中写入数组的size信息，返回整个block对应的Slice。 1234567891011// 调用finish，设置restarts数组和restarts数组的个数，返回此data blockSlice BlockBuilder::Finish() &#123; // Append restart array for (size_t i = 0; i &lt; restarts_.size(); i++) &#123; PutFixed32(&amp;buffer_, restarts_[i]); &#125; // put restarts_.size() PutFixed32(&amp;buffer_, restarts_.size()); finished_ = true; return Slice(buffer_);&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb data block 读取解析]]></title>
    <url>%2F2017%2F06%2F11%2Fleveldb-data-block-%E8%AF%BB%E5%8F%96%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[leveldb data block 读取解析下面解析的代码是block.h和block.cc，这一部分代码的功能是读取data block，并且提供一个基于data block中存储数据之上的迭代器。这一部分代码的实现首先基于data block内部存储格式，并且借助了data block数据有序的特性。 data block 内部格式 record 格式 BlockBlock的基本第一很简单，主要逻辑是一个迭代器的实现，定义在在内部类Iter中。 12345678910111213141516171819202122232425class Block &#123; public: // Initialize the block with the specified contents. explicit Block(const BlockContents&amp; contents); ~Block(); size_t size() const &#123; return size_; &#125; // Return new Iterator of given comparator Iterator* NewIterator(const Comparator* comparator); private: uint32_t NumRestarts() const; const char* data_; // 指向data block 开始处 size_t size_; // data block的大小 uint32_t restart_offset_; // Offset in data_ of restart array bool owned_; // Block owns data_[], if own need to call free when destruction // No copying allowed Block(const Block&amp;); void operator=(const Block&amp;); // 内部实现实际定义在Iter中 class Iter;&#125;; 在构造函数中，读取restarts数组的数目，判断是否合理，即存储的数组大小不可超出max_restarts_allowed。 1234567891011121314151617181920// 读取contents对应的block// 实际上读取的是data blockBlock::Block(const BlockContents&amp; contents) : data_(contents.data.data()), size_(contents.data.size()), owned_(contents.heap_allocated) &#123; if (size_ &lt; sizeof(uint32_t)) &#123; size_ = 0; // Error marker &#125; else &#123; // 最大允许的restarts的数目 size_t max_restarts_allowed = (size_-sizeof(uint32_t)) / sizeof(uint32_t); if (NumRestarts() &gt; max_restarts_allowed) &#123; // The size is too small for NumRestarts() size_ = 0; &#125; else &#123; // 指向restart数组开始的位置 restart_offset_ = size_ - (1 + NumRestarts()) * sizeof(uint32_t); &#125; &#125;&#125; 如果输入块的大小不足以容纳存放restarts数组大小的数，那么返回空的Error Iterator，若restarts数组数目为0，返回空的Iterator，否则返回内部类Iter中实现的Iterator。 123456789101112131415Iterator* Block::NewIterator(const Comparator* cmp) &#123; // 块的大小无法存储restarts数组的数目 if (size_ &lt; sizeof(uint32_t)) &#123; return NewErrorIterator(Status::Corruption("bad block contents")); &#125; // restarts数组的元素数目 const uint32_t num_restarts = NumRestarts(); // 返回一个空的iterator if (num_restarts == 0) &#123; return NewEmptyIterator(); &#125; else &#123; // 返回iterator return new Iter(cmp, data_, restart_offset_, num_restarts); &#125;&#125; Iter内部类Iter的成员如下所示： 12345678910111213const Comparator* const comparator_; const char* const data_; // underlying block contents // 指向restart数组的第一个元素 uint32_t const restarts_; // Offset of restart array (list of fixed32) uint32_t const num_restarts_; // Number of uint32_t entries in restart array // current_ is offset in data_ of current entry. &gt;= restarts_ if !Valid uint32_t current_; // 当前current_位置对应的restart数组的index uint32_t restart_index_; // Index of restart block in which current_ falls std::string key_; Slice value_; Status status_; 在构造函数之中，根据输入参数对类内部成员进行初始化，并且断言restarts数组的数目不为0。current_指向当前遍历到的record的开头位置。 12345678910111213Iter(const Comparator* comparator, const char* data, uint32_t restarts, uint32_t num_restarts) : comparator_(comparator), // 比较器 data_(data), // data restarts_(restarts), // 指向restart数组的开头位置 num_restarts_(num_restarts), // restart数组的元素个数 current_(restarts_), // current_ is offset in data_ of current entry. restart_index_(num_restarts_) &#123; // restart index // 断言restarts数组中的元素个数大于0 assert(num_restarts_ &gt; 0); &#125; 解析record的时候，调用ParseNextKey，首先判断当前record的位置是否有效，然后获取共享，不共享key的长度，value的长度，设置当前entry对应的key和value，并且设置下一个key对应的restart_index。 123456789101112131415161718192021222324252627282930313233343536373839// 解析下一个值的实现 bool ParseNextKey() &#123; // 下一个entry的offset current_ = NextEntryOffset(); const char* p = data_ + current_; // 不可能越过restarts数组 const char* limit = data_ + restarts_; // Restarts come right after data // 没有更多的entry，设置current和restart_index_，并且返回 if (p &gt;= limit) &#123; // No more entries to return. Mark as invalid. current_ = restarts_; restart_index_ = num_restarts_; return false; &#125; // Decode next entry uint32_t shared, non_shared, value_length; // 现在p指向non_shared key p = DecodeEntry(p, limit, &amp;shared, &amp;non_shared, &amp;value_length); // 解析失败，或者key的长度小于共享key的长度 // 产生了崩溃错误，返回失败 if (p == NULL || key_.size() &lt; shared) &#123; CorruptionError(); return false; &#125; else &#123; // 设置key_和value_ key_.resize(shared); key_.append(p, non_shared); // 这里的value_存放的是对应的value值 value_ = Slice(p + non_shared, value_length); // 跳过无效的restart数组元素，下一个restart数组元素指向的offset需要大于当前current_对应的偏移 while (restart_index_ + 1 &lt; num_restarts_ &amp;&amp; GetRestartPoint(restart_index_ + 1) &lt; current_) &#123; ++restart_index_; &#125; return true; &#125; &#125;&#125;; 结合record格式，对于DecodeEntry的实现可以有清晰的认识： DecodeEntry实际上是解析出共享key，非共享key和value的长度，使得p指向value开头的位置。因为key的长度一般不超过128，而且存储长度使用了varint32格式，所以这里首先尝试fast path。 123456789101112131415161718192021222324252627static inline const char* DecodeEntry(const char* p, const char* limit, uint32_t* shared, uint32_t* non_shared, uint32_t* value_length) &#123; // 不够存放key共享长度，key非共享长度和value长度 // 3个varint32数，最少需要的空间是3byte if (limit - p &lt; 3) return NULL; // 取出key共享长度，非共享长度以及value的长度 // 这几个长度都是使用varint32进行存放 *shared = reinterpret_cast&lt;const unsigned char*&gt;(p)[0]; *non_shared = reinterpret_cast&lt;const unsigned char*&gt;(p)[1]; *value_length = reinterpret_cast&lt;const unsigned char*&gt;(p)[2]; if ((*shared | *non_shared | *value_length) &lt; 128) &#123; // Fast path: all three values are encoded in one byte each p += 3; &#125; else &#123; if ((p = GetVarint32Ptr(p, limit, shared)) == NULL) return NULL; if ((p = GetVarint32Ptr(p, limit, non_shared)) == NULL) return NULL; if ((p = GetVarint32Ptr(p, limit, value_length)) == NULL) return NULL; &#125; // 若剩余的字符串长度不足以存放non_shared key和value，返回 NULL if (static_cast&lt;uint32_t&gt;(limit - p) &lt; (*non_shared + *value_length)) &#123; return NULL; &#125; // 返回指向non_shared key字符串开始位置对应的指针 return p;&#125; 相比而言，Prev的实现稍微复杂一点。首先获取上一个entry对应的restarts数组的index值，然后调整到对应的offset，遍历entry，直到entry的右边界和Prev操作之前的entry的offset重合，就找到了上一个entry。 123456789101112131415161718192021222324// iterator 往前移动一位 virtual void Prev() &#123; assert(Valid()); // Scan backwards to a restart point before current_ const uint32_t original = current_; // 设置正确的restart_index_ // 若越过了，就轮转 while (GetRestartPoint(restart_index_) &gt;= original) &#123; if (restart_index_ == 0) &#123; // No more entries current_ = restarts_; restart_index_ = num_restarts_; return; &#125; restart_index_--; &#125; // 调整到正确的restart_index_对应的位置 SeekToRestartPoint(restart_index_); // 循环直到当前entry结束的位置和original entry对应的位置相同 do &#123; // Loop until end of current entry hits the start of original entry &#125; while (ParseNextKey() &amp;&amp; NextEntryOffset() &lt; original); &#125; Seek操作利用了data block中的record有序的特性，首先利用二分查找找到小于target但是最接近target的restarts数组的偏移位置。在此偏移位置的基础之上，往后遍历直到对应entry的key大于等于target，迭代器就移动到了第一个大于或等于target的位置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748virtual void Seek(const Slice&amp; target) &#123; // Binary search in restart array to find the last restart point // with a key &lt; target // 进行二分查找，找到最后的restart point, key &lt; target uint32_t left = 0; uint32_t right = num_restarts_ - 1; // loop until left hit right while (left &lt; right) &#123; // middle uint32_t mid = (left + right + 1) / 2; uint32_t region_offset = GetRestartPoint(mid); uint32_t shared, non_shared, value_length; // 解析middle restart的第一个key const char* key_ptr = DecodeEntry(data_ + region_offset, data_ + restarts_, &amp;shared, &amp;non_shared, &amp;value_length); // 发生错误，或者第一个key shared的长度不为0 if (key_ptr == NULL || (shared != 0)) &#123; CorruptionError(); return; &#125; Slice mid_key(key_ptr, non_shared); // 在右半部分 if (Compare(mid_key, target) &lt; 0) &#123; // Key at "mid" is smaller than "target". Therefore all // blocks before "mid" are uninteresting. left = mid; &#125; // 在左半部分 else &#123; // Key at "mid" is &gt;= "target". Therefore all blocks at or // after "mid" are uninteresting. right = mid - 1; &#125; &#125; // Linear search (within restart block) for first key &gt;= target SeekToRestartPoint(left); // 找到第一个 &gt;= target的key while (true) &#123; if (!ParseNextKey()) &#123; return; &#125; if (Compare(key_, target) &gt;= 0) &#123; return; &#125; &#125; &#125; 相比而言SeekToFirst和SeekToLast的实现比较简单，如代码所示： 12345678910111213// 指向第一个restarts数组元素对应的offset，然后解析获取值virtual void SeekToFirst() &#123; SeekToRestartPoint(0); ParseNextKey();&#125;// 指向最后一个restarts数组元素对应的offset，然后解析所有剩余的keyvirtual void SeekToLast() &#123; SeekToRestartPoint(num_restarts_ - 1); while (ParseNextKey() &amp;&amp; NextEntryOffset() &lt; restarts_) &#123; // Keep skipping &#125;&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++运行时类型识别]]></title>
    <url>%2F2017%2F06%2F11%2FC-%E8%BF%90%E8%A1%8C%E6%97%B6%E7%B1%BB%E5%9E%8B%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[C++ 运行时类型识别C++中运行时类型识别(run-time type identification, RTTI)的功能由两个运算符实现。 typeid运算符，用于返回表达式的类型。 dynamic_cast运算符，用于将基类的指针或引用安全地转换成派生类的指针或者引用。 这两个运算符特别适用于以下情况：我们想使用基类对象的指针或引用执行某个派生类操作并且该操作不是虚函数。一般来说，只要有可能我们应该尽量使用虚函数。当操作被定义成为虚函数时，编译器将根据对象的动态类型根据对象的动态类型自动选择正确的函数版本。 dynamic_cast运算符dynamic_cast运算符的使用形式如下所示： 123dynamic_cast&lt;type*&gt;(e);dynamic_cast&lt;type&amp;&gt;(e);dynamic_cast&lt;type&amp;&amp;&gt;(e); type必须是一个类类型，并且通常情况下该类型应该含有虚函数。 在上面的所有形式之中，e的类型必须符合下面3个条件之中的任意一个： e的类型是目标type的公有派生类 e的类型是目标type的公有基类 e的类型就是目标type的类型。 如果符合，则类型转换就可以成功。否则，转换失败。如果一条dynamica_cast语句的转换目标是指针类型并且失败了，则结果为0。如果转换目标是引用类型并且失败了，则dynamic_cast运算符将抛出一个bad_cast的异常。 使用举例： 指针类型的dynamic_cast 12345678if (Derived* dp = dynamic_cast&lt;Derived*&gt;(bp))&#123; // 使用dp指向的Derived对象 &#125;else&#123; // 转换失败，使用bp指向的Base对象&#125; 引用类型的dynamic_cast 1234567891011void f(const Base&amp; b)&#123; try &#123; const Derived&amp; d = dynamic_cast&lt;const Derived&amp;&gt;(b); // 使用b引用的Derived对象 &#125; catch(bad_cast) &#123; // 处理类型转换失败的情况 &#125;&#125; typeid运算符为RTTI提供的第二个运算符是typeid运算符，它允许程序向表达式提问，你是什么类型？ typeid表达式的形式是typeid(e)，其中e可以是任意表达式或者类型的名字。typeid操作的结果是一个常量对象的引用，该对象的类型是标准库类型type_info或者type_info的公有派生类型。 可以通过下述方式比较两条表达式的类型是否相同，或者比较一条表达式的类型是否与指定类型相同。 123456789101112Derived* dp = new Derived;Base* bp = dp;if(typeid(*bp) == typeid(*dp))&#123; // bp和dp指向同一类型的对象&#125;// 检查运行时类型是否是某种指定的类型// 请注意，typeid应该作用于对象而不是指针。if(typeid(*bp) == typeid(Derived))&#123; // bp 实际指向Derived对象&#125; type_info类type_info类的精确定义和编译器的实现有关。C++标准规定type_info类必须定义在typeinfo头文件中，并且至少提供以下操作： 操作 说明 t1 == t2 若type_info对象t1和t2表示同一类型，返回true，否则返回false t1 != t2 如果type_info对象t1和t2表示不同的类型，返回true，否则返回false t.name() 返回一个C风格字符串，表示类型名字的可打印形式。类型名字的生成方式因系统而定 t1.before(t2) 返回一个bool值，表示t1是否位于t2之前。before所采用的顺序关系是依赖于编译器的 示例程序： 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;typeinfo&gt;using namespace std;class test&#123; public:&#125;;int main()&#123; int arr[10]; string str; cout &lt;&lt; typeid(42).name() &lt;&lt; endl; cout &lt;&lt; typeid(arr).name() &lt;&lt; endl; cout &lt;&lt; typeid(str).name() &lt;&lt; endl; return 0;&#125; 输出(macos, clang)： 1234iA10_iNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE4test]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++内存模型]]></title>
    <url>%2F2017%2F06%2F11%2FC-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[C++ std::atomic 原子类型原子操作：一个不可分割的操作。标准原子类型可以在头文件之中找到，在这种类型上的所有操作都是原子的。它们都有一个is_lock_free()的成员函数，让用户决定在给定类型上的操作是否用原子指令完成。唯一不提供is_lock_free()成员函数的类型是std::atomic_flag,在此类型上的操作要求是无锁的。可以利用std::atomic_flag实现一个简单的锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;atomic&gt;#include &lt;assert.h&gt;class spinlock_mutex&#123; public: spinlock_mutex() : flag_(ATOMIC_FLAG_INIT) &#123; &#125; void lock() &#123; while(flag_.test_and_set(std::memory_order_acquire)) ; &#125; void unlock() &#123; flag_.clear(std::memory_order_release); &#125; private: std::atomic_flag flag_;&#125;;int value = 0;spinlock_mutex mutex;void test_function()&#123; for(int i = 0; i &lt; 100000; i++) &#123; std::unique_lock&lt;spinlock_mutex&gt; lock(mutex); ++ value; &#125;&#125;int main()&#123; std::thread t1(test_function); std::thread t2(test_function); t1.join(); t2.join(); assert(value == 200000); return 0;&#125; C++ 11中的内存模型都是围绕std::atomic展开的，下面依次介绍C++ 11中引入的内存顺序。参考: Memory Model 顺序一致顺序默认的的顺序被命名为顺序一致，因为这意味着程序的行为和一个简单的世界观是一致的。如果所有原子类型实例上的操作是顺序一致的，多线程的行为就好像是所有这些操作由单个线程以某种特定的顺序进行执行的一样。在一个带有多处理器的弱顺序的机器上，它可能导致显著的性能惩罚，因为操作的整体顺序必须与处理器之间保持一致，可能需要处理器之间进行密集的同步操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x()&#123; x.store(true, std::memory_order_seq_cst);&#125;void write_y()&#123; y.store(true, std::memory_order_seq_cst);&#125;void read_x_then_y()&#123; while(!x.load(std::memory_order_seq_cst)) ; if(y.load(std::memory_order_seq_cst)) &#123; printf("x,y\n"); ++ z; &#125;&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_seq_cst)) ; if(x.load(std::memory_order_seq_cst)) &#123; printf("y,x\n"); ++ z; &#125;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load() != 0); return 0;&#125; 上述代码中的assert永远不会触发，因为while循环总能保证x或者y的值已经修改为true，如果线程c或d中有一个线程if条件不满足，那么另一个线程的if条件总能保障，所以最后z的值一定不为0。请注意memory_order_seq_cst的语义需要在所有标记memory_order_seq_cst的操作上有单一的总体顺序。 顺序一致是最直观的顺序，但是也是最为昂贵的内存顺序，因为它要求所有线程之间的全局同步。在多处理器系统中，这可能需要处理器之间相当密集和耗时的通信。 松散顺序以松散顺序执行的原子类型上的操作不参与synchronizes-with关系。单线程中的同一变量的操作仍然服从happens-before的关系，但相对于其他线程的顺序几乎没有任何要求。唯一的要求是，从同一线程对单个原子变量的访问不能重排，一旦给定的线程已经看到了原子变量的特定值，该线程之后的读取就不能获取该变量更早的值。以下程序展现了这种松散性。 123456789101112131415161718192021222324252627282930313233#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x_then_y()&#123; x.store(true, std::memory_order_relaxed); y.store(true, std::memory_order_relaxed);&#125;void read_x_then_y()&#123; while(!y.load(std::memory_order_relaxed)) ; if(x.load(std::memory_order_relaxed)) ++ z;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x_then_y); std::thread b(read_x_then_y); a.join(); b.join(); assert(z.load() != 0);&#125; 这一次，assert可能会触发。因为x和y是不同的变量，每个操作所产生的值的可见性没有顺序的保证。 为了理解松散顺序是如何工作的，可以想象每个变量是一个小隔间里使用记事本的人。在他的记事本上有一列值。你可以打电话给他，要求他给你一个值，或者你可以告诉他写下了一个新值。如果你告诉他写下新值，他就将其写在列表的底部。如果你向他要一个值，他就为你从列表之中读取一个数字。第一次你和这个人交谈，如果你向他要一个值，此时他可能从他的记事本上的列表里任意选一个给你。如果你接着向他要另一个值，他可能会再给你同一个值，或者从列表的下方给一个给你。他永远不会给你一个在列表上更上面的值。 获取释放顺序获取释放顺序是松散顺序的进步，操作仍然没有总的顺序，但是引入了一些同步。在这个顺序模型下，原子载入是acquire操作memory_order_acquire，原子存储是release操作memory_order_release，原子的读，修改，写操作是获取，释放或者两者兼有memory_order_acq_rel。不同的线程仍然可以看到不同的顺序，但是这些顺序受到了限制。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x()&#123; x.store(true, std::memory_order_release);&#125;void write_y()&#123; y.store(true, std::memory_order_release);&#125;void read_x_then_y()&#123; while(!x.load(std::memory_order_acquire)) ; if(y.load(std::memory_order_acquire)) &#123; ++ z; &#125;&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_seq_cst)) ; if(x.load(std::memory_order_seq_cst)) &#123; ++ z; &#125;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x); std::thread b(write_y); std::thread c(read_x_then_y); std::thread d(read_y_then_x); a.join(); b.join(); c.join(); d.join(); assert(z.load() != 0); return 0;&#125; 上述代码中的断言仍然可能触发，因为对x的载入和对y的载入都读取false也是有可能的。x与y由不同的线程写入，所以每种情况从释放到获取的顺序对另一个线程的操作是没有影响的。 但是对于同一个线程来说，使用获取-释放操作可以在松散操作之中施加顺序。 12345678910111213141516171819202122232425262728293031323334#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x_then_y()&#123; x.store(true, std::memory_order_relaxed); y.store(true, std::memory_order_release);&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_acquire)); if(x.load(std::memory_order_relaxed)) ++ z;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x_then_y); std::thread b(read_y_then_x); a.join(); b.join(); assert(z.load() != 0); return 0;&#125; 因为存储使用memory_order_release并且载入使用memory_order_acquire，存储与载入同步。对x的存储发生在y的存储之前，因为它们在同一个线程之中。因为对y的存储与对y的载入同步，对x的载入必然读到true，所以断言并不会触发。配合使用release和acquire可以达到跨线程同步的功能，如下代码所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;std::atomic&lt;int&gt; data[5];std::atomic&lt;bool&gt; sync1(false), sync2(false);void thread_1()&#123; data[0].store(42, std::memory_order_relaxed); data[1].store(97, std::memory_order_relaxed); data[2].store(17, std::memory_order_relaxed); data[3].store(1, std::memory_order_relaxed); data[4].store(2, std::memory_order_relaxed); sync1.store(true, std::memory_order_release);&#125;void thread_2()&#123; while(!sync1.load(std::memory_order_acquire)) ; sync2.store(true, std::memory_order_release);&#125;void thread_3()&#123; while(!sync2.load(std::memory_order_acquire)); assert(data[0].load(std::memory_order_relaxed) == 42); assert(data[1].load(std::memory_order_relaxed) == 97); assert(data[2].load(std::memory_order_relaxed) == 17); assert(data[3].load(std::memory_order_relaxed) == 1); assert(data[4].load(std::memory_order_relaxed) == 2);&#125;int main()&#123; std::thread a(thread_1); std::thread b(thread_2); std::thread c(thread_3); a.join(); b.join(); c.join(); return 0;&#125; 获取释放顺序与MEMORY_ORDER_CONSUME的数据依赖通过在载入上使用memory_order_consume以及在之前的存储上使用memory_order_release，你可以确保所指向的数据得到正确的同步，并且无需再其他非依赖的数据上强制任何同步需求。以下代码展示了这种用途: 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;#include &lt;string&gt;#include &lt;unistd.h&gt;struct X&#123; int i; std::string s;&#125;;std::atomic&lt;X*&gt; p;std::atomic&lt;int&gt; a;void create_x()&#123; X* x = new X; x-&gt;i = 42; x-&gt;s = "hello world"; a.store(99, std::memory_order_relaxed); // 因为这里依赖了x，所以这一句代码执行时保证了x已经初始化完毕，并且已经完成赋值。 // 要点，有依赖关系的都已赋值完毕 p.store(x, std::memory_order_release);&#125;void use_x()&#123; X * x; while(!(x=p.load(std::memory_order_consume))) sleep(1); assert(x-&gt;i == 42); assert(x-&gt;s == "hello world"); // 可能断言出错 assert(a.load(std::memory_order_relaxed) == 99);&#125;int main()&#123; std::thread t1(create_x); std::thread t2(use_x); t1.join(); t2.join();&#125; 上述代码中的前两个断言不会出错，因为p的载入带有对那些通过变量x的表达式的依赖。另一方面，在a的值上的断言或许会被触发。此操作并不依赖从p载入的值，因而对读到的值就没有保证。 内存屏障内存屏障分为写内存屏障和读内存屏障。写内存屏障保证所有在屏障之前的写入操作都会在屏障之后的写入操作之前完成，而读内存屏障确保所有屏障之前的读取操作都会在屏障之后的读取操作前执行。内存屏障使得特定的操作无法穿越。以下代码演示了内存屏障的用法。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;#include &lt;string&gt;#include &lt;unistd.h&gt;std::atomic&lt;bool&gt; x, y;std::atomic&lt;int&gt; z;void write_x_then_y()&#123; x.store(true, std::memory_order_relaxed); // 写内存屏障 std::atomic_thread_fence(std::memory_order_release); y.store(true, std::memory_order_release);&#125;void read_y_then_x()&#123; while(!y.load(std::memory_order_acquire)); // 读内存屏障 std::atomic_thread_fence(std::memory_order_acquire); if(x.load(std::memory_order_relaxed)) ++ z;&#125;int main()&#123; x = false; y = false; z = 0; std::thread a(write_x_then_y); std::thread b(read_y_then_x); a.join(); b.join(); assert(z.load() != 0);&#125; 释放屏障与获取屏障同步，因为线程b中从y载入在线程a中存储的值，这意味着线程a对x的存储发生在线程b从x的load之前，所以读取的值一定为true，断言永远不会触发。 参考: 《 C++并发编程实战 》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo EPollPoller]]></title>
    <url>%2F2017%2F06%2F11%2Fmuduo-EPollPoller%2F</url>
    <content type="text"><![CDATA[默认使用什么io复用模型？在Poller的接口类中定义了一个static函数，如下所示： 1static Poller* newDefaultPoller(EventLoop* loop); 其实现是在DefaultPoller.cc文件之中，如下所示：1234567891011Poller* Poller::newDefaultPoller(EventLoop* loop)&#123; if (::getenv("MUDUO_USE_POLL")) &#123; return new PollPoller(loop); &#125; else &#123; return new EPollPoller(loop); &#125;&#125; 可见除非定义了MUDUO_USE_POLL环境变量，否则muduo会使用epoll作为io复用的方式。 poll因为epoll返回的io事件对应的结构体 epoll_event中，有一个data成员可以记录相关信息，可以方便我们找到对应的Channel，因而epoll的实现较poll比较更为简单。 1234567typedef union epoll_data&#123; void* ptr; int fd; uint32_t u32; uint64_t u64;&#125;epoll_data_t; 12345678910111213141516171819202122232425262728293031323334Timestamp EPollPoller::poll(int timeoutMs, ChannelList* activeChannels)&#123; LOG_TRACE &lt;&lt; "fd total count " &lt;&lt; channels_.size(); int numEvents = ::epoll_wait(epollfd_, &amp;*events_.begin(), static_cast&lt;int&gt;(events_.size()), timeoutMs); int savedErrno = errno; Timestamp now(Timestamp::now()); if (numEvents &gt; 0) &#123; LOG_TRACE &lt;&lt; numEvents &lt;&lt; " events happended"; fillActiveChannels(numEvents, activeChannels); if (implicit_cast&lt;size_t&gt;(numEvents) == events_.size()) &#123; events_.resize(events_.size()*2); &#125; &#125; else if (numEvents == 0) &#123; LOG_TRACE &lt;&lt; "nothing happended"; &#125; else &#123; // error happens, log uncommon ones if (savedErrno != EINTR) &#123; errno = savedErrno; LOG_SYSERR &lt;&lt; "EPollPoller::poll()"; &#125; &#125; return now;&#125; 拿到epoll返回的事件列表之后，就可以调用fillActiveChannels来将当前active的Channel填充进入EventLoop之中的activeChannels之中。 123456789101112131415161718void EPollPoller::fillActiveChannels(int numEvents, ChannelList* activeChannels) const&#123; assert(implicit_cast&lt;size_t&gt;(numEvents) &lt;= events_.size()); for (int i = 0; i &lt; numEvents; ++i) &#123; Channel* channel = static_cast&lt;Channel*&gt;(events_[i].data.ptr);#ifndef NDEBUG int fd = channel-&gt;fd(); ChannelMap::const_iterator it = channels_.find(fd); assert(it != channels_.end()); assert(it-&gt;second == channel);#endif // set revents channel-&gt;set_revents(events_[i].events); activeChannels-&gt;push_back(channel); &#125;&#125; update Channel在Poller中使用std::map&lt;int, Channel*&gt; 来存放fd和对应channel之间的对应关系。需要保证channel和fd的一一对应，不能存在一个fd由两个不同的channel来管理。 12345678910111213141516171819202122232425262728293031323334353637383940414243void EPollPoller::updateChannel(Channel* channel)&#123; Poller::assertInLoopThread(); const int index = channel-&gt;index(); LOG_TRACE &lt;&lt; "fd = " &lt;&lt; channel-&gt;fd() &lt;&lt; " events = " &lt;&lt; channel-&gt;events() &lt;&lt; " index = " &lt;&lt; index; if (index == kNew || index == kDeleted) &#123; // a new one, add with EPOLL_CTL_ADD int fd = channel-&gt;fd(); if (index == kNew) &#123; assert(channels_.find(fd) == channels_.end()); channels_[fd] = channel; &#125; else // index == kDeleted &#123; assert(channels_.find(fd) != channels_.end()); assert(channels_[fd] == channel); &#125; channel-&gt;set_index(kAdded); update(EPOLL_CTL_ADD, channel); &#125; else &#123; // update existing one with EPOLL_CTL_MOD/DEL int fd = channel-&gt;fd(); (void)fd; assert(channels_.find(fd) != channels_.end()); assert(channels_[fd] == channel); assert(index == kAdded); if (channel-&gt;isNoneEvent()) &#123; update(EPOLL_CTL_DEL, channel); channel-&gt;set_index(kDeleted); &#125; else &#123; update(EPOLL_CTL_MOD, channel); &#125; &#125;&#125; Channel默认的index被设为-1，在epoll之中，index被用作标明类别，有以下3种类型，故而新创建的Channel其index代表新增的Channel。 123456namespace&#123;const int kNew = -1;const int kAdded = 1;const int kDeleted = 2;&#125; updateChannel会根据Channel的revent来调用update方法。注意到对于没有关注任何io事件的Channel，EPollPoller采取的方式是将该channel对应的fd直接从epoll之中删除。 123456789101112131415161718192021void EPollPoller::update(int operation, Channel* channel)&#123; struct epoll_event event; bzero(&amp;event, sizeof event); event.events = channel-&gt;events(); event.data.ptr = channel; int fd = channel-&gt;fd(); LOG_TRACE &lt;&lt; "epoll_ctl op = " &lt;&lt; operationToString(operation) &lt;&lt; " fd = " &lt;&lt; fd &lt;&lt; " event = &#123; " &lt;&lt; channel-&gt;eventsToString() &lt;&lt; " &#125;"; if (::epoll_ctl(epollfd_, operation, fd, &amp;event) &lt; 0) &#123; if (operation == EPOLL_CTL_DEL) &#123; LOG_SYSERR &lt;&lt; "epoll_ctl op =" &lt;&lt; operationToString(operation) &lt;&lt; " fd =" &lt;&lt; fd; &#125; else &#123; LOG_SYSFATAL &lt;&lt; "epoll_ctl op =" &lt;&lt; operationToString(operation) &lt;&lt; " fd =" &lt;&lt; fd; &#125; &#125;&#125; 在update中，对于delete操作进行了区分处理，它容忍delete出错，但是对于modify和add出错，程序会fatal。 removeChannelremoveChannel将Channel对应的fd从epoll中删除，并且Channel也从channels_之中删除了。123456789101112131415161718192021void EPollPoller::removeChannel(Channel* channel)&#123; Poller::assertInLoopThread(); int fd = channel-&gt;fd(); LOG_TRACE &lt;&lt; "fd = " &lt;&lt; fd; assert(channels_.find(fd) != channels_.end()); assert(channels_[fd] == channel); assert(channel-&gt;isNoneEvent()); int index = channel-&gt;index(); assert(index == kAdded || index == kDeleted); size_t n = channels_.erase(fd); (void)n; assert(n == 1); if (index == kAdded) &#123; update(EPOLL_CTL_DEL, channel); &#125; channel-&gt;set_index(kNew);&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Connector]]></title>
    <url>%2F2017%2F06%2F11%2Fmuduo-Connector%2F</url>
    <content type="text"><![CDATA[怎么判断连接成功了？12345678910111213141516171819202122232425262728293031323334353637383940void Connector::connect()&#123; int sockfd = sockets::createNonblockingOrDie(serverAddr_.family()); int ret = sockets::connect(sockfd, serverAddr_.getSockAddr()); int savedErrno = (ret == 0) ? 0 : errno; switch (savedErrno) &#123; case 0: case EINPROGRESS: case EINTR: case EISCONN: connecting(sockfd); break; case EAGAIN: case EADDRINUSE: case EADDRNOTAVAIL: case ECONNREFUSED: case ENETUNREACH: retry(sockfd); break; case EACCES: case EPERM: case EAFNOSUPPORT: case EALREADY: case EBADF: case EFAULT: case ENOTSOCK: LOG_SYSERR &lt;&lt; "connect error in Connector::startInLoop " &lt;&lt; savedErrno; sockets::close(sockfd); break; default: LOG_SYSERR &lt;&lt; "Unexpected error in Connector::startInLoop " &lt;&lt; savedErrno; sockets::close(sockfd); // connectErrorCallback_(); break; &#125;&#125; 可见，对于非阻塞io，如果connect之后的返回值为0，或者errno设置为EINTR, EINPROGRESS, EISCONN, 那么代表连接成功或者正在连接的过程之中。 如果errno为EAGIN，EADDRINUSE，EADDRNOTAVAIL，ECONNREFUSED，ENETURNREACH, 那么表示连接失败。在linux tcp编程之中，对于连接失败的情况，可以移植的解决方式是重新创建一个socket fd，再次尝试连接。对于EACCES，EPERM，EAFNOSUPPORT，EALREADY，EBADF，EFAULT，ENOTSOCK的情况，表示不可恢复的连接失败，直接停止连接，对于其他未知的情况也做此处理。 现在，怎么知道连接成功了呢？以connect返回的sockfd创建一个channel，关注其可写事件。若channel可写，并且尝试使用getsockopt(sockfd, SOL_SOCKET, SO_ERROR, &amp;optval, &amp;optlen)返回的errorCode为0，并且不是自连接，那么说明连接成功，可以将这个sockfd通过connectionCallback通知TcpClient。当然，如果调用的是ErrorCallback，那么close返回的fd，并且进行重试。 1234567891011121314151617181920212223242526272829303132333435363738void Connector::handleWrite()&#123; LOG_TRACE &lt;&lt; "Connector::handleWrite " &lt;&lt; state_; if (state_ == kConnecting) &#123; int sockfd = removeAndResetChannel(); int err = sockets::getSocketError(sockfd); if (err) &#123; LOG_WARN &lt;&lt; "Connector::handleWrite - SO_ERROR = " &lt;&lt; err &lt;&lt; " " &lt;&lt; strerror_tl(err); retry(sockfd); &#125; else if (sockets::isSelfConnect(sockfd)) &#123; LOG_WARN &lt;&lt; "Connector::handleWrite - Self connect"; retry(sockfd); &#125; else &#123; setState(kConnected); if (connect_) &#123; newConnectionCallback_(sockfd); &#125; else &#123; sockets::close(sockfd); &#125; &#125; &#125; else &#123; // what happened? assert(state_ == kDisconnected); &#125;&#125; 12345678910111213141516171819202122// check if self connectionbool sockets::isSelfConnect(int sockfd)&#123; struct sockaddr_in6 localaddr = getLocalAddr(sockfd); struct sockaddr_in6 peeraddr = getPeerAddr(sockfd); if (localaddr.sin6_family == AF_INET) &#123; const struct sockaddr_in* laddr4 = reinterpret_cast&lt;struct sockaddr_in*&gt;(&amp;localaddr); const struct sockaddr_in* raddr4 = reinterpret_cast&lt;struct sockaddr_in*&gt;(&amp;peeraddr); return laddr4-&gt;sin_port == raddr4-&gt;sin_port &amp;&amp; laddr4-&gt;sin_addr.s_addr == raddr4-&gt;sin_addr.s_addr; &#125; else if (localaddr.sin6_family == AF_INET6) &#123; return localaddr.sin6_port == peeraddr.sin6_port &amp;&amp; memcmp(&amp;localaddr.sin6_addr, &amp;peeraddr.sin6_addr, sizeof localaddr.sin6_addr) == 0; &#125; else &#123; return false; &#125;&#125; 怎么实现超时重连？对于retry的处理使用了Connector的retry方法，他会设置超时回调，回调的时间间隔设置为从500ms~30s, 每次重新retry会将间隔的时间加倍，当然时间间隔不可超过30s。 1234567891011121314151617void Connector::retry(int sockfd)&#123; sockets::close(sockfd); setState(kDisconnected); if (connect_) &#123; LOG_INFO &lt;&lt; "Connector::retry - Retry connecting to " &lt;&lt; serverAddr_.toIpPort() &lt;&lt; " in " &lt;&lt; retryDelayMs_ &lt;&lt; " milliseconds. "; loop_-&gt;runAfter(retryDelayMs_/1000.0, std::bind(&amp;Connector::startInLoop, shared_from_this())); retryDelayMs_ = std::min(retryDelayMs_ * 2, kMaxRetryDelayMs); &#125; else &#123; LOG_DEBUG &lt;&lt; "do not connect"; &#125;&#125; 对于stop的处理如果要停止连接，那么首先设置connect_为false，表示不需要建立连接了，这样若handleWrite之中返回了正常的sockfd，那么我也不要通过这个sockfd创建一个连接，而是直接将其close。并且因为connect_设置设置为false，后续进行retry的时候也不会尝试重新连接的。 紧接着的是对stopInLoop的调用，这里对正在处于连接状态的channel进行了reset处理，并且将没有确定连接的sockfd关闭。]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的可变长参数模板]]></title>
    <url>%2F2017%2F06%2F10%2FC-%E4%B8%AD%E7%9A%84%E5%8F%AF%E5%8F%98%E9%95%BF%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[C++ 中的可变长参数基本格式在C++中，可变长参数模板可以用来应对未知长度函数参数的问题。其基本格式如下所示： 123456template&lt;typename ...Args&gt;void g(Args ... args)&#123; cout &lt;&lt; sizeof ...(Args) &lt;&lt; endl; // 类型参数的数目 cout &lt;&lt; sizeof ...(args) &lt;&lt; endl; // 函数参数的数目&#125; 基本用法可变参数函数通常是递归的，第一步调用处理包中的第一个实参，然后用剩余的实参来调用自身。如下的print示例程序就演示了这种用法。123456789101112131415161718192021222324#include &lt;vector&gt;#include &lt;cstring&gt;using namespace std;// 递归调用的终点template&lt;typename T&gt;ostream&amp; print(ostream&amp; os, const T&amp; t)&#123; return os &lt;&lt; t;&#125;template&lt;typename T, typename... Args&gt;ostream&amp; print(ostream&amp; os, const T&amp; t, const Args&amp;... rest)&#123; os &lt;&lt; t &lt;&lt; ", "; // 递归用剩余参数进行调用 return print(os, rest...);&#125;int main()&#123; print(cout, 1, 2.0, false);&#125; 递归会执行如下序列： print(cout, 1, 2.0, false) print(cout, 2.0, false) print(cout, false) 当定义可变参数版本的print的时候，非可变参数版本的声明必须在作用域中。否则，可变参数版本会无限递归。 包扩展可以利用包扩展机制，对可变长模板参数中的每一个参数进行相同的调用。如下所示代码演示了对输入的每个参数都调用了函数no_operation。 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;atomic&gt;#include &lt;vector&gt;#include &lt;cstring&gt;using namespace std;// 递归调用的终点template&lt;typename T&gt;ostream&amp; print(ostream&amp; os, const T&amp; t)&#123; return os &lt;&lt; t;&#125;template&lt;typename T&gt;T no_operation(const T&amp; val)&#123; return val;&#125;template&lt;typename T, typename... Args&gt;ostream&amp; print(ostream&amp; os, const T&amp; t, const Args&amp;... rest)&#123; os &lt;&lt; t &lt;&lt; ", "; // 递归用剩余参数进行调用 // 对所有的参数统一调用no_operation return print(os, no_operation(rest)...);&#125;int main()&#123; // 实际调用no_operation的次数为3，和输入的参数的个数一致 print(cout, 1, 2.0, false);&#125; 转发参数包借助std::forward，可以安全的将输入的可变长参数转发给其他函数，这样vector通过emplace_back就在容器内部直接通过输入的参数构造需要插入的对象。 最简单的例子是make_unique，如下所示： 12345template&lt;typename T, typename... Args&gt;std::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp; ...args)&#123; return std::unique_ptr&lt;T&gt;(new T(std::forward&lt;Args&gt;(args)...));&#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb filter_block]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-filter-block%2F</url>
    <content type="text"><![CDATA[leveldb filter_block解析filter meta block 文件格式首先借助leveldb文档leveldb File format可以确定filter meta block内部的格式如下所示： 1234567891011121314[filter 0][filter 1][filter 2][filter 3][filter 4]...[filter N-1][offset of filter 0] : 4 bytes[offset of filter 1] : 4 bytes[offset of filter 2] : 4 bytes...[offset of filter N-1] : 4 bytes[offset of beginning of offset array] : 4 byteslg(base) : 1 byte 借助源码和文档，我对filter meta block的格式有了深刻的理解。每一个filter对应负责一个block offset范围内的key的组织。对于第i个filter，它所管理的key在文件中的偏移范围是[i * base ... (i+1) * base - 1]。在leveldb中，base默认被设置为2KB，也就是说每2KB长度的偏移位置对应一个独立的filter。 每一个key借助hash函数(maybe, 看filter策略具体实现)产生一个滤值，一个filter可能会有多个这样的滤值。所有filter的滤值最后从前到后依次保存在filter meta block之中。然后再存放每一个filter对应滤值的偏移位置。根据当前filter和下一个filter的offset值就可以确定当前filter对应滤值在filter meta block中偏移值的范围。紧接着存放最后一个filter对应滤值offset范围的下界，通过它我们还能知道整个块中filter的数量。filter meta block的最后存放的是log(base)的值，由它我们能知道每个filter所能管理的文件偏移大小限制。 附上一张网上找到的图 FilterBlockBuilder12345678910111213141516171819202122232425262728293031// A FilterBlockBuilder is used to construct all of the filters for a// particular Table. It generates a single string which is stored as// a special block in the Table.//// The sequence of calls to FilterBlockBuilder must match the regexp:// (StartBlock AddKey*)* Finishclass FilterBlockBuilder &#123; public: explicit FilterBlockBuilder(const FilterPolicy*); void StartBlock(uint64_t block_offset); void AddKey(const Slice&amp; key); Slice Finish(); private: void GenerateFilter(); const FilterPolicy* policy_; // 过滤策略 std::string keys_; // 存放所有的key std::vector&lt;size_t&gt; start_; // 存放每一个key在keys_的下标范围 // 存放最终的结果 std::string result_; // Filter data computed so far // 用于记录每个filter产生的滤值的临时容器 std::vector&lt;Slice&gt; tmp_keys_; // policy_-&gt;CreateFilter() argument // 记录每个filter的offset开始位置 std::vector&lt;uint32_t&gt; filter_offsets_; // No copying allowed FilterBlockBuilder(const FilterBlockBuilder&amp;); void operator=(const FilterBlockBuilder&amp;);&#125;; FilterBlockBuilder对象在构造的时候需要指定FilterPolicy，它要用其来生成滤值。在对偏移为block_offset的文件进行操作前，首先需要调用StartBlock。此方法确定输入的偏移值对应哪一个filter，并且将filter_index更小的filter的滤值写入result_。 123456789void FilterBlockBuilder::StartBlock(uint64_t block_offset) &#123; // kFilterBase的大小为2048 uint64_t filter_index = (block_offset / kFilterBase); assert(filter_index &gt;= filter_offsets_.size()); while (filter_index &gt; filter_offsets_.size()) &#123; // 若filter_index 的值更大，将之前的filter对应的滤值加入result_ GenerateFilter(); &#125;&#125; 请注意，要按照偏移的先后顺序调用StartBlock和AddKey方法，这样才能保证filter meta block内部顺序和实际偏移一致。 GenerateFilter方法将当前filter所管理的key按照输入的Filter策略转换为滤值，并且记录当前filter对应的滤值在block中偏移的开始位置。123456789101112131415161718192021222324252627282930313233// 产生新的filtervoid FilterBlockBuilder::GenerateFilter() &#123; // 对应key的数目 const size_t num_keys = start_.size(); if (num_keys == 0) &#123; // Fast path if there are no keys for this filter // 记录此filter的偏移位置 filter_offsets_.push_back(result_.size()); return; &#125; // Make list of keys from flattened key structure start_.push_back(keys_.size()); // Simplify length computation tmp_keys_.resize(num_keys); for (size_t i = 0; i &lt; num_keys; i++) &#123; // 每个key的开头位置 const char* base = keys_.data() + start_[i]; // 每个key的长度 size_t length = start_[i+1] - start_[i]; tmp_keys_[i] = Slice(base, length); &#125; // Generate filter for current set of keys and append to result_. // 记录此filter的偏移起始位置 filter_offsets_.push_back(result_.size()); // 创建filter，输入key对应的数组，数组大小，存放结果的result // result存放key对应的hash值 policy_-&gt;CreateFilter(&amp;tmp_keys_[0], static_cast&lt;int&gt;(num_keys), &amp;result_); tmp_keys_.clear(); keys_.clear(); start_.clear();&#125; 在加入新的key时，会在start_中记录新的key在keys_中的开始位置，然后将其append到keys_之中，这样之后借助keys_和start_t就能重构所有输入的key。12345void FilterBlockBuilder::AddKey(const Slice&amp; key) &#123; Slice k = key; start_.push_back(keys_.size()); keys_.append(k.data(), k.size());&#125; Finish函数的操作很容易理解，他首先记录所有filter对应滤值的offset范围，注意要补充记录最后一个filter的滤值offset下界。当然也要按照文件格式记录log(base)值。 12345678910111213141516171819Slice FilterBlockBuilder::Finish() &#123; if (!start_.empty()) &#123; GenerateFilter(); &#125; // Append array of per-filter offsets // 这是滤值数组的结束位置offset，将这个值记住 const uint32_t array_offset = result_.size(); // 存放filter对应的offset开头位置 for (size_t i = 0; i &lt; filter_offsets_.size(); i++) &#123; PutFixed32(&amp;result_, filter_offsets_[i]); &#125; // 存放最后一个filter offset的下界 PutFixed32(&amp;result_, array_offset); // 存放kFilterBaseLg的大小 // kFilterBaseLg = log(base) result_.push_back(kFilterBaseLg); // Save encoding parameter in result return Slice(result_);&#125; FilterBlockReader相比FilterBlockBuilder，FilterBLockReader可以理解为它的逆过程。 123456789101112131415class FilterBlockReader &#123; public: // REQUIRES: "contents" and *policy must stay live while *this is live. FilterBlockReader(const FilterPolicy* policy, const Slice&amp; contents); bool KeyMayMatch(uint64_t block_offset, const Slice&amp; key); private: const FilterPolicy* policy_; const char* data_; // Pointer to filter data (at block-start) // 指向offset数组靠近block尾部的开始处 const char* offset_; // Pointer to beginning of offset array (at block-end) // filter的数目 size_t num_; // Number of entries in offset array size_t base_lg_; // Encoding parameter (see kFilterBaseLg in .cc file)&#125;; 在构造函数中，Reader根据文件格式获取base的log值，filter的数目，第一个filter的偏移的开始位置。 123456789101112131415161718192021FilterBlockReader::FilterBlockReader(const FilterPolicy* policy, const Slice&amp; contents) : policy_(policy), data_(NULL), offset_(NULL), num_(0), base_lg_(0) &#123; size_t n = contents.size(); // size not enough to hold start and offset array if (n &lt; 5) return; // 1 byte for base_lg_ and 4 for start of offset array // 取出base_lg_的值 base_lg_ = contents[n-1]; uint32_t last_word = DecodeFixed32(contents.data() + n - 5); // 滤值数组的最后元素的末尾位置不可能超出n-5，否则无法容纳 if (last_word &gt; n - 5) return; data_ = contents.data(); // 指向最后一个filter滤值的offset下界位置 offset_ = data_ + last_word; // filter的数量 num_ = (n - 5 - last_word) / 4;&#125; 至于对key的匹配判断，对于输入的block_offset，计算出它属于哪一个filter。然后取出此filter的所有滤值，和key按照filter策略计算得到的滤纸进行匹配，相同说明可能匹配，否则不能匹配。对于计算得到的filter的index值大于block中filter的数量的情况，也被认为是匹配，即错误被当做潜在的匹配。 123456789101112131415161718bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice&amp; key) &#123; uint64_t index = block_offset &gt;&gt; base_lg_; if (index &lt; num_) &#123; // 滤值开始位置对应的偏移 uint32_t start = DecodeFixed32(offset_ + index*4); // 滤值结束位置对应的偏移 // 实质上是下一个filter的offset开始位置 uint32_t limit = DecodeFixed32(offset_ + index*4 + 4); if (start &lt;= limit &amp;&amp; limit &lt;= static_cast&lt;size_t&gt;(offset_ - data_)) &#123; Slice filter = Slice(data_ + start, limit - start); return policy_-&gt;KeyMayMatch(key, filter); &#125; else if (start == limit) &#123; // Empty filters do not match any keys return false; &#125; &#125; return true; // Errors are treated as potential matches&#125;]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb File format]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-File-format%2F</url>
    <content type="text"><![CDATA[leveldb File format123456789101112&lt;beginning_of_file&gt;[data block 1][data block 2]...[data block N][meta block 1]...[meta block K][metaindex block][index block][Footer] (fixed size; starts at file_size - sizeof(Footer))&lt;end_of_file&gt; 文件之中包含内部指针。每一个这样的指针被称为BlockHandle，包含下述信息。 12offset: varint64size: varint64 varint的解释可以查看varints。 文件中的键值对按照顺序进行存储，并被分割成为数据块序列。这些数据块在文件中从前到后依次排列。每一个数据块按照block_builder.cc中的代码进行格式化，然后进行可选的压缩。 在数据块之后，我们存储了一串元数据块。支持的meta块类型会在下文描述。未来可能会增加新的meta块类型。每一个meta块也是使用block_builder.cc中的代码进行格式化，然后进行可选的压缩。 一个命名为”metaindex”的块。对于其他的meta块每个块记录一个entry，key是meta块的名称，value是指向对应meta块的BlockHandle。 一个名为”index”的块。这个块对于每个数据块记录一个entry，key是大于对应数据块最后一个key，并且小于紧接着的下一个数据块的第一个key的字符串。value是数据块的BlockHandle。 每个文件的末尾是一个固定长度的footer，包含metaindex和index块的BlockHandle，以及一个魔数。 12345metaindex_handle: char[p]; // Block handle for metaindexindex_handle: char[q]; // Block handle for indexpadding: char[40-p-q];// zeroed bytes to make fixed length // (40==2*BlockHandle::kMaxEncodedLength)magic: fixed64; // == 0xdb4775248b80fb57 (little-endian) “filter” Meta Block若数据库打开时指定了FilterPolicy，每个table会存储一个filter块。”metaindex”块包含一条entry，记录从filter.&lt;N&gt;到filter块的BlockHandle的映射。其中&lt;N&gt;是filter policy的Name()方法返回的字符串。 filter块存储了filters序列，其中filter i包含FilterPolicy::CreateFilter()所有key的输出，这些key在文件中偏移的范围在范围： 1[ i*base ... (i+1)*base-1 ] 当前，”base”是2KB，举例来说，若块x和y在文件中的偏移范围是[0KB .. 2KB-1]，所有x和y的将会调用FilterPolicy::CreateFilter()转换成filter，生成的filter是第一个filter block。 filter块的格式如下所示： 1234567891011121314[filter 0][filter 1][filter 2]...[filter N-1][offset of filter 0] : 4 bytes[offset of filter 1] : 4 bytes[offset of filter 2] : 4 bytes...[offset of filter N-1] : 4 bytes[offset of beginning of offset array] : 4 byteslg(base) : 1 byte filter块末尾的offset array 允许从data block偏移到对应filter的有效映射。 “Stats” Meta Block这一meta块包含一串统计信息。key是统计名称，value是统计值。 TODO(postrelease): record following stats. 123456data sizeindex sizekey size (uncompressed)value size (uncompressed)number of entriesnumber of data blocks]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb Log format]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-Log-format%2F</url>
    <content type="text"><![CDATA[leveldb Log format日志文件内容是一系列32KB大小的block序列。唯一的例外是文件的末尾可能包含一个不完整的block。 每一个block包含一个记录序列： 123456block := record* trailer? record := checksum: uint32 // crc32c of type and data[] ; little-endian length: uint16 // little-endian type: uint8 // One of FULL, FIRST, MIDDLE, LAST data: uint8[length] 一条记录不会在一个block的最后6 byte处开始（因为放不下）。所有剩余的bytes组成trailer，需要包含全0的bytes，并且必须被读者跳过。 例外：若当前block恰好剩余7bytes，增加一个新的非0长度的record，写者必须将第一条记录（包含长度为0的用户数据）填充之前block剩余的7bytes，将用户数据写入之后的block之中。 在未来可能会增加新的类型。 一些读者可能会跳过不理解的记录类型，其他的可能会报告他跳过了一些值。 1234FULL == 1FIRST == 2MIDDLE == 3LAST == 4 FULL record包含完整的用户记录。 FIRST, MIDDLE, LAST 用于标志分片的用户记录（一般由于block边界）。FIRST是用户记录第一个分片的类型，LAST是用户记录最后一个分片的类型，MIDDLE是所有的用户记录中间分片的类型。 例子： 一个用户记录序列： 123A: length 1000B: length 97270C: length 8000 A 会是第一个block的FULL记录。 B 会被分为3个分段：第一段占据第一块剩余部分，第二段占据第二个block的全部，第三段占据第三个block的前面的绝大部分。第三个block会剩余6bytes空间，会被空余当做trailer。 C 会在第4个block中存放一条FULL记录。 Some benefits over the recordio format: 重新同步时不需要任何启发式查找 - 只需要到下一个block边界并进行扫描。 如果有错误，跳过去处理下一个block。附加的好处是，当一个log文件的部分内容被嵌入另一个log文件作为record时，我们不会陷入疑惑。 在大致的边界上进行分割（例如，mapreduce）非常简单：找到下一个块的边界，跳过record直到我们找到一条FULL或者FIRST类型的记录。 对于大的records，我们不需要额外的缓存。 Some downside compared to recordio format: 不会对小的record进行打包。可以通过增加新的记录类型来解决。所以这是当前实现的缺陷，不是这一format的缺点。 没有压缩。 这个也可以通过增加新的记录类型来解决。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leveldb 实现文档]]></title>
    <url>%2F2017%2F06%2F09%2Fleveldb-%E5%AE%9E%E7%8E%B0%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[leveldb 实现文档Filesleveldb的实现和一个单点的Bigtable tablet(section 5.2)相似。但是内部文件的组成有所不同，下面会进行解释。 每一个数据库都是存储在目录下一系列的文件集合构成。有以下几种不同的文件类型： Log files一个log文件存储了最近更新的序列。每一个更新记录都被追加到当前的log文件中。当log文件达到预先设置的大小（可能是默认值4MB），它会被转换为一个sorted table，并且会创建一个新的log文件记录未来的更新。 当前log文件的副本被保存在内存中(memtable)。每次读都会检索这一副本，所以读操作能反映所有已经记录日志的更新。 Sorted tables一个sorted table（*.ldb）保存了按照key排序的entry序列。每一个entry可能是key和对应的value，或者key和对应的删除标记。（在旧版本的sorted tables中，删除标记用于覆盖过期的value）。 sorted tables组成的集合被组织成为level序列。从一个log文件中生成的sorted table被放置在一个特殊的 young level之中（也被称为level-0）。当 young files 的数目超出阈值（当前设置为4），所有的 young files 和key区间重叠的level-1文件合并生成一系列新的level-1文件（我们创建的新的level-1文件的大小是2MB）。 young level 文件可能包含重叠区间的key。但是其他level的文件都有唯一的没有重叠的key区间范围。对于 &gt;= 1的level值L，当level-L级别的文件大小超过（10^L）MB时（例如，level-1达到10MB, level-2达到100MB，···），一个level-L文件和所有key区间重叠的level-(L+1)文件合并为level-(L+1)的一系列新文件。这些合并操作使用块读取和写入操作，将新的更新从young level 逐步迁移到最大的level，减少了昂贵的寻道操作。 Manifset一个MANIFEST文件列出了组成每个level的sorted tables文件集合，对应key的范围，其他重要的元数据。一个新的MANIFEST文件（会在文件名中植入新的number）会在数据库重新打开时创建。MANIFEST是日志文件，服务状态的更新（新增或者移除文件）会追加到这一log文件。 CurrentCURRENT是一个简单的文本文件，其中包含了最新的MANIFEST文件的名字。 Info logs日志信息被写入命名为LOG或者Log.old的文件。 Others其他文件各种用途的文件，用途如名称所述，例如LOCK， *.dbtmp。 level0当log文件增长到某个值（默认是1MB）时： 创建新的memtable和log文件，将未来的更新写入新的文件。 在后台： 将之前memtable的内容写入到sstable 丢弃memtable 删除旧的log和memtable文件，将新的sstable文件加入young level。 Compactions当level L的文件大小超出限制之后，我们会在后台线程之中进行压缩合并。合并操作选取level-L中的一个文件和下一个level-(L+1)中key区间重叠的所有文件进行。注意到，如果level-L文件key区间只和level-(L+1)文件部分重叠，那么level-(L+1)文件会作为合并操作的输入，并且在合并操作完成之后被丢弃。例外：因为level-0文件比较特殊（level-0文件可能彼此之间互相重叠），我们对于从level-0到level-1的合并操作特殊对待：一个level-0级别的合并操作会选取所有key区间重叠的level-0文件进行，因而选取的level-0文件数量可能超过1。 一个合并压缩操作合并选取的文件内容，产生一个level-(L+1)序列的文件。在当前输出文件大小到达目标大小（2MB），我们会创建新的level-(L+1)文件。我们在当前输出文件的大小增长到和超过10个level-(L+2)级别的文件重叠时，也会产生新的输出文件。最后一条规则确保之后对于level-(L+1)文件的合并操作不会涉及到level-(L+2)中的过多的文件。 旧的文件会被丢弃，新的文件会被记录以更新当前服务状态。 对于一个特定level来说，合并操作会在key区间轮转进行。更详细地说，对于每一个level L，我们记录上一次level-L合并操作最后的key，下次level L的合并操作将会选取第一个大于这个key的文件开始（如果没有这样的文件，就从key区间的开头位置开始）。 合并操作会丢弃覆盖的值。若更高level的文件key的区间没有包含标记为删除的key，也会将其删除。 TimingLevel-0的合并操作会读取至多4个1MB大小的level-0文件，在最坏的情况下会读取所有的level-1文件（10MB）。因此，我们会读14MB，写14MB。 除了特殊的level-0合并操作，我们会从level-L选取一个2MB的文件。在最坏的情况下，这一文件会和level-(L+1)的中12个level-L文件大小的，level-(L+1)文件key区间重合（10因为level-(L+1) 比level-L的文件大小大10倍，剩余2因为level-L的文件大小和level-L+1的文件大小通常不对齐而增加的界限)。所以合并操作会读取26MB，写入26MB。假设硬盘的IO速度为100MB/s(现代设备的速度)，最坏的合并操作需要大约0.5秒。 若我们限制后台写入的速度，比如说全速100MB/s的10%，一个合并操作可能花费5秒。如果用户写入的速度是10MB/s，我们需要创建很多level-0文件（~50个，用于存放5*10MB）。由于每次读操作会合并过多的文件，这会显著增加读的开销。 解决方式： 为了减小这一问题，当level-0文件数量很大时，我们可能需要增加生成新的log文件的阈值。然而，缺点是这个阈值越大，我们需要更多的内存来存放对应的memtable。 当level-0文件数量上涨时，我们可能需要人为减小写入速度。 减小大幅度merge的开销。可能大多数level-0文件都是未经压缩存放在cache中，我们只需要O(N)复杂度的合并操作。 Number of files不再总是创建2MB的文件，更大level的文件有更大的大小能减小文件总数，虽然以合并操作更加突发为代价。另外，我们能将文件集合存放在不同的路径下。 2001年2月4日，一个在ext3文件系统下的实验演示了对于目录下不同数量，相同大小（100K）文件的打开操作的时间开销： Files in directory Microseconds to open a file 1000 9 10000 10 100000 16 所以对于现代文件系统，分片没有必要？ Recovery 读取CURRENT找到最新提交的MANIFEST文件的名称 读取MANIFEST文件 清除无效文件 我们可以打开所有的sstables文件，但是可能晚点打开会更好… 将log文件转换为新的level-0 sstable文件 将更新新写入新的log文件（以恢复后的序列） Garbage collection of fileDeleteObsoleteFiles()在每次合并和恢复操作的最后会被调用。他会查找database中用到的所有文件，删除不是当前log文件的所有log文件，删除没被任何层引用并且不是有效合并操作输出的所有table文件。]]></content>
      <categories>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>leveldb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Channel]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Channel%2F</url>
    <content type="text"><![CDATA[实现简介channel一般用于抽象一个fd，包含fd当前关注的事件，出现事件更新需要在poller之中做出更新。poller获取到当前io复用返回的io事件之后，会更新channel之中的revent。在eventloop中会为当前活跃的channel进行事件处理，调用对应revent，io事件的回调函数。整个Channel类的实现非常简单明了。 重点:tie可能出现这种情况，我们设置的回调函数是某个类的成员函数，此类对象使用shared_ptr进行管理。如果在回调函数之中对此shared_ptr进行了reset或者release处理，那么此回调函数就会立即失效，因为类对象被回收了。对于这种特殊情况，可以使用std::weak_ptr&lt;void&gt; tie来存放该shared_ptr的弱引用（使用弱引用是为了避免增加shared_ptr的引用计数，导致对象一直无法得以析构。每次进行事件处理的时候，若之前设置了tie，那么首先tie进行提升，保证回调函数处理期间此shared_ptr管理的对象不会被析构。 tie这一措施是为了TcpConnectionPtr而设计了，如果在某个回调函数之中，reset了此TcpConnectionPtr, 那么TcpConnection的其他回调函数就会失效。所以在处理这些事件期间，需要提升此TcpConnectionPtr的引用计数，阻止TcpConnectionPtr被析构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455void Channel::tie(const std::shared_ptr&lt;void&gt;&amp; obj)&#123; tie_ = obj; tied_ = true;&#125;void Channel::handleEvent(Timestamp receiveTime)&#123; std::shared_ptr&lt;void&gt; guard; if (tied_) &#123; guard = tie_.lock(); if (guard) &#123; handleEventWithGuard(receiveTime); &#125; &#125; else &#123; handleEventWithGuard(receiveTime); &#125;&#125;void Channel::handleEventWithGuard(Timestamp receiveTime)&#123; eventHandling_ = true; LOG_TRACE &lt;&lt; reventsToString(); if ((revents_ &amp; POLLHUP) &amp;&amp; !(revents_ &amp; POLLIN)) &#123; if (logHup_) &#123; LOG_WARN &lt;&lt; "fd = " &lt;&lt; fd_ &lt;&lt; " Channel::handle_event() POLLHUP"; &#125; if (closeCallback_) closeCallback_(); &#125; if (revents_ &amp; POLLNVAL) &#123; LOG_WARN &lt;&lt; "fd = " &lt;&lt; fd_ &lt;&lt; " Channel::handle_event() POLLNVAL"; &#125; if (revents_ &amp; (POLLERR | POLLNVAL)) &#123; if (errorCallback_) errorCallback_(); &#125; if (revents_ &amp; (POLLIN | POLLPRI | POLLRDHUP)) &#123; if (readCallback_) readCallback_(receiveTime); &#125; if (revents_ &amp; POLLOUT) &#123; if (writeCallback_) writeCallback_(); &#125; eventHandling_ = false;&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Buffer]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Buffer%2F</url>
    <content type="text"><![CDATA[实现原理在muduo之中，使用std::vector来存放网络中传输的数据，包括从要发送给对方的数据以及从对方接收的数据。在Buffer之中，预留了 prependable 的缓存，可以在buffer之中加入前缀而无需移动整个buffer。整个buffer分为prependable, readable, writable bytes. Buffer 的布局可以参考下图。 12345678910/// A buffer class modeled after org.jboss.netty.buffer.ChannelBuffer////// @code/// +-------------------+------------------+------------------+/// | prependable bytes | readable bytes | writable bytes |/// | | (CONTENT) | |/// +-------------------+------------------+------------------+/// | | | |/// 0 &lt;= readerIndex &lt;= writerIndex &lt;= size/// @endcode&gt;&gt;&gt; Buffer的作用非常之大，将用户程序从繁琐的Buffer相关读写操作之中解放了出来。 重点在muduo的Buffer之中，对read进行了特殊处理。因为从socket读，会调用read，涉及到一次上下文切换，为了减少系统调用的开销，read的调用次数是越少越好，因而需要尽可能预先分配更大的用户空间缓存。另一方面，如果对于每个连接都分配过多的缓存，那么会造成因为内存容量有限而造成支持的并发连接数目有限的问题。这二者之间存在矛盾。 在muduo之中，使用分配在堆栈上的缓存区域以及readv系统调用，将读取的数据优先存入buffer之中，超过限制才存放在堆栈上分配的缓存之中，最后再统一汇总到buffer之中。离开readFd函数之后，堆栈上分配的读取缓存会被自动回收。具体可以参考以下代码: 123456789101112131415161718192021222324252627282930313233ssize_t Buffer::readFd(int fd, int* savedErrno)&#123; // saved an ioctl()/FIONREAD call to tell how much to read char extrabuf[65536]; struct iovec vec[2]; const size_t writable = writableBytes(); vec[0].iov_base = begin()+writerIndex_; vec[0].iov_len = writable; vec[1].iov_base = extrabuf; vec[1].iov_len = sizeof extrabuf; // when there is enough space in this buffer, don't read into extrabuf. // when extrabuf is used, we read 128k-1 bytes at most. const int iovcnt = (writable &lt; sizeof extrabuf) ? 2 : 1; const ssize_t n = sockets::readv(fd, vec, iovcnt); if (n &lt; 0) &#123; *savedErrno = errno; &#125; else if (implicit_cast&lt;size_t&gt;(n) &lt;= writable) &#123; writerIndex_ += n; &#125; else &#123; writerIndex_ = buffer_.size(); append(extrabuf, n - writable); &#125; // if (n == writable + sizeof extrabuf) // &#123; // goto line_30; // &#125; return n;&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[auto关键字]]></title>
    <url>%2F2017%2F06%2F08%2Fauto%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[5. 优先使用auto而非显示类型声明在C++之中，使用auto关键字声明类型可以将程序员从输入繁琐的类型中解放出来，编译器会自动推导出变量的实际类型。 123456789template&lt;typename It&gt;void dwim(It b, It e)&#123; while(b != e)&#123; typename std::iterator_traits&lt;It&gt;::value_type currValue = *b; ... &#125;&#125; 使用auto关键字 12345678template&lt;typename It&gt;void dwim(It b, It e)&#123; while(b != e)&#123; auto currValue = *b; ... &#125;&#125; 在C++14中，lambda函数的参数都可以使用auto来定义。1234auto derefLess = // C++14 comparison [](const auto&amp; p1, // function for const auto&amp; p2) // values pointed &#123; return *p1 &lt; *p2; &#125;; 使用auto生命类型还可以将我们从类型截断的问题中解放出来：12std::vector&lt;int&gt; arrs;auto size = arrs.size(); 在C++中，unordered_map的key的类型是const类型的，所以即便采取如下方式遍历unordered_map容器，仍然会产生临时对象：1234567std::unordered_map&lt;std::string, int&gt; m; ...for (const std::pair&lt;std::string, int&gt;&amp; p : m)&#123; ... // do something with p&#125; 但是借助auto，我们不仅使声明更加简洁，还避开了此问题：1234567std::unordered_map&lt;std::string, int&gt; m; ...for (const auto&amp; p : m)&#123; ... // do something with p&#125; 6. 当auto推导出非预期类型时应当使用显示的类型初始化在C++中，因为标准不允许返回对bit的引用，所以对于vector&lt;bool&gt;标准库进行了特化处理，其[]运算符返回的是std::vector&lt;bool&gt;::reference类型的临时对象。对临时对象的修改会被其同步到vector中，因而这样使用auto关键字是不合规的。12345Widget w;…auto highPriority = features(w)[5]; // w是不是个高优先级的？…processWidget(w, highPriority); // 配合优先级处理w 在这种情况下，我们只需显示指出highPriority的类型为bool即可规避此问题。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>modern effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++类型推导]]></title>
    <url>%2F2017%2F06%2F08%2FC%2B%2B%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[1. 理解模板类型推导1. expr是T&amp;123456template&lt;typename T&gt;void f(T &amp; param);// 我们声明如下变量int x = 27;const int cx = x;const int&amp; rx = x; 函数调用时，推导出的Param和T的类型如下： 123f(x); // T is int, param's type is int&amp;f(cx); // T is const int, param's type is const int&amp;f(rx); // T is const int, param's type is const int&amp; 需要特别注明的是，通过T&amp;的方式传入数组，数组的大小信息不会丢失。 1234template&lt;typename T&gt;void f(T&amp; param);const int arr[10];f(arr); // T is const int[10], param type is const int(&amp;)[10] 在类型推导期间，数组和函数将退化为指针类型，除非他们是被初始化为引用。 2. expr是const T&amp;123456template&lt;typename T&gt;void f(const T&amp; param);int x = 27;const int cx = x;const int&amp; rx = x; 在进行类型推导的时候，rx的引用性被忽略了。 123f(x); // T is int, param's type is const int&amp;f(cx); // T is int, param's type is const int&amp;f(rx); // T is int, param's type is const int&amp; 3. param是一个指针类型1234567template&lt;typename T&gt;void f(T* param); // param is now a pointerint x = 27;const int* px = &amp;x;f(&amp;x); // T is int, param's type is int *f(px); // T is const int, param's type is const int * 4. param是universial reference1234567891011template&lt;typename T&gt;void f(T&amp;&amp; param); // param is now a universal referenceint x = 27;const int cx = x;const int&amp; rx = x;f(x); // x is lvalue, so T is int&amp;, param's type is also int&amp;f(cx); // cx is lvalue, so T is const int&amp;, param's type is also const int&amp;f(rx); // rx is lvalue, so T is const int&amp;, param's type is also const int&amp;f(27); // 27 is rvalue, so T is int, param's typs is int&amp;&amp; 5. param 既不是指针也不是引用12template&lt;typename T&gt;void f(T param); 当ParamType既不是指针也不是引用的时候，我们按照值传递的方式进行处理。需要举出一个有用的例子：1234template&lt;typename T&gt;void f(T param);const char* const ptr = "hello world\n";f(ptr); // param's type is const char* 2. 理解auto自动类型推导auto 类型对象推导通常和模板类型推导是相同的。例子：123456const char name[] = "zhouyang";auto arr1 = name; // arr1's type is const char*auto&amp; arr2 = name; // arr2's type is const char(&amp;)[9]void someFunc(int, double); // someFunc is a functionauto func1 = someFunc; // func1's type is void(*)(int, double)auto&amp; func2 = someFunc; // func2's type is void(&amp;)(int, double) 唯一的例外是：使用auto和大括号进行初始化时，自动推导为std::initializer_list。并且，对于使用括号进行的初始化，模板类型推导会失败。 3. 理解decltypedecltype 一般情况下总是返回变量名或者表达式的类型而不做任何的修改。123const int i = 0; // decltype(i) is const intbool f(const Widget&amp; w) // decltype(w) is const Widget&amp;Widget W; // decltype(w) is Widget 在C++14中，提供了decltype(auto)的支持，它从初始化式子中推导类型，使用的是decltype的推导规则。123456Widget w;cosnt Widget&amp; cw = w;auto myWidget1 = cw; // myWidget1's type is Widgetdecltype(auto) myWidget2 = cw; // decltype type deduction: // myWidget2's type is const Widget&amp;// 注：可以在模板中使用 特例:12345678910111213#include &lt;iostream&gt;using namespace std;int main()&#123; int temp = 10; decltype((temp)) temp1 = temp; // temp1's type is int&amp; temp1 = 1; cout&lt;&lt; temp &lt;&lt; endl; return 0;&#125;//输出 : 1 4. 了解如何查看推导出的类型可以利用编译器诊断来完成。我们想要知道被推导出的类型，可以首先声明一个类模板，但是不定义它。那么编译器的出错信息会包含推导的类型信息。12template&lt;typename T&gt;class TD; 通过编译器内置的宏定义，可以输出函数类型1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void test_func(int)&#123;#if defined(__GNUC__) cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; endl;#elif defined(_MSC_VER) cout &lt;&lt; __FUNCSIG__ &lt;&lt; endl;#endif&#125;int main()&#123; test_func(10); return 0;&#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>modern effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo Acceptor]]></title>
    <url>%2F2017%2F06%2F08%2Fmuduo-Acceptor%2F</url>
    <content type="text"><![CDATA[运行流程Acceptr是muduo之中TcpServer用于接受连接的wrapper类。其中有一个成员acceptChannel_用于接受连接。其句柄是用于接受连接的socket fd。 上述acceptChannel_关注的是可读事件，可读代表有新的连接可以accept了。在关注可读事件之前需要首先开始监听。监听的backlog的限制采用的是Linux所支持的最大值: SOMAXCONN. 特殊处理在接受连接的时候，可能会出现这种问题：描述符用完了，这会导致accpet失败，并且返回ENFILE错误。但是并没有拒绝这一连接，连接仍然会在连接队列之中，这导致了下一次eventLoop中仍然会触发监听描述符的可读事件，这会导致busy loop。 一种比较简单的解决方式是程序遇到这个问题，直接忽略，直到这种情况消失，但是这种解决方式会导致busy waiting。 另一种解决思路是记录除了EAGAIN或者EWOULDBLOCK其他任何错误，告诉用户出现了某种错误，并且停止监听描述符的可读事件，减少CPU的使用。 在libevent中，采用的是如下解决方式。首先打开/dev/null, 保留一个文件描述符，当accept出现ENFILE或者EMFILE错误的时候，关闭/dev/null，然后再次accept，并且close掉accept产生的fd，再次打开/dev/null，这是一种比较优雅的方式来拒绝客户端的连接。 最后一种比较sb的方式是遇到accept的这种错误，直接拒绝并且退出。这种方式比较容易受到Dos攻击。 12345678910111213141516171819202122232425262728293031323334void Acceptor::handleRead()&#123; loop_-&gt;assertInLoopThread(); InetAddress peerAddr; //FIXME loop until no more int connfd = acceptSocket_.accept(&amp;peerAddr); if (connfd &gt;= 0) &#123; // string hostport = peerAddr.toIpPort(); // LOG_TRACE &lt;&lt; "Accepts of " &lt;&lt; hostport; if (newConnectionCallback_) &#123; newConnectionCallback_(connfd, peerAddr); &#125; else &#123; sockets::close(connfd); &#125; &#125; else &#123; LOG_SYSERR &lt;&lt; "in Acceptor::handleRead"; // Read the section named "The special problem of // accept()ing when you can't" in libev's doc. // By Marc Lehmann, author of libev. if (errno == EMFILE) &#123; ::close(idleFd_); idleFd_ = ::accept(acceptSocket_.fd(), NULL, NULL); ::close(idleFd_); idleFd_ = ::open("/dev/null", O_RDONLY | O_CLOEXEC); &#125; &#125;&#125;]]></content>
      <categories>
        <category>muduo</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>muduo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>